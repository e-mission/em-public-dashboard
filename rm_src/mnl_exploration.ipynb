{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import importlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from uuid import UUID\n",
    "from collections import defaultdict\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_path = Path(os.getcwd()).parent.parent / 'my_emission_server' / 'e-mission-server'\n",
    "sys.path.append(str(emission_path))\n",
    "\n",
    "# Also add the home (viz_scripts) to the path\n",
    "sys.path.append('../viz_scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storage not configured, falling back to sample, default configuration\n",
      "URL not formatted, defaulting to \"Stage_database\"\n",
      "Connecting to database URL localhost\n"
     ]
    }
   ],
   "source": [
    "import scaffolding\n",
    "import emission.core.get_database as edb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'scaffolding' from '/Users/rkulhall/em-public-dashboard/rm_src/../viz_scripts/scaffolding.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(scaffolding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.reset_index(drop=True, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../viz_scripts/auxiliary_files/dic_re.pkl', 'rb') as f:\n",
    "    dic_re = pickle.loads(f.read())\n",
    "\n",
    "with open('../viz_scripts/auxiliary_files/dic_pur.pkl', 'rb') as f:\n",
    "    dic_pur = pickle.loads(f.read())\n",
    "\n",
    "# convert a dictionary to a defaultdict\n",
    "dic_re = defaultdict(lambda: 'Other', dic_re)\n",
    "dic_pur = defaultdict(lambda: 'Other', dic_pur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new program stage, creating new list\n",
      "Found new program 4c, creating new list\n",
      "Found new program cc, creating new list\n",
      "Found new program fc, creating new list\n",
      "Found new program pc, creating new list\n",
      "Found new program sc, creating new list\n",
      "Found new program vail, creating new list\n",
      "Found new program prepilot, creating new list\n"
     ]
    }
   ],
   "source": [
    "# Split UUIDs by program\n",
    "program_uuid_map = {}\n",
    "for ue in edb.get_uuid_db().find():\n",
    "    uuid = str(ue['uuid'])\n",
    "    # uuid = str(ue['uuid'])\n",
    "    program = ue['user_email'].split(\"_\")[0]\n",
    "    if program in program_uuid_map.keys():\n",
    "        program_uuid_map[program].append(uuid)\n",
    "    else:\n",
    "        print(f\"Found new program {program}, creating new list\")\n",
    "        program_uuid_map[program] = []\n",
    "        program_uuid_map[program].append(uuid)\n",
    "\n",
    "uuid_program_list = []\n",
    "for ue in edb.get_uuid_db().find():\n",
    "    # uuid = str(ue['uuid'].as_uuid(3))\n",
    "    uuid = str(ue['uuid'])\n",
    "    program = ue['user_email'].split(\"_\")[0]\n",
    "    uuid_program_list.append({\"program\": program, \"opcode\": ue[\"user_email\"], \"user_id\": uuid})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid_program_df = pd.DataFrame(uuid_program_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded all confirmed trips of length 241123\n",
      "After filtering, found 241123 participant trips \n",
      "After filtering, found 92446 labeled trips\n",
      "Found Index(['mode_confirm', 'purpose_confirm', 'replaced_mode'], dtype='object') columns of length 3\n",
      "After expanding, columns went from 41 -> 44\n",
      "_prepilot\n",
      "Based on 92395 confirmed trips from 235 users\n",
      "of 241123 total  trips from 261 users (38.32%)\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "\n",
    "# for program in uuid_program_df.program.unique():\n",
    "expanded_ct, file_suffix, quality_text, debug_df = scaffolding.load_viz_notebook_data(None,\n",
    "                                                                            None,\n",
    "                                                                            'prepilot',\n",
    "                                                                            'program',\n",
    "                                                                            dic_re,\n",
    "                                                                            dic_pur=dic_pur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join to the program df to get each user's program\n",
    "expanded_ct['original_user_id'] = expanded_ct['user_id'].copy()\n",
    "expanded_ct['user_id'] = expanded_ct['user_id'].apply(lambda x: str(x))\n",
    "expanded_ct = expanded_ct.merge(uuid_program_df, on='user_id')\n",
    "expanded_ct['user_id'] = expanded_ct['user_id'].apply(lambda x: str(x).replace(\"-\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source', 'end_ts', 'end_fmt_time', 'end_loc', 'raw_trip', 'start_ts',\n",
       "       'start_fmt_time', 'start_loc', 'duration', 'distance', 'start_place',\n",
       "       'end_place', 'cleaned_trip', 'inferred_labels', 'inferred_trip',\n",
       "       'expectation', 'confidence_threshold', 'expected_trip', 'user_input',\n",
       "       'section_modes', 'section_distances', 'start_local_dt_year',\n",
       "       'start_local_dt_month', 'start_local_dt_day', 'start_local_dt_hour',\n",
       "       'start_local_dt_minute', 'start_local_dt_second',\n",
       "       'start_local_dt_weekday', 'start_local_dt_timezone',\n",
       "       'end_local_dt_year', 'end_local_dt_month', 'end_local_dt_day',\n",
       "       'end_local_dt_hour', 'end_local_dt_minute', 'end_local_dt_second',\n",
       "       'end_local_dt_weekday', 'end_local_dt_timezone', '_id', 'user_id',\n",
       "       'metadata_write_ts', 'additions', 'mode_confirm', 'purpose_confirm',\n",
       "       'replaced_mode', 'distance_miles', 'Mode_confirm', 'Replaced_mode',\n",
       "       'Trip_purpose', 'original_user_id', 'program', 'opcode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_ct.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the target column.\n",
    "expanded_ct.drop(columns=['replaced_mode'], axis='rows', inplace=True)\n",
    "expanded_ct['Replaced_mode'] = expanded_ct['Replaced_mode'].fillna('Unlabeled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92383 trips across 235 users\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"{n_trips} trips across {n_users} users\".format(\n",
    "        n_trips=len(expanded_ct.cleaned_trip.unique()),\n",
    "        n_users=len(expanded_ct.user_id.unique())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.to_datetime(\n",
    "    expanded_ct.start_fmt_time, utc=True\n",
    ").dt.tz_convert('America/Denver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range from 2016-08-15 07:59:32.418000-06:00 to 2022-12-30 23:33:27.147785-07:00\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Date range from {min_dt} to {max_dt}\".format(\n",
    "        min_dt=dates.min(),\n",
    "        max_dt=dates.max()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Denver dedmographic info\n",
    "survey_data = pd.read_csv('../viz_scripts/Can Do Colorado eBike Program - en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data.rename(\n",
    "    {\n",
    "        \"Unique User ID (auto-filled, do not edit)\": \"user_id\",\n",
    "        \"In which year were you born?\": \"birth_year\",\n",
    "        \"What is your gender?\": \"gender\",\n",
    "        \"Do you have a valid driver's license?\": \"has_drivers_license\",\n",
    "        \"Are you a student?\": \"is_student\",\n",
    "        \"What is the highest grade or degree that you have completed?\": \"highest_education\",\n",
    "        \"Do you work for either pay or profit?\": \"is_paid\",\n",
    "        \"Do you have more than one job?\": \"has_multiple_jobs\",\n",
    "        \"Do you work full-time or part-time at your primary job?\": \"primary_job_type\",\n",
    "        \"Which best describes your primary job?\": \"primary_job_description\",\n",
    "        \"How did you usually get to your primary job last week? \": \"primary_job_commute_mode\",\n",
    "        \"Thinking about your daily commute to work last week, how many minutes did it usually take to get from home to the primary job/work place?\": \"primary_job_commute_time\",\n",
    "        \"At your primary job, do you have the ability to set or change your own start time?\": \"is_primary_job_flexible\",\n",
    "        \"Do you have the option of working from home or an alternate location instead of going into your primary work place?\": \"primary_job_can_wfh\",\n",
    "        \"How many days per week do you usually work from home or an alternate location?\": \"wfh_days\",\n",
    "        \"Do you own or rent your place of residence?\": \"residence_ownership_type\",\n",
    "        \"What is your home type?\": \"residence_type\",\n",
    "        \"Please identify which category represents your total household income, before taxes, for last year.\": \"income_category\",\n",
    "        \"Including yourself, how many people live in your home?\": \"n_residence_members\",\n",
    "        \"How many children under age 18 live in your home?\": \"n_residents_u18\",\n",
    "        \"Including yourself, how many people have a driver's license in your household?\": \"n_residents_with_license\",\n",
    "        \"How many motor vehicles are owned, leased, or available for regular use by the people who currently live in your household?\": \"n_motor_vehicles\",\n",
    "        \"If you were unable to use your household vehicle(s), which of the following options would be available to you to get you from place to place?\": \"available_modes\",\n",
    "        \"Do you have a medical condition that makes it difficult to travel outside of the home?\": \"has_medical_condition\",\n",
    "        \"How long have you had this condition?\": \"medical_condition_duration\"\n",
    "    },\n",
    "    axis='columns',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data['Timestamp'] = pd.to_datetime(survey_data['Timestamp'])\n",
    "survey_data['Timestamp'] = survey_data['Timestamp'].dt.tz_localize('America/Los_Angeles', ambiguous='infer')\n",
    "survey_data['Timestamp'] = survey_data['Timestamp'].dt.tz_convert('America/Denver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data.Timestamp.min(), survey_data.Timestamp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_survey = survey_data.loc[survey_data.user_id.isin(expanded_ct.user_id), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f_survey.user_id.unique()), len(survey_data.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_survey = f_survey.sort_values(\n",
    "    by=['user_id', 'Timestamp'], ascending=True\n",
    ").drop_duplicates(\n",
    "    subset=['user_id'], keep='last', ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert f_survey.user_id.value_counts().max() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers.\n",
    "\n",
    "bad_ix = list()\n",
    "\n",
    "# WFH is not a good feature to include because of its high sparsity.\n",
    "# wfh_mask = f_survey.wfh_days > 7\n",
    "\n",
    "# Computed by calculating 99th percentile.\n",
    "commute_time_mask = f_survey.primary_job_commute_time > 75\n",
    "\n",
    "# Computed by calculating 99th percentile.\n",
    "residence_members_mask = f_survey.n_residence_members > 8\n",
    "\n",
    "for mask in [commute_time_mask, residence_members_mask]:\n",
    "    bad_ix += f_survey[mask].index.tolist()\n",
    "\n",
    "f_survey.drop(index=set(bad_ix), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find age at the time of the timestamp. subtract birth year from timestamp year.\n",
    "def compute_age(row):\n",
    "    if row['birth_year'] < 100:\n",
    "        return row['birth_year']\n",
    "    return row['Timestamp'].year - row['birth_year']\n",
    "\n",
    "f_survey['age'] = f_survey.apply(lambda x: compute_age(x), axis=1)\n",
    "# f_survey.drop(columns=['birth_year'], inplace=True)\n",
    "\n",
    "# For those who leave it NA, categorize them as 'prefer not to say'.\n",
    "f_survey.loc[f_survey['has_multiple_jobs'].isna(), 'has_multiple_jobs'] = 'Prefer not to say'\n",
    "\n",
    "# Fix primary commute mode.\n",
    "\n",
    "f_survey.loc[\n",
    "    f_survey.primary_job_commute_mode.isna(), 'primary_job_commute_mode'\n",
    "] = 'Unknown'\n",
    "\n",
    "# Remove all leading and trailing whitespace.\n",
    "f_survey.primary_job_commute_mode = f_survey.primary_job_commute_mode.str.strip()\n",
    "\n",
    "f_survey.loc[\n",
    "    f_survey.primary_job_commute_mode.isin([\n",
    "        'Car', 'SUV', 'Pickup truck', 'Taxi/Limo (including services like Uber or Lyft)', 'Van',\n",
    "        'Shared vehicle'\n",
    "    ]), 'primary_job_commute_mode'\n",
    "] = 'Car transport'\n",
    "\n",
    "f_survey.loc[\n",
    "    f_survey.primary_job_commute_mode.isin([\n",
    "        'Public or commuter bus', 'Buss'\n",
    "    ]), 'primary_job_commute_mode'\n",
    "] = 'Public transport'\n",
    "\n",
    "f_survey.loc[\n",
    "    f_survey.primary_job_commute_mode.isin([\n",
    "        'Walk', 'Skateboard', 'Bicycle'\n",
    "    ]), 'primary_job_commute_mode'\n",
    "] = 'Active transport'\n",
    "\n",
    "f_survey.loc[\n",
    "    f_survey.primary_job_commute_mode.isin([\n",
    "        'Telecommute', 'Work from home', 'I work from home'\n",
    "    ]), 'primary_job_commute_mode'\n",
    "] = 'WFH'\n",
    "\n",
    "f_survey.loc[\n",
    "    f_survey.primary_job_commute_mode.isin([\n",
    "        'Walk, bike, bus, uber or lyft.', 'Car and E-Bike'\n",
    "    ]), 'primary_job_commute_mode'\n",
    "] = 'Hybrid'\n",
    "\n",
    "# Fix primary job type\n",
    "f_survey.loc[f_survey.primary_job_type.isna(), 'primary_job_type'] = 'Prefer not to say'\n",
    "\n",
    "# Remove whitespace.\n",
    "f_survey.primary_job_description = f_survey.primary_job_description.str.strip()\n",
    "\n",
    "# Normalize the job description. Inspired from the 'e-bike trips by occupation' \n",
    "# plot in the CanBikeCo full pilot paper.\n",
    "f_survey.loc[\n",
    "    f_survey.primary_job_description.isin([\n",
    "        'Paraprofessional', 'Education', 'education/early childhood', 'Teacher',\n",
    "        'Education non-profit manager', 'Scientific research', 'Research',\n",
    "        'Preschool Tracher'\n",
    "    ]), 'primary_job_description'\n",
    "] = 'Education'\n",
    "\n",
    "f_survey.loc[\n",
    "    f_survey.primary_job_description.isin([\n",
    "        'Custodian', 'Custodial', 'Csu custodian', 'Janitorial',\n",
    "        'Custodial Maintanace'\n",
    "    ]), 'primary_job_description'\n",
    "] = 'Custodial'\n",
    "\n",
    "f_survey.loc[\n",
    "    f_survey.primary_job_description.isin([\n",
    "        'Inbound cs', 'Accounting Technician', \n",
    "        'Clerical'\n",
    "    ]), 'primary_job_description'\n",
    "] = 'Clerical or administrative support'\n",
    "\n",
    "f_survey.loc[\n",
    "    f_survey.primary_job_description.isin([\n",
    "        'Restaurant manager', 'Transportaion Services',\n",
    "    ]), 'primary_job_description'\n",
    "] = 'Sales or service'\n",
    "\n",
    "f_survey.loc[\n",
    "    f_survey.primary_job_description.isin([\n",
    "        'Pastry chef and line cook', 'Cook', 'Chef', 'Dining Services',\n",
    "        'Food Service', 'Cooking', 'Residential Dining Services', 'Line Cook'\n",
    "    ]), 'primary_job_description'\n",
    "] = 'Food service'\n",
    "\n",
    "f_survey.loc[\n",
    "    f_survey.primary_job_description.isin([\n",
    "        'CNA', 'Caregiver/ Qmap', 'Health care', 'Nurse',\n",
    "        'Healthcare', 'Medical', 'Medical field',\n",
    "        'Family support'\n",
    "    ]), 'primary_job_description'\n",
    "] = 'Medical/healthcare'\n",
    "\n",
    "f_survey.loc[\n",
    "    f_survey.primary_job_description.isin([\n",
    "        'Amazon', 'Hockey rink', 'Caregiver', 'Security', 'Nonprofit social work',\n",
    "        'Therapeutic', 'Driver'\n",
    "    ]), 'primary_job_description'\n",
    "] = 'Other'\n",
    "\n",
    "f_survey.loc[\n",
    "    f_survey.primary_job_description.isin([\n",
    "        'Hospital laundry', 'Matreal handler', 'Maintenance',\n",
    "        'Co op laundry'\n",
    "    ]), 'primary_job_description'\n",
    "] = 'Manufacturing, construction, maintenance, or farming'\n",
    "\n",
    "f_survey.loc[f_survey.primary_job_description.isna(), 'primary_job_description'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_survey.primary_job_description.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the commute time by grouping by occupation type and using median.\n",
    "job_commutes = f_survey.groupby('primary_job_description')['primary_job_commute_time'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_type in job_commutes.index:\n",
    "    f_survey.loc[\n",
    "        (f_survey.primary_job_description == job_type)&(f_survey.primary_job_commute_time.isna()), \n",
    "        'primary_job_commute_time'\n",
    "    ] = job_commutes[job_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix motor vehicles. Keep this ordinal.\n",
    "f_survey.loc[f_survey.n_motor_vehicles == '4+', 'n_motor_vehicles'] = 4\n",
    "f_survey.loc[f_survey.n_motor_vehicles == 'Prefer not to say / Prefiero no decir.', 'n_motor_vehicles'] = 0\n",
    "f_survey.n_motor_vehicles = f_survey.n_motor_vehicles.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [\n",
    "    'Which one below describe you best?', 'wfh_days', 'primary_job_can_wfh', 'is_primary_job_flexible',\n",
    "    'medical_condition_duration', 'has_medical_condition', 'residence_type', 'residence_ownership_type',\n",
    "    'is_paid', 'is_student'\n",
    "]\n",
    "\n",
    "f_survey.drop(columns=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(f_survey.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Let us think about this. Given that the income category is not defined, it does not make sense\n",
    "to encode the factor as a non-zero ordinal number. 9.6% of the people in the dataset choose to\n",
    "not disclose their income. We could just drop them, but then we risk losing quite a lot of information.\n",
    "'''\n",
    "\n",
    "f_survey.loc[f_survey.income_category == 'Prefer not to say', 'income_category'] = 0\n",
    "f_survey.loc[f_survey.income_category == 'Less than $24,999', 'income_category'] = 1\n",
    "f_survey.loc[f_survey.income_category == '$25,000-$49,999', 'income_category'] = 2\n",
    "f_survey.loc[f_survey.income_category == '$50,000-$99,999', 'income_category'] = 3\n",
    "f_survey.loc[f_survey.income_category == '$100,000 -$149,999', 'income_category'] = 4\n",
    "f_survey.loc[f_survey.income_category == '$150,000-$199,999', 'income_category'] = 5\n",
    "f_survey.loc[f_survey.income_category == '$150,000', 'income_category'] = 5\n",
    "f_survey.loc[f_survey.income_category == '$150,000-$199,999', 'income_category'] = 6\n",
    "f_survey.loc[f_survey.income_category == '$200,000 or more', 'income_category'] = 7\n",
    "f_survey.income_category = f_survey.income_category.astype(int)\n",
    "\n",
    "# TODO: Think of a strategy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_survey.primary_job_description.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(f_survey.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def generate_ohe_features(df, feature_name):\n",
    "    ohe = OneHotEncoder()\n",
    "    ohe.fit(df[[feature_name]])\n",
    "    return pd.DataFrame(\n",
    "        ohe.transform(df[[feature_name]]).todense(), \n",
    "        columns=ohe.get_feature_names_out(),\n",
    "        index=df.index\n",
    "    ), ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_features = [\n",
    "    'gender', 'has_drivers_license', 'has_multiple_jobs', 'highest_education', \n",
    "    'primary_job_type', 'primary_job_description', 'primary_job_commute_mode'\n",
    "]\n",
    "\n",
    "for feature in ohe_features:\n",
    "    df, _ = generate_ohe_features(f_survey, feature)\n",
    "    f_survey = f_survey.merge(right=df, left_index=True, right_index=True)\n",
    "\n",
    "f_survey.drop(columns=ohe_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(f_survey.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def plot_survey_distribution(df: pd.DataFrame, feature_names: List[str]):\n",
    "    \n",
    "    n = len(feature_names)\n",
    "    \n",
    "    # No more than 4 plots in on subplot.\n",
    "    assert n <= 4, \"Only 4 features can be visualized at a time.\"\n",
    "    \n",
    "    ncols = 2\n",
    "    nrows = n//ncols if n%ncols == 0 else (n//ncols) + 1\n",
    "    \n",
    "    h_scale = 4*nrows\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(8, h_scale))\n",
    "    for ix, ax in enumerate(axes.flatten()):\n",
    "        if ix < n:\n",
    "            sns.histplot(data=df, y=feature_names[ix], ax=ax)\n",
    "        else:\n",
    "            ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_survey_distribution(\n",
    "#     f_survey, ['income_category', 'n_motor_vehicles', 'primary_job_commute_mode']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(f_survey.user_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPS Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only wish to focus on Denver data for now.\n",
    "# denver_data = r(expanded_ct.loc[\n",
    "#     (expanded_ct.start_local_dt_timezone == \"America/Denver\") & (expanded_ct.end_local_dt_timezone == \"America/Denver\"), \n",
    "#     :])\n",
    "\n",
    "denver_data = expanded_ct.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denver_data['start_fmt_time'] = pd.to_datetime(\n",
    "    denver_data['start_fmt_time'], utc=True\n",
    ").dt.tz_convert('America/Denver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(denver_data.start_fmt_time.min(), denver_data.start_fmt_time.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the datetime to Denver time.\n",
    "denver_data['start_fmt_time'] = pd.to_datetime(\n",
    "    denver_data['start_fmt_time'], utc=True\n",
    ").dt.tz_convert('America/Denver')\n",
    "\n",
    "# Re-compute all the start variables.\n",
    "# denver_data['start_local_dt_year'] = denver_data['start_fmt_time'].dt.year\n",
    "# denver_data['start_local_dt_month'] = denver_data['start_fmt_time'].dt.month\n",
    "# denver_data['start_local_dt_day'] = denver_data['start_fmt_time'].dt.day\n",
    "# denver_data['start_local_dt_hour'] = denver_data['start_fmt_time'].dt.hour\n",
    "# denver_data['start_local_dt_weekday'] = denver_data['start_fmt_time'].dt.weekday\n",
    "\n",
    "# ## Do the same with the end time.\n",
    "denver_data['end_fmt_time'] = pd.to_datetime(\n",
    "    denver_data['end_fmt_time'], utc=True\n",
    ").dt.tz_convert('America/Denver')\n",
    "\n",
    "# # Re-compute all the end variables.\n",
    "# denver_data['end_local_dt_year'] = denver_data['end_fmt_time'].dt.year\n",
    "# denver_data['end_local_dt_month'] = denver_data['end_fmt_time'].dt.month\n",
    "# denver_data['end_local_dt_day'] = denver_data['end_fmt_time'].dt.day\n",
    "# denver_data['end_local_dt_hour'] = denver_data['end_fmt_time'].dt.hour\n",
    "# denver_data['end_local_dt_weekday'] = denver_data['end_fmt_time'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the trip data with the survey data.\n",
    "\n",
    "# inner join.\n",
    "merged_data = denver_data.merge(\n",
    "    f_survey, left_on='user_id', right_on='user_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(denver_data.user_id.unique()), len(merged_data.user_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start choosing features for modeling.\n",
    "\n",
    "# base_time_features = ['fmt_time', 'local_dt_year', 'local_dt_month', 'local_dt_day', 'local_dt_hour', 'local_dt_weekday']\n",
    "# time_features = ['start_' + x for x in base_time_features] + ['end_' + x for x in base_time_features]\n",
    "\n",
    "# demographic_features = ['available_modes',\n",
    "#     'birth_year', 'income_category', 'n_motor_vehicles', 'n_residence_members', 'n_residents_u18', 'gender', \n",
    "#     'is_student', 'n_residents_with_license']\n",
    "\n",
    "# sensed_features = ['duration', 'distance_miles', 'cleaned_trip', 'start_loc', 'end_loc', 'section_modes', 'section_distances']\n",
    "\n",
    "# modeling_data = merged_data[['user_id', '_id', 'original_user_id', 'cleaned_trip', 'Replaced_mode', 'Mode_confirm'] + time_features + demographic_features + sensed_features].copy()\n",
    "modeling_data = merged_data.copy()\n",
    "\n",
    "# Rename columns in-place.\n",
    "modeling_data.rename(columns={\n",
    "    'start_local_dt_year': 'start:year', 'start_local_dt_month': 'start:month', 'start_local_dt_day': 'start:day', 'start_local_dt_hour': 'start:hour',\n",
    "    'end_local_dt_year': 'end:year', 'end_local_dt_month': 'end:month', 'end_local_dt_day': 'end:day', 'end_local_dt_hour': 'end:hour'\n",
    "    }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_overnight_trip(start_date, end_date):\n",
    "    return int((end_date - start_date).days > 0)\n",
    "\n",
    "# overnight trips may be more likely taken by car.\n",
    "modeling_data['is_overnight_trip'] = modeling_data.apply(\n",
    "    lambda x: is_overnight_trip(x.start_fmt_time, x.end_fmt_time), axis=1\n",
    ")\n",
    "\n",
    "# Number of working individuals in the household = number of individuals in the house - number of children.\n",
    "modeling_data['n_working_residents'] = (modeling_data['n_residence_members'] - modeling_data['n_residents_u18']).astype(int)\n",
    "\n",
    "# Convert the total duration of the trip into minutes.\n",
    "modeling_data[['duration']] = modeling_data[['duration']]/60\n",
    "\n",
    "# Extract start and end latitudes and longitudes.\n",
    "modeling_data['start_lat'] = modeling_data['start_loc'].apply(lambda x: x['coordinates'][1])\n",
    "modeling_data['start_lng'] = modeling_data['start_loc'].apply(lambda x: x['coordinates'][0])\n",
    "\n",
    "modeling_data['end_lat'] = modeling_data['end_loc'].apply(lambda x: x['coordinates'][1])\n",
    "modeling_data['end_lng'] = modeling_data['end_loc'].apply(lambda x: x['coordinates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from calendar import monthrange\n",
    "\n",
    "# # Find day of month: use monthrange with (mm, yyyy) args and find how many days that month had (leap years are supported).\n",
    "# def get_num_days_in_month(yyyy, mm):\n",
    "#     return monthrange(yyyy, mm)[1]\n",
    "\n",
    "# def is_overnight_trip(start_date, end_date):\n",
    "#     return int((end_date - start_date).days > 0)\n",
    "\n",
    "# # get the number of days for the start and end times.\n",
    "# modeling_data['start:n_days_in_month'] = modeling_data.apply(lambda x: get_num_days_in_month(x['start:year'], x['start:month']), axis=1)\n",
    "# modeling_data['end:n_days_in_month'] = modeling_data.apply(lambda x: get_num_days_in_month(x['end:year'], x['end:month']), axis=1)\n",
    "\n",
    "# # age = current year - year of birth\n",
    "# modeling_data['age'] = 2023 - modeling_data['birth_year']\n",
    "\n",
    "# # overnight trips may be more likely taken by car.\n",
    "# modeling_data['is_overnight_trip'] = modeling_data.apply(lambda x: is_overnight_trip(x.start_fmt_time, x.end_fmt_time), axis=1)\n",
    "\n",
    "# # Number of working individuals in the household = number of individuals in the house - number of children.\n",
    "# modeling_data['n_working_residents'] = (modeling_data['n_residence_members'] - modeling_data['n_residents_u18']).astype(int)\n",
    "\n",
    "# # Create a binary indicator.\n",
    "# modeling_data['is_male'] = modeling_data.gender.apply(lambda x: 1 if x==\"Male\" else 0)\n",
    "\n",
    "# # Bin the number of vehicles owned.\n",
    "# # Drop the observations with (Prefer not to say)\n",
    "# modeling_data = modeling_data.loc[~modeling_data['n_motor_vehicles'].isin(['Prefer not to say / Prefiero no decir.']), :]\n",
    "# modeling_data.loc[modeling_data['n_motor_vehicles'].isin(['4+']), 'n_motor_vehicles'] = 4\n",
    "# modeling_data['n_motor_vehicles'] = modeling_data['n_motor_vehicles'].astype(int)\n",
    "\n",
    "# # Convert the total duration of the trip into minutes.\n",
    "# modeling_data[['duration']] = modeling_data[['duration']]/60\n",
    "\n",
    "# # Extract start and end latitudes and longitudes.\n",
    "# modeling_data['start_lat'] = modeling_data['start_loc'].apply(lambda x: x['coordinates'][1])\n",
    "# modeling_data['start_lng'] = modeling_data['start_loc'].apply(lambda x: x['coordinates'][0])\n",
    "\n",
    "# modeling_data['end_lat'] = modeling_data['end_loc'].apply(lambda x: x['coordinates'][1])\n",
    "# modeling_data['end_lng'] = modeling_data['end_loc'].apply(lambda x: x['coordinates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Time-related feature engineeering:\n",
    "# '''\n",
    "# HOD: hour of day\n",
    "# DOM: day of month\n",
    "# MOY: month of year\n",
    "# '''\n",
    "\n",
    "# def get_HOD(hour, how='sin'):\n",
    "#     if how == 'sin':\n",
    "#         return np.sin(2 * np.pi * (hour/24))\n",
    "#     return np.cos(2 * np.pi * (hour/24))\n",
    "\n",
    "# def get_DOM(day, n_days, how='sin'):\n",
    "#     if how == 'sin':\n",
    "#         return np.sin(2 * np.pi * (day/n_days))\n",
    "#     return np.cos(2 * np.pi * (day/n_days))\n",
    "\n",
    "# def get_MOY(month, how='sin'):\n",
    "#     if how == 'sin':\n",
    "#         return np.sin(2 * np.pi * (month/12))\n",
    "#     return np.cos(2 * np.pi * (month/12))\n",
    "\n",
    "# # Start - sin\n",
    "# modeling_data['start:sin_HOD'] = modeling_data.apply(lambda x: get_HOD(x['start:hour']), axis=1)\n",
    "# modeling_data['start:sin_DOM'] = modeling_data.apply(lambda x: get_DOM(x['start:day'], x['start:n_days_in_month']), axis=1)\n",
    "# modeling_data['start:sin_MOY'] = modeling_data.apply(lambda x: get_MOY(x['start:year']), axis=1)\n",
    "\n",
    "# # Start - cos\n",
    "# modeling_data['start:cos_HOD'] = modeling_data.apply(lambda x: get_HOD(x['start:hour'], how='cos'), axis=1)\n",
    "# modeling_data['start:cos_DOM'] = modeling_data.apply(lambda x: get_DOM(x['start:day'], x['start:n_days_in_month'], how='cos'), axis=1)\n",
    "# modeling_data['start:cos_MOY'] = modeling_data.apply(lambda x: get_MOY(x['start:year'], how='cos'), axis=1)\n",
    "\n",
    "# # End - sin\n",
    "# modeling_data['end:sin_HOD'] = modeling_data.apply(lambda x: get_HOD(x['end:hour']), axis=1)\n",
    "# modeling_data['end:sin_DOM'] = modeling_data.apply(lambda x: get_DOM(x['end:day'], x['end:n_days_in_month']), axis=1)\n",
    "# modeling_data['end:sin_MOY'] = modeling_data.apply(lambda x: get_MOY(x['end:year']), axis=1)\n",
    "\n",
    "# # End - cos\n",
    "# modeling_data['end:cos_HOD'] = modeling_data.apply(lambda x: get_HOD(x['end:hour'], how='cos'), axis=1)\n",
    "# modeling_data['end:cos_DOM'] = modeling_data.apply(lambda x: get_DOM(x['end:day'], x['end:n_days_in_month'], how='cos'), axis=1)\n",
    "# modeling_data['end:cos_MOY'] = modeling_data.apply(lambda x: get_MOY(x['end:year'], how='cos'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_air_or_hsr(df):\n",
    "\n",
    "    df['mark'] = 0\n",
    "\n",
    "    for ix, row in df.iterrows():\n",
    "        sections = row['section_modes']\n",
    "        if 'air_or_hsr' in sections:\n",
    "            df.loc[ix, 'mark'] = 1\n",
    "    \n",
    "    df = r(df.loc[df.mark == 0, :])\n",
    "    df.drop(columns=['mark'], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data = remove_air_or_hsr(modeling_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(scaffolding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data = r(modeling_data.loc[:,~modeling_data.columns.duplicated()].copy())\n",
    "subset = modeling_data[['original_user_id', 'cleaned_trip']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACT_DURATIONS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes ~150 minutes if n=5.\n",
    "num_splits = 5\n",
    "samples_per_split = modeling_data.shape[0]//num_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "if EXTRACT_DURATIONS:\n",
    "\n",
    "    for split_ix in range(num_splits):\n",
    "        low = samples_per_split * split_ix\n",
    "\n",
    "        # -1 since .loc is index-inclusive.\n",
    "        high = samples_per_split * (split_ix + 1) - 1\n",
    "\n",
    "        # For last split, include last index too.\n",
    "        if split_ix < num_splits - 1:\n",
    "                split = subset.loc[low:high, :]\n",
    "        else:\n",
    "            split = subset.loc[low:, :]\n",
    "\n",
    "        print(f\"Split {split_ix} size: {split.shape[0]}\")\n",
    "\n",
    "        now = perf_counter()\n",
    "        result = scaffolding.get_section_durations(split)\n",
    "        end = perf_counter() - now\n",
    "\n",
    "        print(f\"Took {end/60} minutes to complete\")\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "        print(50*'-')\n",
    "\n",
    "    cat = pd.concat(results, axis=0)\n",
    "    \n",
    "    # This will save a LOT of time.\n",
    "    # cat.to_csv('../data/section_durations.csv', index=False)\n",
    "else:\n",
    "    cat = pd.read_csv('../data/section_durations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modeling_data.shape[0], cat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data = pd.concat([modeling_data, cat[['section_durations']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data.to_csv('../data/final_modeling_data_02142024.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab0c6e94c9422d07d42069ec9e3bb23090f5e156fc0e23cc25ca45a62375bf53"
  },
  "kernelspec": {
   "display_name": "emission",
   "language": "python",
   "name": "emission"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
