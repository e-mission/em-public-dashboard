{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b147ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import sys\n",
    "import pickle\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pathlib import Path\n",
    "from uuid import UUID\n",
    "from collections import defaultdict\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e550aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "INCLUDE_TEST_USERS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39306a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add path to your emission server here. Uncommented because the notebooks are run in the server.\n",
    "# If running locally, you need to point this to the e-mission server repo.\n",
    "# emission_path = Path(os.getcwd()).parent.parent.parent / 'my_emission_server' / 'e-mission-server'\n",
    "# sys.path.append(str(emission_path))\n",
    "\n",
    "# # Also add the home (viz_scripts) to the path\n",
    "sys.path.append('../viz_scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f673d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emission.core.get_database as edb\n",
    "import emission.storage.timeseries.abstract_timeseries as esta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e171e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_SOURCE = [\n",
    "    \"Stage_database\",            # Does NOT have composite trips BUT has section modes and distances\n",
    "    \"openpath_prod_durham\",      # Has composite trips\n",
    "    \"openpath_prod_mm_masscec\",  # Has composite trips\n",
    "    \"openpath_prod_ride2own\",    # Has composite trips\n",
    "    \"openpath_prod_uprm_nicr\"    # Has composite trips\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fa3112",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DB = DB_SOURCE[0]\n",
    "\n",
    "assert CURRENT_DB in DB_SOURCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbde79d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACED_MODE_DICT = {\n",
    "    \"Stage_database\": {\n",
    "        'no_trip': 'no_trip',\n",
    "        'no_travel': 'no_trip',\n",
    "        'Unknown': 'unknown',\n",
    "        'unknown': 'unknown',\n",
    "        'bus': 'transit',\n",
    "        'drove_alone': 'car',\n",
    "        'bike': 'p_micro',\n",
    "        'shared_ride': 's_car',\n",
    "        'walk': 'walk',\n",
    "        'train': 'transit',\n",
    "        'bikeshare': 's_micro',\n",
    "        'not_a trip': 'no_trip',\n",
    "        'pilot_ebike': 'p_micro',\n",
    "        'electric_car': 'car',\n",
    "        'taxi': 'ridehail',\n",
    "        'not_a_trip': 'no_trip',\n",
    "        'run': 'walk',\n",
    "        'scootershare': 's_micro',\n",
    "        'tramway': 'transit',\n",
    "        'free_shuttle': 'transit',\n",
    "        'e-bike': 'p_micro',\n",
    "        'rental_car': 'car',\n",
    "        'train_+ bus': 'transit',\n",
    "        'skateboard': 'p_micro',\n",
    "        'snowboarding': 'p_micro',\n",
    "        'e_bike': 'p_micro',\n",
    "        'golf_cart': 'unknown',\n",
    "        'emergency_vehicle with others': 's_car',\n",
    "        'call_friend': 's_car',\n",
    "        'no_replacement': 'no_travel',\n",
    "        'doing_nothing': 'no_trip',\n",
    "        'na': 'no_trip',\n",
    "        'ebike': 'p_micro',\n",
    "        'hiking': 'walk',\n",
    "        'n/a': 'no_trip',\n",
    "        'testing': 'unknown',\n",
    "        'home': 'no_trip',\n",
    "        'must_walk 3-5 mi a day for back': 'walk',\n",
    "        'family': 's_car',\n",
    "        'car': 'car',\n",
    "        'pilot_e-bike': 'p_micro',\n",
    "        'pilot_bike': 'p_micro',\n",
    "        'time_spent on the clock at amazon': 'no_trip',\n",
    "        'working': 'no_trip',\n",
    "        'walk_at work': 'walk',\n",
    "        'sitting_on my butt doing nothing': 'no_trip',\n",
    "        'nothing._delivered food for work': 'no_trip',\n",
    "        'train,_bus and walk': 'transit',\n",
    "        'work_vehicle': 'car',\n",
    "        'friend_picked me up': 's_car',\n",
    "        'ski': 'p_micro',\n",
    "        'not_accurate': 'unknown',\n",
    "        'stolen_ebike': 'p_micro'\n",
    "    },\n",
    "    \"openpath_prod_durham\": {\n",
    "        'Unknown': 'unknown',\n",
    "        'bike': 'p_micro',\n",
    "        'shared_ride': 's_car',\n",
    "        'drove_alone': 'car',\n",
    "        'bus': 'transit',\n",
    "        'no_travel': 'no_trip',\n",
    "        'scootershare': 's_micro',\n",
    "        'walk': 'walk',\n",
    "        'taxi': 'ridehail',\n",
    "        'e_car_drove_alone': 'car',\n",
    "        'bikeshare': 's_micro',\n",
    "        'ebike': 'p_micro',\n",
    "        'train': 'transit',\n",
    "        'e_car_shared_ride': 's_car'\n",
    "    },\n",
    "    \"openpath_prod_mm_masscec\": {\n",
    "        'Unknown': 'unknown',\n",
    "        'drove_alone': 'car',\n",
    "        'walk': 'walk',\n",
    "        'shared_ride': 's_car',\n",
    "        'bike': 'p_micro',\n",
    "        'bikeshare': 's_micro',\n",
    "        'no_travel': 'no_trip',\n",
    "        'taxi': 'ridehail',\n",
    "        'bus': 'transit',\n",
    "        'scootershare': 's_micro',\n",
    "        'train': 'transit',\n",
    "        'walking': 'walk',\n",
    "        'e_car_drove_alone': 'car'\n",
    "    },\n",
    "    \"openpath_prod_ride2own\": {\n",
    "        'Unknown': 'unknown',\n",
    "        'drove_alone': 'car',\n",
    "        'walk': 'walk',\n",
    "        'shared_ride': 's_car',\n",
    "        'bike': 'p_micro',\n",
    "        'no_travel': 'no_trip',\n",
    "        'taxi': 'ridehail',\n",
    "        'bus': 'transit',\n",
    "        'train': 'transit',\n",
    "        'e_car_drove_alone': 'car',\n",
    "        'e_car_shared_ride': 's_car'\n",
    "    },\n",
    "    \"openpath_prod_uprm_nicr\": {\n",
    "        'Unknown': 'unknown',\n",
    "        'walk': 'walk',\n",
    "        'drove_alone': 'car'\n",
    "    }\n",
    "}\n",
    "\n",
    "SURVEY_DATA_DICT = {\n",
    "    \"Stage_database\": {\n",
    "        \"Unique User ID (auto-filled, do not edit)\": \"user_id\",\n",
    "        \"In which year were you born?\": \"birth_year\",\n",
    "        \"What is your gender?\": \"gender\",\n",
    "        \"Do you have a valid driver's license?\": \"has_drivers_license\",\n",
    "        \"Are you a student?\": \"is_student\",\n",
    "        \"What is the highest grade or degree that you have completed?\": \"highest_education\",\n",
    "        \"Do you work for either pay or profit?\": \"is_paid\",\n",
    "        \"Do you have more than one job?\": \"has_multiple_jobs\",\n",
    "        \"Do you work full-time or part-time at your primary job?\": \"primary_job_type\",\n",
    "        \"Which best describes your primary job?\": \"primary_job_description\",\n",
    "        \"How did you usually get to your primary job last week? \": \"primary_job_commute_mode\",\n",
    "        \"Thinking about your daily commute to work last week, how many minutes did it usually take to get from home to the primary job/work place?\": \"primary_job_commute_time\",\n",
    "        \"At your primary job, do you have the ability to set or change your own start time?\": \"is_primary_job_flexible\",\n",
    "        \"Do you have the option of working from home or an alternate location instead of going into your primary work place?\": \"primary_job_can_wfh\",\n",
    "        \"How many days per week do you usually work from home or an alternate location?\": \"wfh_days\",\n",
    "        \"Do you own or rent your place of residence?\": \"residence_ownership_type\",\n",
    "        \"What is your home type?\": \"residence_type\",\n",
    "        \"Please identify which category represents your total household income, before taxes, for last year.\": \"income_category\",\n",
    "        \"Including yourself, how many people live in your home?\": \"n_residence_members\",\n",
    "        \"How many children under age 18 live in your home?\": \"n_residents_u18\",\n",
    "        \"Including yourself, how many people have a driver's license in your household?\": \"n_residents_with_license\",\n",
    "        \"How many motor vehicles are owned, leased, or available for regular use by the people who currently live in your household?\": \"n_motor_vehicles\",\n",
    "        \"If you were unable to use your household vehicle(s), which of the following options would be available to you to get you from place to place?\": \"available_modes\",\n",
    "        \"Do you have a medical condition that makes it difficult to travel outside of the home?\": \"has_medical_condition\",\n",
    "        \"How long have you had this condition?\": \"medical_condition_duration\"\n",
    "    },\n",
    "    # Retrieved from: e-mission-phone/survey-resources/data-xls/demo-survey-v1.xlsx\n",
    "    \"openpath_prod_durham\": {\n",
    "        \"At_your_primary_job_do_you_ha\": \"is_primary_job_flexible\",\n",
    "        \"Which_best_describes_your_prim\": \"primary_job_description\",\n",
    "        \"Do_you_work_full_time_or_part_\": \"primary_job_type\",\n",
    "        \"Do_you_have_the_option_of_work\": \"primary_job_can_wfh\",\n",
    "        \"Please_describe_your_primary_job\": \"primary_job_description_2\",\n",
    "        \"Do_you_have_more_than_one_job\": \"has_multiple_jobs\",\n",
    "        # Two columns: how many days/week do you work & what days of the week do you work. \n",
    "        # the latter has only 4 NA values, the former has 45 NA values.\n",
    "        \"What_days_of_the_week_do_you_t\": \"wfh_days\",\n",
    "        \"How_many_days_do_you_usually_w_001\": \"n_wfh_days\",\n",
    "        # All these are NAs.\n",
    "        \"Which_one_below_describe_you_b\": \"description\",\n",
    "        \"What_is_your_race_ethnicity\": \"race_or_ethnicity\",\n",
    "        \"Are_you_a_student\": \"is_student\",\n",
    "        \"What_is_the_highest_grade_or_d\": \"highest_education\",\n",
    "        \"do_you_consider_yourself_to_be\": \"is_transgender\",\n",
    "        \"What_is_your_gender\": \"gender\",\n",
    "        \"How_old_are_you\": \"age\",\n",
    "        \"Are_you_a_paid_worker\": \"is_paid\",\n",
    "        \"Do_you_have_a_driver_license\": \"has_drivers_license\",\n",
    "        \"How_long_you_had_this_conditio\": \"medical_condition_duration\",\n",
    "        \"Including_yourself_how_many_w_001\": \"n_residents_u18\",\n",
    "        \"Including_yourself_how_many_p\": \"n_residence_members\",\n",
    "        \"Do_you_own_or_rent_your_home\": \"residence_ownership_type\",\n",
    "        \"Please_identify_which_category\": \"income_category\",\n",
    "        \"If_you_were_unable_to_use_your\": \"available_modes\",\n",
    "        \"Including_yourself_how_many_p_001\": \"n_residents_with_license\",\n",
    "        \"Including_yourself_how_many_w\": \"n_working_residents\",\n",
    "        \"What_is_your_home_type\": \"residence_type\",\n",
    "        \"How_many_motor_vehicles_are_ow\": \"n_motor_vehicles\",\n",
    "        \"Do_you_have_a_condition_or_han\": \"has_medical_condition\"\n",
    "    },\n",
    "    \"openpath_prod_mm_masscec\": {\n",
    "        # Same questions as Durham.\n",
    "        \"At_your_primary_job_do_you_ha\": \"is_primary_job_flexible\",\n",
    "        \"Which_best_describes_your_prim\": \"primary_job_description\",\n",
    "        \"Do_you_work_full_time_or_part_\": \"primary_job_type\",\n",
    "        \"Do_you_have_the_option_of_work\": \"primary_job_can_wfh\",\n",
    "        \"Please_describe_your_primary_job\": \"primary_job_description_2\",\n",
    "        \"Do_you_have_more_than_one_job\": \"has_multiple_jobs\",\n",
    "        # Two columns: how many days/week do you work & what days of the week do you work. \n",
    "        # the latter has only 4 NA values, the former has 45 NA values.\n",
    "        \"What_days_of_the_week_do_you_t\": \"wfh_days\",\n",
    "        \"How_many_days_do_you_usually_w_001\": \"n_wfh_days\",\n",
    "        # All these are NAs.\n",
    "        \"Which_one_below_describe_you_b\": \"description\",\n",
    "        \"What_is_your_race_ethnicity\": \"race_or_ethnicity\",\n",
    "        \"Are_you_a_student\": \"is_student\",\n",
    "        \"What_is_the_highest_grade_or_d\": \"highest_education\",\n",
    "        \"do_you_consider_yourself_to_be\": \"is_transgender\",\n",
    "        \"What_is_your_gender\": \"gender\",\n",
    "        \"How_old_are_you\": \"age\",\n",
    "        \"Are_you_a_paid_worker\": \"is_paid\",\n",
    "        \"Do_you_have_a_driver_license\": \"has_drivers_license\",\n",
    "        \"How_long_you_had_this_conditio\": \"medical_condition_duration\",\n",
    "        \"Including_yourself_how_many_w_001\": \"n_residents_u18\",\n",
    "        \"Including_yourself_how_many_p\": \"n_residence_members\",\n",
    "        \"Do_you_own_or_rent_your_home\": \"residence_ownership_type\",\n",
    "        \"Please_identify_which_category\": \"income_category\",\n",
    "        \"If_you_were_unable_to_use_your\": \"available_modes\",\n",
    "        \"Including_yourself_how_many_p_001\": \"n_residents_with_license\",\n",
    "        \"Including_yourself_how_many_w\": \"n_working_residents\",\n",
    "        \"What_is_your_home_type\": \"residence_type\",\n",
    "        \"How_many_motor_vehicles_are_ow\": \"n_motor_vehicles\",\n",
    "        \"Do_you_have_a_condition_or_han\": \"has_medical_condition\"\n",
    "    },\n",
    "    \"openpath_prod_ride2own\": {\n",
    "        # Same questions as Durham.\n",
    "        \"How_old_are_you\": \"age\",\n",
    "        \"What_is_your_gender\": \"gender\",\n",
    "        \"do_you_consider_yourself_to_be\": \"is_transgender\",\n",
    "        \"What_is_your_race_ethnicity\": \"race_or_ethnicity\",\n",
    "        \"Do_you_have_a_driver_license\": \"has_drivers_license\",\n",
    "        \"Are_you_a_student\": \"is_student\",\n",
    "        \"What_is_the_highest_grade_or_d\": \"highest_education\",\n",
    "        \"Are_you_a_paid_worker\": \"is_paid\",\n",
    "        \"Which_one_below_describe_you_b\": \"description\",\n",
    "        \"Do_you_own_or_rent_your_home\": \"residence_ownership_type\",\n",
    "        \"What_is_your_home_type\": \"residence_type\",\n",
    "        \"Please_identify_which_category\": \"income_category\",\n",
    "        \"Including_yourself_how_many_p\": \"n_residence_members\",\n",
    "        \"Including_yourself_how_many_w\": \"n_working_residents\",\n",
    "        \"Including_yourself_how_many_p_001\": \"n_residents_with_license\",\n",
    "        \"Including_yourself_how_many_w_001\": \"n_residents_u18\",\n",
    "        \"How_many_motor_vehicles_are_ow\": \"n_motor_vehicles\",\n",
    "        \"If_you_were_unable_to_use_your\": \"available_modes\",\n",
    "        \"Do_you_have_a_condition_or_han\": \"has_medical_condition\",\n",
    "        \"How_long_you_had_this_conditio\": \"medical_condition_duration\",\n",
    "        \"Do_you_have_more_than_one_job\": \"has_multiple_jobs\",\n",
    "        \"Do_you_work_full_time_or_part_\": \"primary_job_type\",\n",
    "        \"Which_best_describes_your_prim\": \"primary_job_description\",\n",
    "        \"Please_describe_your_primary_job\": \"primary_job_description_2\",\n",
    "        \"At_your_primary_job_do_you_ha\": \"is_primary_job_flexible\",\n",
    "        \"Do_you_have_the_option_of_work\": \"primary_job_can_wfh\",\n",
    "        \"How_many_days_do_you_usually_w_001\": \"n_wfh_days\",\n",
    "        \"What_days_of_the_week_do_you_t\": \"wfh_days\"\n",
    "    },\n",
    "    \"openpath_prod_uprm_nicr\": {\n",
    "        # Same as Durham!\n",
    "        \"At_your_primary_job_do_you_ha\": \"is_primary_job_flexible\",\n",
    "        \"Which_best_describes_your_prim\": \"primary_job_description\",\n",
    "        \"Do_you_work_full_time_or_part_\": \"primary_job_type\",\n",
    "        \"Do_you_have_the_option_of_work\": \"primary_job_can_wfh\",\n",
    "        \"Please_describe_your_primary_job\": \"primary_job_description_2\",\n",
    "        \"Do_you_have_more_than_one_job\": \"has_multiple_jobs\",\n",
    "        # Two columns: how many days/week do you work & what days of the week do you work. \n",
    "        # the latter has only 4 NA values, the former has 45 NA values.\n",
    "        \"What_days_of_the_week_do_you_t\": \"wfh_days\",\n",
    "        \"How_many_days_do_you_usually_w_001\": \"n_wfh_days\",\n",
    "        # All these are NAs.\n",
    "        \"Which_one_below_describe_you_b\": \"description\",\n",
    "        \"What_is_your_race_ethnicity\": \"race_or_ethnicity\",\n",
    "        \"Are_you_a_student\": \"is_student\",\n",
    "        \"What_is_the_highest_grade_or_d\": \"highest_education\",\n",
    "        \"do_you_consider_yourself_to_be\": \"is_transgender\",\n",
    "        \"What_is_your_gender\": \"gender\",\n",
    "        \"How_old_are_you\": \"age\",\n",
    "        \"Are_you_a_paid_worker\": \"is_paid\",\n",
    "        \"Do_you_have_a_driver_license\": \"has_drivers_license\",\n",
    "        \"How_long_you_had_this_conditio\": \"medical_condition_duration\",\n",
    "        \"Including_yourself_how_many_w_001\": \"n_residents_u18\",\n",
    "        \"Including_yourself_how_many_p\": \"n_residence_members\",\n",
    "        \"Do_you_own_or_rent_your_home\": \"residence_ownership_type\",\n",
    "        \"Please_identify_which_category\": \"income_category\",\n",
    "        \"If_you_were_unable_to_use_your\": \"available_modes\",\n",
    "        \"Including_yourself_how_many_p_001\": \"n_residents_with_license\",\n",
    "        \"Including_yourself_how_many_w\": \"n_working_residents\",\n",
    "        \"What_is_your_home_type\": \"residence_type\",\n",
    "        \"How_many_motor_vehicles_are_ow\": \"n_motor_vehicles\",\n",
    "        \"Do_you_have_a_condition_or_han\": \"has_medical_condition\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69008893",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Source: db_utils.py in op-admin-dashboard.\n",
    "\n",
    "BINARY_DEMOGRAPHICS_COLS = [\n",
    "    'user_id',\n",
    "    '_id',\n",
    "]\n",
    "\n",
    "EXCLUDED_DEMOGRAPHICS_COLS = [\n",
    "    'data.xmlResponse', \n",
    "    'data.name',\n",
    "    'data.version',\n",
    "    'data.label',\n",
    "    'xmlns:jr',\n",
    "    'xmlns:orx',\n",
    "    'id',\n",
    "    'start',\n",
    "    'end',\n",
    "    'attrxmlns:jr',\n",
    "    'attrxmlns:orx',\n",
    "    'attrid',\n",
    "    '__version__',\n",
    "    'attrversion',\n",
    "    'instanceID',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cc0c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Source: scaffolding.py\n",
    "\n",
    "def expand_userinputs(labeled_ct):\n",
    "    '''\n",
    "    param: labeled_ct: a dataframe of confirmed trips, some of which have labels\n",
    "    params: labels_per_trip: the number of labels for each trip.\n",
    "        Currently, this is 2 for studies and 3 for programs, and should be \n",
    "        passed in by the notebook based on the input config.\n",
    "        If used with a trip-level survey, it could be even larger.\n",
    "    '''\n",
    "    # CASE 1 of https://github.com/e-mission/em-public-dashboard/issues/69#issuecomment-1256835867\n",
    "    if len(labeled_ct) == 0:\n",
    "        return labeled_ct\n",
    "    label_only = pd.DataFrame(labeled_ct.user_input.to_list(), index=labeled_ct.index)\n",
    "    # disp.display(label_only.head())\n",
    "    labels_per_trip = len(label_only.columns)\n",
    "    print(\"Found %s columns of length %d\" % (label_only.columns, labels_per_trip))\n",
    "    expanded_ct = pd.concat([labeled_ct, label_only], axis=1)\n",
    "    assert len(expanded_ct) == len(labeled_ct), \\\n",
    "        (\"Mismatch after expanding labels, expanded_ct.rows = %s != labeled_ct.rows %s\" %\n",
    "            (len(expanded_ct), len(labeled_ct)))\n",
    "    print(\"After expanding, columns went from %s -> %s\" %\n",
    "        (len(labeled_ct.columns), len(expanded_ct.columns)))\n",
    "    assert len(expanded_ct.columns) == len(labeled_ct.columns) + labels_per_trip, \\\n",
    "        (\"Mismatch after expanding labels, expanded_ct.columns = %s != labeled_ct.columns %s\" %\n",
    "            (len(expanded_ct.columns), len(labeled_ct.columns)))\n",
    "    # disp.display(expanded_ct.head())\n",
    "    return expanded_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a98e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Source: scaffolding.py\n",
    "\n",
    "def data_quality_check(expanded_ct):\n",
    "    '''1. Delete rows where the mode_confirm was pilot_ebike and repalced_mode was pilot_ebike.\n",
    "       2. Delete rows where the mode_confirm was pilot_ebike and repalced_mode was same_mode.\n",
    "       3. Replace same_mode for the mode_confirm for Energy Impact Calcualtion.'''\n",
    "\n",
    "    # TODO: This is only really required for the initial data collection around the minipilot\n",
    "    # in subsequent deployes, we removed \"same mode\" and \"pilot_ebike\" from the options, so the\n",
    "    # dataset did not contain of these data quality issues\n",
    "\n",
    "    if 'replaced_mode' in expanded_ct.columns:\n",
    "        expanded_ct.drop(expanded_ct[(expanded_ct['mode_confirm'] == 'pilot_ebike') & (expanded_ct['replaced_mode'] == 'pilot_ebike')].index, inplace=True)\n",
    "        expanded_ct.drop(expanded_ct[(expanded_ct['mode_confirm'] == 'pilot_ebike') & (expanded_ct['replaced_mode'] == 'same_mode')].index, inplace=True)\n",
    "        expanded_ct['replaced_mode'] = np.where(expanded_ct['replaced_mode'] == 'same_mode',expanded_ct['mode_confirm'], expanded_ct['replaced_mode'])\n",
    "    \n",
    "    return expanded_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe37bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Source: scaffolding.py\n",
    "\n",
    "uuid_df = pd.json_normalize(list(edb.get_uuid_db().find()))\n",
    "\n",
    "if not INCLUDE_TEST_USERS:\n",
    "    uuid_df = uuid_df.loc[~uuid_df.user_email.str.contains('_test_'), :]\n",
    "\n",
    "filtered = uuid_df.uuid.unique()\n",
    "\n",
    "agg = esta.TimeSeries.get_aggregate_time_series()\n",
    "all_ct = agg.get_data_df(\"analysis/confirmed_trip\", None)\n",
    "\n",
    "print(f\"Before filtering, length={len(all_ct)}\")\n",
    "participant_ct_df = all_ct.loc[all_ct.user_id.isin(filtered), :]\n",
    "print(f\"After filtering, length={len(participant_ct_df)}\")\n",
    "\n",
    "expanded_ct = expand_userinputs(participant_ct_df)\n",
    "expanded_ct = data_quality_check(expanded_ct)\n",
    "print(expanded_ct.columns.tolist())\n",
    "expanded_ct['replaced_mode'] = expanded_ct['replaced_mode'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13536d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Additional preprocessing for replaced mode (if any)\n",
    "\n",
    "mode_counts = expanded_ct['replaced_mode'].value_counts()\n",
    "drop_modes = mode_counts[mode_counts == 1].index.tolist()\n",
    "\n",
    "expanded_ct.drop(\n",
    "    index=expanded_ct.loc[expanded_ct.replaced_mode.isin(drop_modes)].index,\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Additional modes to drop.\n",
    "expanded_ct.drop(\n",
    "    index=expanded_ct.loc[expanded_ct.replaced_mode.isin(\n",
    "        # Remove all rows with air, boat, or weird answers.\n",
    "        ['houseboat', 'gondola', 'airline_flight', 'aircraft', 'zoo', 'air',\n",
    "         'airplane', 'boat', 'flight', 'plane', 'meal', 'lunch']\n",
    "    )].index,\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "expanded_ct.replaced_mode = expanded_ct.replaced_mode.apply(lambda x: REPLACED_MODE_DICT[CURRENT_DB][x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258844f4",
   "metadata": {},
   "source": [
    "# Demographic pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7461a4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographics\n",
    "\n",
    "if CURRENT_DB != \"Stage_database\":\n",
    "\n",
    "    decoded_uuids = [str(x) for x in filtered]\n",
    "\n",
    "    ## Source: query_demographics() in op-admin-dashboard.\n",
    "    ts = esta.TimeSeries.get_aggregate_time_series()\n",
    "    entries = list(ts.find_entries([\"manual/demographic_survey\"]))\n",
    "\n",
    "    available_key = {}\n",
    "    for entry in entries:\n",
    "        survey_key = list(entry['data']['jsonDocResponse'].keys())[0]\n",
    "        if survey_key not in available_key:\n",
    "            available_key[survey_key] = []\n",
    "\n",
    "        # Minor modification: Added user_id check to filter users.\n",
    "        if str(entry['user_id']) in decoded_uuids:\n",
    "            available_key[survey_key].append(entry)\n",
    "\n",
    "    dataframes = {}\n",
    "    for key, json_object in available_key.items():\n",
    "        df = pd.json_normalize(json_object)\n",
    "        dataframes[key] = df\n",
    "\n",
    "    for key, df in dataframes.items():\n",
    "        if not df.empty:\n",
    "            for col in BINARY_DEMOGRAPHICS_COLS:\n",
    "                if col in df.columns:\n",
    "                    df[col] = df[col].apply(str) \n",
    "            columns_to_drop = [col for col in df.columns if col.startswith(\"metadata\")]\n",
    "            df.drop(columns= columns_to_drop, inplace=True) \n",
    "            df.columns=[col.rsplit('.',1)[-1] if col.startswith('data.jsonDocResponse.') else col for col in df.columns]\n",
    "            for col in EXCLUDED_DEMOGRAPHICS_COLS:\n",
    "                if col in df.columns:\n",
    "                    df.drop(columns= [col], inplace=True)\n",
    "\n",
    "    survey_data = pd.DataFrame()                \n",
    "    for v in dataframes.values():\n",
    "        survey_data = pd.concat([survey_data, v], axis=0, ignore_index=True)\n",
    "else:\n",
    "    # Read the demographics.\n",
    "    # Ensure that you have access to this survey file and that it is placed in the given destination.\n",
    "    survey_data = pd.read_csv('../viz_scripts/Can Do Colorado eBike Program - en.csv')\n",
    "    survey_data.rename(columns={'Unique User ID (auto-filled, do not edit)': 'user_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07922a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_section_durations(confirmed_trips: pd.DataFrame):\n",
    "    \n",
    "    import pandarallel\n",
    "\n",
    "    # Initialize the parallel processing.\n",
    "    pandarallel.initialize(progress_bar=False)\n",
    "\n",
    "    \"\"\"\n",
    "    Extract section-wise durations from trips for every trips.\n",
    "    \"\"\"\n",
    "\n",
    "    # the inner function has access to these variables.\n",
    "    primary_key = 'analysis/inferred_section'\n",
    "    fallback_key = 'analysis/cleaned_section'\n",
    "\n",
    "    def get_durations(user_id, trip_id):\n",
    "\n",
    "        inferred_sections = esdt.get_sections_for_trip(key = primary_key,\n",
    "            user_id = user_id, trip_id = trip_id)\n",
    "\n",
    "        if inferred_sections and len(inferred_sections) > 0:\n",
    "            return [x.data.duration for x in inferred_sections]\n",
    "        \n",
    "        print(\"Falling back to confirmed trips...\")\n",
    "\n",
    "        cleaned_sections = esdt.get_sections_for_trip(key = fallback_key,\n",
    "            user_id = user_id, trip_id = trip_id)\n",
    "    \n",
    "        if cleaned_sections and len(cleaned_sections) > 0:\n",
    "            return [x.data.duration for x in cleaned_sections]\n",
    "\n",
    "        return []\n",
    "\n",
    "    confirmed_trips['section_durations'] = confirmed_trips.parallel_apply(\n",
    "        lambda x: get_durations(x.user_id, x.cleaned_trip), axis=1\n",
    "    )\n",
    "\n",
    "    return confirmed_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5a9dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CURRENT_DB == \"Stage_database\":\n",
    "    \n",
    "    if os.path.exists('./data/cached_allceo_data.csv'):\n",
    "        \n",
    "        # Replace current instance of dataframe with the cached dataframe.\n",
    "        expanded_ct = pd.read_csv('./data/cached_allceo_data.csv')\n",
    "        expanded_ct.loc[expanded_ct.replaced_mode == 'no_travel', 'replaced_mode'] = 'no_trip'\n",
    "    else:\n",
    "        ## NOTE: Run this cell only if the cached CSV is not already available. It will take a LOT of time.\n",
    "        ## Benchmark timing: ~12 hours on a MacBook Pro (2017 model) with pandarallel, 4 workers.\n",
    "        expanded_ct = get_section_durations(expanded_ct)\n",
    "        expanded_ct.to_csv('./data/cached_allceo_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(survey_data.user_id.unique()), len(expanded_ct.user_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebc87d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data.rename(SURVEY_DATA_DICT[CURRENT_DB], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522b1362",
   "metadata": {},
   "source": [
    "### Demographic data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bc7996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gtg\n",
    "survey_data['ft_job'] = survey_data.primary_job_type.apply(\n",
    "    lambda x: 1 if str(x).lower() == 'full_time' else 0\n",
    ")\n",
    "\n",
    "# gtg\n",
    "survey_data['multiple_jobs'] = survey_data.has_multiple_jobs.apply(\n",
    "    lambda x: 1 if str(x).lower() == 'yes' else 0\n",
    ")\n",
    "\n",
    "# gtg\n",
    "survey_data.loc[\n",
    "    survey_data.n_motor_vehicles.isin(\n",
    "        ['prefer_not_to_say', 'Prefer not to say / Prefiero no decir.']\n",
    "    ), 'n_motor_vehicles'] = 0\n",
    "\n",
    "survey_data.loc[survey_data.n_motor_vehicles.isin(\n",
    "    ['more_than_3', '4+', 'more_than_4', 'more_than_3']\n",
    "), 'n_motor_vehicles'] = 4\n",
    "survey_data.n_motor_vehicles = survey_data.n_motor_vehicles.astype(int)\n",
    "\n",
    "# gtg\n",
    "survey_data.has_drivers_license = survey_data.has_drivers_license.apply(\n",
    "    lambda x: 1 if str(x).lower() == 'yes' else 0\n",
    ")\n",
    "\n",
    "survey_data.loc[survey_data.n_residents_u18 == 'prefer_not_to_say', 'n_residents_u18'] = 0\n",
    "survey_data.n_residents_u18 = survey_data.n_residents_u18.astype(int)\n",
    "\n",
    "survey_data.loc[survey_data.n_residence_members == 'prefer_not_to_say', 'n_residence_members'] = 0\n",
    "survey_data.n_residence_members = survey_data.n_residence_members.astype(int)\n",
    "\n",
    "survey_data.loc[survey_data.n_residents_with_license == 'prefer_not_to_say'] = 0\n",
    "survey_data.loc[survey_data.n_residents_with_license == 'more_than_4', 'n_residents_with_license'] = 4\n",
    "survey_data.n_residents_with_license = survey_data.n_residents_with_license.astype(int)\n",
    "\n",
    "# Handle abnormal inputs.\n",
    "survey_data = survey_data[\n",
    "     (survey_data.n_residence_members - survey_data.n_residents_with_license >= 0) &\n",
    "    (survey_data.n_residence_members - survey_data.n_residents_u18 >= 0)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# gtg\n",
    "if CURRENT_DB != \"Stage_database\":\n",
    "    survey_data.n_working_residents = survey_data.n_working_residents.apply(\n",
    "        lambda x: 0 if x == 'prefer_not_to_say' else int(x)\n",
    "    )\n",
    "else:\n",
    "    survey_data['n_working_residents'] = survey_data['n_residence_members'] - survey_data['n_residents_u18']\n",
    "    \n",
    "survey_data = survey_data[survey_data.n_working_residents >= 0].reset_index(drop=True)\n",
    "\n",
    "# gtg\n",
    "survey_data.is_paid = survey_data.is_paid.apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "# gtg\n",
    "survey_data.has_medical_condition = survey_data.has_medical_condition.apply(\n",
    "    lambda x: 1 if str(x).lower() == 'yes' else 0\n",
    ")\n",
    "\n",
    "## gtg\n",
    "survey_data.is_student.replace({\n",
    "    'Not a student': 0, \n",
    "    'Yes - Full Time College/University': 1,\n",
    "    'Yes - Vocation/Technical/Trade School': 1,\n",
    "    'Yes - K-12th Grade including GED': 1, \n",
    "    'Work': 0, \n",
    "    'No': 0,\n",
    "    'Prefer not to say': 0,\n",
    "    'Yes - Part-Time College/University': 1,\n",
    "    'Taking prerequisites missing for grad program ': 1, \n",
    "    'Graduate': 1,\n",
    "    'Custodian': 0, \n",
    "    'Work at csu': 0,\n",
    "    'not_a_student': 0, \n",
    "    'yes___vocation_technical_trade_school': 1,\n",
    "    'yes___part_time_college_university': 1,\n",
    "    'prefer_not_to_say': 0, \n",
    "    'yes___k_12th_grade_including_ged': 1,\n",
    "    'yes___full_time_college_university': 1\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb85637",
   "metadata": {},
   "source": [
    "### Additinal Demographic Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c069bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CURRENT_DB == \"Stage_database\":\n",
    "    age = survey_data.birth_year.apply(\n",
    "        lambda x: 2024 - int(x) if int(x) > 100 else int(x)\n",
    "    )\n",
    "    \n",
    "    upper = age - (age % 5)\n",
    "    lower = upper + 5\n",
    "    new_col = (upper + 1).astype(str) + '___' + lower.astype(str) + '_years_old'\n",
    "    survey_data['age'] = new_col\n",
    "    \n",
    "    survey_data.loc[survey_data.age.isin([\n",
    "        '66___70_years_old', '76___80_years_old', '81___85_years_old'\n",
    "    ]), 'age'] = '__65_years_old'\n",
    "    \n",
    "    survey_data.drop(columns=['birth_year'], inplace=True)\n",
    "\n",
    "else:\n",
    "    survey_data = survey_data[survey_data.age != 0].reset_index(drop=True)\n",
    "\n",
    "if survey_data.columns.isin(['primary_job_commute_mode', 'primary_job_commute_time']).all():\n",
    "    survey_data.drop(columns=['primary_job_commute_mode', 'primary_job_commute_time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f094cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_job_descriptions(db_name, df):\n",
    "    if db_name != 'Stage_database':\n",
    "        PRIMARY_JOB_DESCRIPTION_DICT = {\n",
    "            \"sales_or_service\": \"Sales or service\",\n",
    "            \"other\": \"Other\",\n",
    "            \"\": \"Other\",\n",
    "            \"professional__managerial__or_technical\": \"Professional, Manegerial, or Technical\",\n",
    "            \"manufacturing__construction__maintenance\": \"Manufacturing, construction, maintenance, or farming\",\n",
    "            \"clerical_or_administrative_support\": \"Clerical or administrative support\",\n",
    "            \"prefer_not_to_say\": \"Prefer not to say\"\n",
    "        }\n",
    "        \n",
    "        df.primary_job_description = df.primary_job_description.apply(\n",
    "            lambda x: PRIMARY_JOB_DESCRIPTION_DICT[x]\n",
    "        )\n",
    "    else:\n",
    "        df.primary_job_description = df.primary_job_description.str.strip()\n",
    "\n",
    "        # Normalize the job description. Inspired from the 'e-bike trips by occupation' \n",
    "        # plot in the CanBikeCo full pilot paper.\n",
    "        df.loc[\n",
    "            df.primary_job_description.isin([\n",
    "                'Paraprofessional', 'Education', 'education/early childhood', 'Teacher',\n",
    "                'Education non-profit manager', 'Scientific research', 'Research',\n",
    "                'Preschool Tracher'\n",
    "            ]), 'primary_job_description'\n",
    "        ] = 'Education'\n",
    "\n",
    "        df.loc[\n",
    "            df.primary_job_description.isin([\n",
    "                'Custodian', 'Custodial', 'Csu custodian', 'Janitorial',\n",
    "                'Custodial Maintanace'\n",
    "            ]), 'primary_job_description'\n",
    "        ] = 'Custodial'\n",
    "\n",
    "        df.loc[\n",
    "            df.primary_job_description.isin([\n",
    "                'Inbound cs', 'Accounting Technician', \n",
    "                'Clerical'\n",
    "            ]), 'primary_job_description'\n",
    "        ] = 'Clerical or administrative support'\n",
    "\n",
    "        df.loc[\n",
    "            df.primary_job_description.isin([\n",
    "                'Restaurant manager', 'Transportaion Services',\n",
    "            ]), 'primary_job_description'\n",
    "        ] = 'Sales or service'\n",
    "\n",
    "        df.loc[\n",
    "            df.primary_job_description.isin([\n",
    "                'Pastry chef and line cook', 'Cook', 'Chef', 'Dining Services',\n",
    "                'Food Service', 'Cooking', 'Residential Dining Services', 'Line Cook'\n",
    "            ]), 'primary_job_description'\n",
    "        ] = 'Food service'\n",
    "\n",
    "        df.loc[\n",
    "            df.primary_job_description.isin([\n",
    "                'CNA', 'Caregiver/ Qmap', 'Health care', 'Nurse',\n",
    "                'Healthcare', 'Medical', 'Medical field',\n",
    "                'Family support'\n",
    "            ]), 'primary_job_description'\n",
    "        ] = 'Medical/healthcare'\n",
    "\n",
    "        df.loc[\n",
    "            df.primary_job_description.isin([\n",
    "                'Amazon', 'Hockey rink', 'Caregiver', 'Security', 'Nonprofit social work',\n",
    "                'Therapeutic', 'Driver'\n",
    "            ]), 'primary_job_description'\n",
    "        ] = 'Other'\n",
    "\n",
    "        df.loc[\n",
    "            df.primary_job_description.isin([\n",
    "                'Hospital laundry', 'Matreal handler', 'Maintenance',\n",
    "                'Co op laundry'\n",
    "            ]), 'primary_job_description'\n",
    "        ] = 'Manufacturing, construction, maintenance, or farming'\n",
    "\n",
    "        df.loc[df.primary_job_description.isna(), 'primary_job_description'] = 'Other'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf37859",
   "metadata": {},
   "outputs": [],
   "source": [
    "INCOME_DICT = {\n",
    "    'Stage_database': {\n",
    "        'Prefer not to say': 0,\n",
    "        'Less than $24,999': 1,\n",
    "        '$25,000-$49,999': 2,\n",
    "        '$50,000-$99,999': 3,\n",
    "        '$100,000 -$149,999': 4,\n",
    "        '$150,000-$199,999': 5,\n",
    "        '$150,000': 5,\n",
    "        '$150,000-$199,999': 6,\n",
    "        '$200,000 or more': 7\n",
    "    },\n",
    "    'Others': {\n",
    "        'prefer_not_to_say': 0, \n",
    "        'less_than__24_999': 1,\n",
    "        '_25_000_to__49_999': 2,\n",
    "        '_50_000_to__99_999': 3,\n",
    "        '_100_000_to__149_999': 4,\n",
    "        '_150_000_to__199_999': 5\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b3163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data = normalize_job_descriptions(CURRENT_DB, survey_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b18b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CURRENT_DB == 'Stage_database':\n",
    "    survey_data.income_category = survey_data.income_category.apply(\n",
    "        lambda x: INCOME_DICT['Stage_database'][x]\n",
    "    )\n",
    "else:\n",
    "    survey_data.income_category = survey_data.income_category.apply(\n",
    "        lambda x: INCOME_DICT['Others'][x]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36672b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def generate_ohe_features(df, feature_name):\n",
    "    ohe = OneHotEncoder()\n",
    "    ohe.fit(df[[feature_name]])\n",
    "    return pd.DataFrame(\n",
    "        ohe.transform(df[[feature_name]]).todense(), \n",
    "        columns=ohe.get_feature_names_out(),\n",
    "        index=df.index\n",
    "    ), ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8d1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ohe_features = ['highest_education', 'primary_job_description', 'gender', 'age']\n",
    "\n",
    "for ohe in ohe_features:\n",
    "    df, _ = generate_ohe_features(survey_data, ohe)\n",
    "    survey_data = survey_data.merge(right=df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d6f8c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_drop = [\n",
    "    'Timestamp', 'gender', 'highest_education', 'primary_job_type', 'primary_job_description', \n",
    "    'primary_job_commute_mode', 'primary_job_commute_time', 'is_primary_job_flexible', \n",
    "    'primary_job_can_wfh', 'wfh_days', 'Which one below describe you best?', 'residence_ownership_type', \n",
    "    'residence_type', 'medical_condition_duration', 'has_multiple_jobs', 'age', '_id', 'data.ts',\n",
    "    'primary_job_description_2', 'wfh_days', 'n_wfh_days', 'description', 'race_or_ethnicity', \n",
    "    'highest_education', 'is_transgender', 'medical_condition_duration'\n",
    "]\n",
    "\n",
    "for column in to_drop:\n",
    "    if column in survey_data.columns:\n",
    "        survey_data.drop(columns=[column], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65039f73",
   "metadata": {},
   "source": [
    "## Merge sensed data and demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb2e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional preprocessing to filter unwanted users from sensed trips data.\n",
    "expanded_ct['user_id_join'] = expanded_ct['user_id'].apply(lambda x: str(x).replace('-', ''))\n",
    "survey_data['user_id_join'] = survey_data['user_id'].apply(lambda x: str(x).replace('-', ''))\n",
    "\n",
    "survey_data.rename(columns={'user_id': 'survey_user_id'}, inplace=True)\n",
    "\n",
    "common = set(expanded_ct.user_id_join.unique()).intersection(\n",
    "    set(survey_data.user_id_join.unique())\n",
    ")\n",
    "\n",
    "filtered_trips = expanded_ct.loc[expanded_ct.user_id_join.isin(common), :].reset_index(drop=True)\n",
    "filtered_survey = survey_data.loc[survey_data.user_id_join.isin(common), :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53927d5f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Just to double-check.\n",
    "print(len(filtered_trips.user_id.unique()), len(filtered_survey.survey_user_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daed8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the section_*_argmax.\n",
    "\n",
    "def compute_argmax(db: str, row):\n",
    "    \n",
    "    if db != 'Stage_database':\n",
    "    \n",
    "        sections = row['inferred_section_summary']\n",
    "\n",
    "        if pd.isna(sections) or len(sections) == 0 or len(sections['distance']) == 0:\n",
    "            return row\n",
    "\n",
    "        try:\n",
    "            mode = sorted(sections['distance'].items(), key=lambda x: x[-1], reverse=True)[0][0]\n",
    "            distance = sections['distance'][mode]\n",
    "            duration = sections['duration'][mode]\n",
    "\n",
    "            row['section_mode_argmax'] = mode\n",
    "            row['section_distance_argmax'] = distance\n",
    "            row['section_duration_argmax'] = duration\n",
    "\n",
    "        except:\n",
    "            row['section_mode_argmax'] = np.nan\n",
    "            row['section_distance_argmax'] = np.nan\n",
    "            row['section_duration_argmax'] = np.nan\n",
    "\n",
    "        finally:\n",
    "            return row\n",
    "    else:\n",
    "        \n",
    "        try:\n",
    "            distances = ast.literal_eval(row['section_distances'])\n",
    "            durations = ast.literal_eval(row['section_durations'])\n",
    "            modes = ast.literal_eval(row['section_modes'])\n",
    "\n",
    "            argmax = np.argmax(distances)\n",
    "            \n",
    "            row['section_distance_argmax'] = distances[argmax]\n",
    "            row['section_duration_argmax'] = durations[argmax]\n",
    "            row['section_mode_argmax'] = modes[argmax]\n",
    "            \n",
    "        except:\n",
    "            row['section_mode_argmax'] = np.nan\n",
    "            row['section_distance_argmax'] = np.nan\n",
    "            row['section_duration_argmax'] = np.nan\n",
    "            \n",
    "        finally:\n",
    "            return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c008a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_trips.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1baa06",
   "metadata": {},
   "source": [
    "### Available feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de49ec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "available = {\n",
    "    # AllCEO\n",
    "    'Bicycle': 'p_micro',\n",
    "    'Do not have vehicle': 'unknown',\n",
    "    'Do not have vehicle ': 'unknown',\n",
    "    'Get a ride from a friend or family member': 's_car',\n",
    "    'None': 'no_trip',\n",
    "    'Public transportation (bus, subway, light rail, etc.)': 'transit',\n",
    "    'Rental car (including Zipcar/ Car2Go)': 'car',\n",
    "    'Shared bicycle or scooter': 's_micro',\n",
    "    'Skateboard': 'p_micro',\n",
    "    'Taxi (regular taxi, Uber, Lyft, etc)': 'ridehail',\n",
    "    'Walk/roll': 'walk',\n",
    "    'Prefer not to say': 'unknown',\n",
    "    # Others\n",
    "    'public_transportation__bus__subway__ligh': 'transit',\n",
    "    'get_a_ride_from_a_friend_or_family_membe': 's_car', \n",
    "    'bicycle': 'p_micro', \n",
    "    'walk': 'walk',\n",
    "    'taxi__regular_taxi__uber__lyft__etc': 'ridehail',\n",
    "    'rental_car__including_zipcar__car2go': 'car', \n",
    "    'prefer_not_to_say': 'unknown'\n",
    "}\n",
    "\n",
    "# We use the sensed mode to update the available modes.\n",
    "# This is to account for any user data input errors. E.g.: user does not select car as available mode\n",
    "# but the sensed mode is car.\n",
    "section_mode_mapping = {\n",
    "    'bicycling': ['p_micro', 's_micro'],\n",
    "    'car': ['s_car', 'car', 'ridehail'],\n",
    "    'no_sensed': ['unknown'],\n",
    "    'walking': ['walk'],\n",
    "    'unknown': ['unknown'],\n",
    "    'transit': ['transit']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62960039",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_trips = filtered_trips.apply(lambda x: compute_argmax(CURRENT_DB, x), axis=1)\n",
    "\n",
    "# Drop all rows where argmax mode == air\n",
    "filtered_trips.drop(\n",
    "    index=filtered_trips.loc[filtered_trips.section_mode_argmax.isin(['AIR_OR_HSR', 'air_or_hsr']),:].index, \n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "filtered_trips.section_mode_argmax.replace({\n",
    "    'subway': 'transit',\n",
    "    'no_sensed': 'unknown',\n",
    "    'train': 'transit',\n",
    "    'TRAM': 'transit',\n",
    "    'LIGHT_RAIL': 'transit',\n",
    "    'CAR': 'car',\n",
    "    'WALKING': 'walking',\n",
    "    'BICYCLING': 'bicycling',\n",
    "    'UNKNOWN': 'unknown',\n",
    "    'TRAIN': 'transit',\n",
    "    'SUBWAY': 'transit',\n",
    "    'BUS': 'transit',\n",
    "    'bus': 'transit'\n",
    "}, inplace=True)\n",
    "\n",
    "filtered_trips.dropna(subset='section_mode_argmax', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8583a709",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Meters -> miles\n",
    "filtered_trips['section_distance_argmax'] *= 0.000621371\n",
    "\n",
    "## Seconds -> minutes\n",
    "filtered_trips['section_duration_argmax'] /= 60.\n",
    "\n",
    "## Total distance and duration are scaled too.\n",
    "filtered_trips['distance'] *= 0.000621371\n",
    "filtered_trips['duration'] /= 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4d05eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_trips = filtered_trips.merge(right=filtered_survey, left_on='user_id_join', right_on='user_id_join')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383fe251",
   "metadata": {},
   "source": [
    "## Update available indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee097233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "new_cols = list(set(available.values()))\n",
    "filtered_trips[new_cols] = 0\n",
    "\n",
    "for user_id, user_trips in filtered_trips.groupby('user_id'):\n",
    "    \n",
    "    if CURRENT_DB == \"Stage_database\":\n",
    "    \n",
    "        # Get the set of available modes (demographics.)\n",
    "        all_av_modes = user_trips['available_modes'].str.split(';').explode()\n",
    "    else:\n",
    "        # Get the set of available modes (demographics.)\n",
    "        all_av_modes = user_trips['available_modes'].str.split().explode()\n",
    "    \n",
    "    # Get all sensed modes.\n",
    "    all_sections = user_trips['section_mode_argmax'].unique()\n",
    "    \n",
    "    # Map to Common Normal Form.\n",
    "    mapped_sections = set(list(itertools.chain.from_iterable([section_mode_mapping[x] for x in all_sections])))\n",
    "    mapped_demo_av = set([available[x] for x in all_av_modes.unique()])\n",
    "    \n",
    "    # Perform a set union.\n",
    "    combined = list(mapped_sections.union(mapped_demo_av))\n",
    "    \n",
    "    # Update dummy indicators.\n",
    "    filtered_trips.loc[filtered_trips.user_id == user_id, combined] = 1\n",
    "\n",
    "filtered_trips.rename(columns=dict([(c, 'av_'+c) for c in new_cols]), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bfcc0c",
   "metadata": {},
   "source": [
    "### Cost estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054a6ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All values are taken from VTPI.\n",
    "# https://www.vtpi.org/tca/tca0501.pdf\n",
    "mode_cost_per_mile = {\n",
    "    # bicycle/skateboard\n",
    "    'p_micro': 0.,\n",
    "    'no_trip': 0.,\n",
    "    # Shared car is half the cost of regular car, which is $0.6/mile.\n",
    "    's_car': 0.3,\n",
    "    # Rental car.\n",
    "    'car': 0.6,\n",
    "    # Average of bus and train taken.\n",
    "    'transit': 0.5,\n",
    "    # Shared bicyle or scooter - values taken from https://nacto.org/shared-micromobility-2020-2021/ and \n",
    "    # https://www.mckinsey.com/industries/automotive-and-assembly/our-insights/how-sharing-the-road-is-likely-to-transform-american-mobility\n",
    "    's_micro': 0.3,\n",
    "    # uber/taxi/lyft\n",
    "    'ridehail': 2.,\n",
    "    'walk': 0.,\n",
    "    'unknown': 0.\n",
    "}\n",
    "\n",
    "# Assumptions.\n",
    "mode_init_cost = {\n",
    "    'p_micro': 0.,\n",
    "    'no_trip': 0.,\n",
    "    # Shared car is half the cost of regular car, which is $0.6/mile.\n",
    "    's_car': 0.,\n",
    "    # Rental car.\n",
    "    'car': 0.,\n",
    "    # Average of bus and train taken.\n",
    "    'transit': 0.,\n",
    "    # $1 unlocking cost.\n",
    "    's_micro': 1.,\n",
    "    # uber/taxi/lyft\n",
    "    'ridehail': 1.5,\n",
    "    'walk': 0.,\n",
    "    'unknown': 0.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccd3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_estimates(df: pd.DataFrame):\n",
    "    \n",
    "    # Create some extra colums.\n",
    "    columns = [c.replace('av_', '') for c in df.columns if 'av_' in c]\n",
    "\n",
    "    # Initialize the columns to 0.\n",
    "    df[columns] = 0.\n",
    "\n",
    "    rows = list()\n",
    "\n",
    "    # Iterate over every row.\n",
    "    for _, row in df.iterrows():\n",
    "        # Check which flags are active.\n",
    "        row_dict = row.to_dict()\n",
    "\n",
    "        # Access the section_distance_argmax attribute for the distance. Note that this is now in miles.\n",
    "        distance = row_dict['section_distance_argmax']\n",
    "        \n",
    "        # Mask using availability.\n",
    "        for lookup in columns:\n",
    "            row_dict[lookup] = row_dict['av_' + lookup] * (\n",
    "                mode_init_cost[lookup] + (mode_cost_per_mile[lookup] * distance)\n",
    "            )\n",
    "\n",
    "        rows.append(row_dict)\n",
    "\n",
    "    new_df = pd.DataFrame(rows)\n",
    "    new_df.rename(columns=dict([(c, 'cost_'+c) for c in columns]), inplace=True)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f1901",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_trips = compute_cost_estimates(filtered_trips)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c20466",
   "metadata": {},
   "source": [
    "### Outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05071cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"For {CURRENT_DB=}, before outlier removal, n_rows = {filtered_trips.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b222715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop instances where duration/distance is unusable.\n",
    "filtered_trips.drop(\n",
    "    index=filtered_trips.loc[(filtered_trips.section_distance_argmax <= 0) | (filtered_trips.section_duration_argmax <= 0), :].index,\n",
    "    inplace=False\n",
    ").reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# bus, train, bicycling, walking, car\n",
    "# split-apply-combine\n",
    "def drop_outliers(df: pd.DataFrame, low=0.1, high=0.9) -> pd.DataFrame:\n",
    "    \n",
    "    def filter_by_percentiles(group):\n",
    "        distance_low = group['section_distance_argmax'].quantile(low)\n",
    "        distance_high = group['section_distance_argmax'].quantile(high)\n",
    "        duration_low = group['section_duration_argmax'].quantile(low)\n",
    "        duration_high = group['section_duration_argmax'].quantile(high)\n",
    "        \n",
    "        l1_filter = group[\n",
    "            (group['section_distance_argmax'] >= distance_low) &\n",
    "            (group['section_distance_argmax'] <= distance_high)\n",
    "        ].reset_index(drop=True)\n",
    "        \n",
    "        l2_filter = l1_filter[\n",
    "            (l1_filter['section_duration_argmax'] >= duration_low) &\n",
    "            (l1_filter['section_duration_argmax'] <= duration_high)\n",
    "        ].reset_index(drop=True)\n",
    "        \n",
    "        return l2_filter\n",
    "    \n",
    "    return df.groupby('section_mode_argmax').apply(filter_by_percentiles).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77febb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_trips = drop_outliers(filtered_trips, low=0.01, high=0.99)\n",
    "\n",
    "# Ideal speed. distance/time (in hours).\n",
    "filtered_trips['mph'] = (\n",
    "    (filtered_trips['section_distance_argmax'] * 60.)/filtered_trips['section_duration_argmax']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52d5325",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_trips[['section_mode_argmax', 'section_duration_argmax', 'section_distance_argmax', 'mph']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_mph(df: pd.DataFrame, low=0.1, high=0.9) -> pd.DataFrame:\n",
    "    \n",
    "    MPH_THRESHOLDS = {\n",
    "        # https://www.sciencedirect.com/science/article/pii/S2210670718304682\n",
    "        'bicycling': 15.,\n",
    "        # https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7806575/\n",
    "        'walking': 2.93\n",
    "    }\n",
    "    \n",
    "    def custom_filter(group):\n",
    "        # Drop data specified in the dict manually.\n",
    "        if group.name in MPH_THRESHOLDS.keys():\n",
    "            f_df = group[group['mph'] <= MPH_THRESHOLDS[group.name]]\n",
    "        else:\n",
    "            mph_low = group['mph'].quantile(low)\n",
    "            mph_high = group['mph'].quantile(high)\n",
    "\n",
    "            f_df = group[(group['mph'] >= mph_low) & (group['mph'] <= mph_high)]\n",
    "        \n",
    "        return f_df\n",
    "    \n",
    "    return df.groupby('section_mode_argmax').apply(custom_filter).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1904cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_trips = filter_mph(filtered_trips, low=0.01, high=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dce2b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_trips.groupby('section_mode_argmax')[['section_distance_argmax', 'section_duration_argmax']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396f196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_trips.groupby('section_mode_argmax')[['mph']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41109148",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"For {CURRENT_DB=}, After outlier removal, n_rows = {filtered_trips.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca22a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop=[\n",
    "    '_id', 'additions', 'cleaned_section_summary', 'cleaned_trip', 'confidence_threshold', \n",
    "    'end_fmt_time', 'end_loc', 'end_local_dt_day', 'raw_trip', 'purpose_confirm',\n",
    "    'end_local_dt_minute', 'end_local_dt_month', 'end_local_dt_second', 'end_local_dt_timezone', \n",
    "    'end_local_dt_weekday', 'end_local_dt_year', 'end_place', 'end_ts', 'expectation', 'expected_trip', \n",
    "    'inferred_labels', 'inferred_section_summary', 'inferred_trip', 'metadata_write_ts', 'mode_confirm', \n",
    "    'section_durations', 'section_modes', 'source', 'start_fmt_time', 'start_loc', 'start_local_dt_day', \n",
    "    'start_local_dt_minute', 'start_local_dt_month', 'start_local_dt_second', \n",
    "    'start_local_dt_timezone', 'start_local_dt_weekday', 'start_local_dt_year', 'start_place', \n",
    "    'start_ts', 'user_id_join', 'user_input', 'survey_user_id', 'section_distances',\n",
    "    'data.local_dt.year', 'data.local_dt.month', 'data.local_dt.day', 'data.local_dt.hour', \n",
    "    'data.local_dt.minute', 'data.local_dt.second', 'data.local_dt.weekday', 'data.local_dt.timezone',\n",
    "    'data.fmt_time'\n",
    "]\n",
    "\n",
    "for col in to_drop:\n",
    "    if col in filtered_trips.columns:\n",
    "        filtered_trips.drop(columns=[col], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2937d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_trips.rename({'start_local_dt_hour': 'start:hour', 'end_local_dt_hour': 'end:hour'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c7fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_trips.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea36cad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(filtered_trips.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7018bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Done processing for {CURRENT_DB=}, Number of unique users: {len(filtered_trips.user_id.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eacc539",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['p_micro', 'no_trip', 's_car', 'transit', 'car', 's_micro', 'ridehail', 'walk', 'unknown']\n",
    "\n",
    "# Rename and map targets.\n",
    "filtered_trips.rename(columns={'replaced_mode': 'target'}, inplace=True)\n",
    "filtered_trips.replace({'target': {t: ix+1 for ix, t in enumerate(targets)}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f35a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# savepath = Path('./data/filtered_data')\n",
    "savepath = Path('./data/filtered_data')\n",
    "\n",
    "if not savepath.exists():\n",
    "    savepath.mkdir()\n",
    "\n",
    "filtered_trips.to_csv(savepath / f'preprocessed_data_{CURRENT_DB}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16fb354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emission",
   "language": "python",
   "name": "emission"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
