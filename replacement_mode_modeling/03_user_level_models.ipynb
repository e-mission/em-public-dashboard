{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04ccf092",
   "metadata": {},
   "source": [
    "## Some important points to remember:\n",
    "\n",
    "### We want to experiment with two types of models:\n",
    "\n",
    "\n",
    "1. have one row per user, so that when predicting modes for a new user, we pick the \"similar user\" or users and determine the replaced mode\n",
    "    - In this, the traditional approach would only use demographics for the user features, we may experiment with some summaries of the trip data that will function as some level of \"fingerprint\" for the user. Ideally we would be able to show that this performs better than demographics alone\n",
    "    - Note also that the original method that you had outlined where the training set is a list of trips (O()) is a third approach which we will be comparing these two against"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c1ee88",
   "metadata": {},
   "source": [
    "Target order:\n",
    "\n",
    "```\n",
    "['p_micro', 'no_trip', 's_car', 'transit', 'car', 's_micro', 'ridehail', 'walk', 'unknown']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ef0f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, f1_score, log_loss\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from enum import Enum\n",
    "from scipy.stats import uniform\n",
    "from typing import List, Dict, Union\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from sklearn.manifold import TSNE\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef98692",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 13210\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "SimilarityMetric = Enum('SimilarityMetric', ['COSINE', 'EUCLIDEAN', 'KNN', 'KMEANS'])\n",
    "GroupType = Enum('GroupType', ['GROUPBY', 'CUT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f8c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE = [\n",
    "    ('./data/filtered_data/preprocessed_data_Stage_database.csv', 'allceo'),\n",
    "    ('./data/filtered_data/preprocessed_data_openpath_prod_durham.csv', 'durham'),\n",
    "    ('./data/filtered_data/preprocessed_data_openpath_prod_mm_masscec.csv', 'masscec'),\n",
    "    ('./data/filtered_data/preprocessed_data_openpath_prod_ride2own.csv', 'ride2own'),\n",
    "    ('./data/filtered_data/preprocessed_data_openpath_prod_uprm_nicr.csv', 'nicr')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d9c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHANGE THE DB INDEX HERE.\n",
    "DB_NUMBER = 0\n",
    "\n",
    "PATH = DATA_SOURCE[DB_NUMBER][0]\n",
    "CURRENT_DB = DATA_SOURCE[DB_NUMBER][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa6843",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_needed = ['deprecatedID', 'data.key']\n",
    "\n",
    "for col in not_needed:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=[col], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72793473",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765f08ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tsne_plots(df: pd.DataFrame, **kwargs):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Important - if not cast as a category, seaborn considers this as a numerical value.\n",
    "    df.target = df.target.astype('category')\n",
    "    \n",
    "    # print(\"Unique targets: \", df.target.unique())\n",
    "    \n",
    "    # According to the docs, > consider choosing a perplexity between 5 and 50.\n",
    "    tsne = TSNE(\n",
    "        n_components=2,\n",
    "        perplexity=kwargs.pop('perplexity', 5),\n",
    "        n_iter=kwargs.pop('n_iter', 2000),\n",
    "        metric=kwargs.pop('metric', 'cosine'),\n",
    "        random_state=SEED,\n",
    "        n_jobs=os.cpu_count()\n",
    "    )\n",
    "    \n",
    "    if df.index.name == 'user_id':\n",
    "        df.reset_index(drop=False, inplace=True)\n",
    "    \n",
    "    if 'user_id' in df.columns:\n",
    "        df.drop(columns=['user_id'], inplace=True)\n",
    "    \n",
    "    targets = df.target.values\n",
    "    df.drop(columns=['target'], inplace=True)\n",
    "    \n",
    "    projected = tsne.fit_transform(df)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    sns.scatterplot(x=projected[:, 0], y=projected[:, 1], hue=targets, ax=ax)\n",
    "    ax.set(xlabel='Embedding dimension 1', ylabel='Embedding dimension 2', title='t-SNE plot for data')\n",
    "    plt.show()\n",
    "    \n",
    "    return projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe76e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode_coverage(df: pd.DataFrame):\n",
    "    \n",
    "    coverage_df = df.groupby(['user_id', 'section_mode_argmax']).size().unstack(fill_value=0)\n",
    "    coverage_df.columns = ['coverage_' + str(c) for c in coverage_df.columns]\n",
    "    \n",
    "    # As a preventative measure.\n",
    "    coverage_df.fillna(0, inplace=True)\n",
    "    \n",
    "    # Normalize over rows.\n",
    "    coverage_df.iloc[:, 1:] = coverage_df.iloc[:, 1:].div(coverage_df.iloc[:, 1:].sum(axis=1), axis=0)\n",
    "    \n",
    "    return coverage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75313008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trip_summaries(df: pd.DataFrame, group_key: str, feature_list: List[str], **kwargs):\n",
    "    \n",
    "    def get_feature_summaries(trip_feature: str, is_ordinal: bool = False):\n",
    "        \n",
    "        if is_numeric_dtype(df[group_key]):\n",
    "            col_prefix = f'{trip_feature}_mean_cut'\n",
    "            if not use_qcut:\n",
    "                grouper = df.groupby(['user_id', pd.cut(df[group_key], n_cuts)])[trip_feature]\n",
    "            else:\n",
    "                grouper = df.groupby(['user_id', pd.qcut(df[group_key], n_cuts)])[trip_feature]\n",
    "        else:\n",
    "            grouper = df.groupby(['user_id', group_key])[trip_feature]\n",
    "        \n",
    "        if not is_ordinal:\n",
    "            # A mean of 0 is an actual value.\n",
    "            \n",
    "            mean = grouper.mean().unstack(level=-1, fill_value=-1.)\n",
    "            \n",
    "            mean.columns = [f'{trip_feature}_mean_' + str(c) for c in mean.columns]\n",
    "            \n",
    "            # Same with percentiles - 0 is an actual value.\n",
    "            median = grouper.median().unstack(level=-1, fill_value=-1.)\n",
    "            median.columns = [f'{trip_feature}_median_' + str(c) for c in median.columns]\n",
    "            \n",
    "            iqr_df = grouper.quantile([0.25, 0.75]).unstack(level=-1)\n",
    "            iqr = (iqr_df[0.75] - iqr_df[0.25]).unstack(level=-1)\n",
    "            iqr.fillna(-1., inplace=True)\n",
    "            iqr.columns = [f'{trip_feature}_iqr_' + str(c) for c in iqr.columns]\n",
    "\n",
    "            # Now merge.\n",
    "            merged = mean.copy()\n",
    "            merged = merged.merge(right=median, left_index=True, right_index=True)\n",
    "            merged = merged.merge(right=iqr, left_index=True, right_index=True)\n",
    "            \n",
    "            merged.fillna(-1., inplace=True)\n",
    "\n",
    "            return merged\n",
    "        \n",
    "        # 0 is OK to indicate NaN values.\n",
    "        f_mode = grouper.apply(\n",
    "            lambda x: x.value_counts().idxmax()\n",
    "        ).unstack(fill_value=0.)\n",
    "        \n",
    "        f_mode.columns = [f'{trip_feature}_mode_' + str(c) for c in f_mode.columns]\n",
    "        f_mode.fillna(0., inplace=True)\n",
    "        \n",
    "        return f_mode\n",
    "    \n",
    "    assert group_key not in feature_list, \"Cannot perform grouping and summarization of the same feature.\"\n",
    "    \n",
    "    # Optional kwarg for number of cuts for numeric dtype grouping.\n",
    "    # Default is 3: short, medium, long trip types:\n",
    "    # For e.g., if the group key is 'section_duration', it will be cut into three equally-sized bins,\n",
    "    # However, an alternative is also present - we could use qcut() instead, which would ensure that\n",
    "    # each bin has roughly the same number of samples.\n",
    "    n_cuts = kwargs.pop('n_cuts', 3)\n",
    "    use_qcut = kwargs.pop('use_qcut', False)\n",
    "    \n",
    "    # This will be the dataframe that all subsequent features will join to.\n",
    "    feature_df = None\n",
    "    \n",
    "    for ix, feature in enumerate(feature_list):\n",
    "        is_ordinal = feature == 'start_local_dt_hour' or feature == 'end_local_dt_hour'\n",
    "        if ix == 0:\n",
    "            feature_df = get_feature_summaries(feature, is_ordinal)\n",
    "        else:\n",
    "            next_feature_df = get_feature_summaries(feature, is_ordinal)\n",
    "            feature_df = feature_df.merge(right=next_feature_df, left_index=True, right_index=True)\n",
    "    \n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63617ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_demographic_data(df: pd.DataFrame, **trip_kwargs):\n",
    "    \n",
    "    '''\n",
    "    A method that returns a U x (D + t) matrix, where U = number of users,\n",
    "    D = number of demographic features, t (optional) = number of trip summary features.\n",
    "    \n",
    "    When use_trip_summaries=True, the 'available_modes' column is dropped in favor of\n",
    "    the already-preprocessed av_ columns. This is because we want to incorporate trip-level\n",
    "    information into the data. When the argument is False, we want to SOLELY use demographics.\n",
    "    '''\n",
    "    \n",
    "    trip_features_to_use = trip_kwargs.pop('trip_features', None)\n",
    "    trip_group_key = trip_kwargs.pop('trip_grouping', 'section_mode_argmax')\n",
    "    \n",
    "    demographics = {\n",
    "        'allceo': [\n",
    "            'has_drivers_license', 'is_student', 'is_paid', 'income_category',\n",
    "            'n_residence_members', 'n_residents_u18', 'n_residents_with_license',\n",
    "            'n_motor_vehicles', 'has_medical_condition',\n",
    "            'ft_job', 'multiple_jobs', 'n_working_residents',\n",
    "            \"highest_education_Bachelor's degree\",\n",
    "            'highest_education_Graduate degree or professional degree',\n",
    "            'highest_education_High school graduate or GED',\n",
    "            'highest_education_Less than a high school graduate',\n",
    "            'highest_education_Prefer not to say',\n",
    "            'highest_education_Some college or associates degree',\n",
    "            'primary_job_description_Clerical or administrative support',\n",
    "            'primary_job_description_Custodial',\n",
    "            'primary_job_description_Education',\n",
    "            'primary_job_description_Food service',\n",
    "            'primary_job_description_Linecook',\n",
    "            'primary_job_description_Manufacturing, construction, maintenance, or farming',\n",
    "            'primary_job_description_Medical/healthcare',\n",
    "            'primary_job_description_Non-profit program manager',\n",
    "            'primary_job_description_Other',\n",
    "            'primary_job_description_Professional, managerial, or technical',\n",
    "            'primary_job_description_Sales or service',\n",
    "            'primary_job_description_Self employed',\n",
    "            'primary_job_description_food service', 'gender_Man',\n",
    "            'gender_Nonbinary/genderqueer/genderfluid', 'gender_Prefer not to say',\n",
    "            'gender_Woman', 'gender_Woman;Nonbinary/genderqueer/genderfluid',\n",
    "            'age_16___20_years_old', 'age_21___25_years_old',\n",
    "            'age_26___30_years_old', 'age_31___35_years_old',\n",
    "            'age_36___40_years_old', 'age_41___45_years_old',\n",
    "            'age_46___50_years_old', 'age_51___55_years_old',\n",
    "            'age_56___60_years_old', 'age_61___65_years_old', 'age___65_years_old',\n",
    "            'av_transit', 'av_no_trip', 'av_p_micro', 'av_s_micro', 'av_ridehail',\n",
    "            'av_unknown', 'av_walk', 'av_car', 'av_s_car'\n",
    "        ],\n",
    "        'durham': [\n",
    "            'is_student', 'is_paid', 'has_drivers_license', 'n_residents_u18',\n",
    "            'n_residence_members', 'income_category',\n",
    "            'n_residents_with_license', 'n_working_residents', 'n_motor_vehicles',\n",
    "            'has_medical_condition', 'ft_job', 'multiple_jobs',\n",
    "            'highest_education_bachelor_s_degree',\n",
    "            'highest_education_graduate_degree_or_professional_degree',\n",
    "            'highest_education_high_school_graduate_or_ged',\n",
    "            'highest_education_less_than_a_high_school_graduate',\n",
    "            'highest_education_some_college_or_associates_degree',\n",
    "            'primary_job_description_Clerical or administrative support',\n",
    "            'primary_job_description_Manufacturing, construction, maintenance, or farming',\n",
    "            'primary_job_description_Other',\n",
    "            'primary_job_description_Professional, Manegerial, or Technical',\n",
    "            'primary_job_description_Sales or service', 'gender_man',\n",
    "            'gender_non_binary_genderqueer_gender_non_confor', 'gender_woman',\n",
    "            'age_16___20_years_old', 'age_21___25_years_old',\n",
    "            'age_26___30_years_old', 'age_31___35_years_old',\n",
    "            'age_36___40_years_old', 'age_41___45_years_old',\n",
    "            'age_51___55_years_old', 'age_56___60_years_old', 'av_walk',\n",
    "            'av_unknown', 'av_no_trip', 'av_p_micro', 'av_transit', 'av_car',\n",
    "            'av_ridehail', 'av_s_micro', 'av_s_car'\n",
    "        ],\n",
    "        'nicr': [\n",
    "            'is_student', 'is_paid',\n",
    "            'has_drivers_license', 'n_residents_u18', 'n_residence_members',\n",
    "            'income_category', 'n_residents_with_license',\n",
    "            'n_working_residents', 'n_motor_vehicles', 'has_medical_condition',\n",
    "            'ft_job', 'multiple_jobs',\n",
    "            'highest_education_high_school_graduate_or_ged',\n",
    "            'highest_education_prefer_not_to_say', 'primary_job_description_Other',\n",
    "            'gender_man', 'gender_woman', 'age_16___20_years_old', 'av_p_micro',\n",
    "            'av_car', 'av_transit', 'av_ridehail', 'av_no_trip', 'av_s_car',\n",
    "            'av_s_micro', 'av_unknown', 'av_walk'\n",
    "        ],\n",
    "        'masscec': [\n",
    "            'is_student', 'is_paid',\n",
    "            'has_drivers_license', 'n_residents_u18', 'n_residence_members',\n",
    "            'income_category', 'n_residents_with_license',\n",
    "            'n_working_residents', 'n_motor_vehicles', 'has_medical_condition',\n",
    "            'ft_job', 'multiple_jobs', 'highest_education_bachelor_s_degree',\n",
    "            'highest_education_graduate_degree_or_professional_degree',\n",
    "            'highest_education_high_school_graduate_or_ged',\n",
    "            'highest_education_less_than_a_high_school_graduate',\n",
    "            'highest_education_prefer_not_to_say',\n",
    "            'highest_education_some_college_or_associates_degree',\n",
    "            'primary_job_description_Clerical or administrative support',\n",
    "            'primary_job_description_Manufacturing, construction, maintenance, or farming',\n",
    "            'primary_job_description_Other',\n",
    "            'primary_job_description_Prefer not to say',\n",
    "            'primary_job_description_Professional, Manegerial, or Technical',\n",
    "            'primary_job_description_Sales or service', 'gender_man',\n",
    "            'gender_prefer_not_to_say', 'gender_woman', 'age_16___20_years_old',\n",
    "            'age_21___25_years_old', 'age_26___30_years_old',\n",
    "            'age_31___35_years_old', 'age_36___40_years_old',\n",
    "            'age_41___45_years_old', 'age_46___50_years_old',\n",
    "            'age_51___55_years_old', 'age_56___60_years_old',\n",
    "            'age_61___65_years_old', 'age___65_years_old', 'av_p_micro', 'av_s_car',\n",
    "            'av_s_micro', 'av_transit', 'av_car', 'av_no_trip', 'av_unknown',\n",
    "            'av_ridehail', 'av_walk'\n",
    "        ],\n",
    "        'ride2own': [\n",
    "            'has_drivers_license', 'is_student',\n",
    "            'is_paid', 'income_category', 'n_residence_members',\n",
    "            'n_working_residents', 'n_residents_u18', 'n_residents_with_license',\n",
    "            'n_motor_vehicles', 'has_medical_condition',\n",
    "            'ft_job', 'multiple_jobs',\n",
    "            'highest_education_bachelor_s_degree',\n",
    "            'highest_education_high_school_graduate_or_ged',\n",
    "            'highest_education_less_than_a_high_school_graduate',\n",
    "            'highest_education_some_college_or_associates_degree',\n",
    "            'primary_job_description_Other',\n",
    "            'primary_job_description_Professional, Manegerial, or Technical',\n",
    "            'gender_man', 'gender_woman', 'age_31___35_years_old',\n",
    "            'age_36___40_years_old', 'age_41___45_years_old',\n",
    "            'age_51___55_years_old', 'av_no_trip', 'av_s_micro', 'av_transit',\n",
    "            'av_car', 'av_ridehail', 'av_p_micro', 'av_s_car', 'av_walk',\n",
    "            'av_unknown'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Retain only the first instance of each user and subset the columns.\n",
    "    filtered = df.groupby('user_id').first()[demographics[CURRENT_DB]]\n",
    "    \n",
    "    # Get the targets.\n",
    "    targets = df.groupby('user_id')['target'].apply(lambda x: x.value_counts().idxmax())\n",
    "    \n",
    "    filtered = filtered.merge(right=targets, left_index=True, right_index=True)\n",
    "    \n",
    "    if trip_features_to_use is None or len(trip_features_to_use) == 0:\n",
    "#         # Use the available modes as indicators.\n",
    "#         return encode_availability(filtered)\n",
    "        return filtered\n",
    "    \n",
    "    # -----------------------------------------------------------\n",
    "    # Reaching here means that we need to include trip summaries\n",
    "    # -----------------------------------------------------------\n",
    "    \n",
    "    # For every user, generate the global trip-level summaries.\n",
    "    global_aggs = df.groupby('user_id').agg({'duration': 'mean', 'distance': 'mean'})\n",
    "    \n",
    "    # coverage.\n",
    "    coverage = get_mode_coverage(df)\n",
    "    \n",
    "    # Trip-level features.\n",
    "    trip_features = get_trip_summaries(\n",
    "        df=df, \n",
    "        group_key=trip_group_key, \n",
    "        feature_list=trip_features_to_use,\n",
    "        use_qcut=trip_kwargs.pop('use_qcut', False)\n",
    "    )\n",
    "    \n",
    "    targets = df.groupby('user_id')['target'].apply(lambda x: x.value_counts().idxmax())\n",
    "    \n",
    "    trip_features = trip_features.merge(right=coverage, left_index=True, right_index=True)\n",
    "    trip_features = trip_features.merge(right=global_aggs, left_index=True, right_index=True)\n",
    "    \n",
    "    # Finally, join with availability indicators and targets.\n",
    "    trip_features = trip_features.merge(right=targets, left_index=True, right_index=True)\n",
    "    \n",
    "    return trip_features.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedb51e8",
   "metadata": {},
   "source": [
    "## Experiment 1: Only demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66421120",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Educated suburban woman -> \n",
    "# An embedding where:\n",
    "# \"highest_education_Bachelor's degree\" == 1 or 'highest_education_Graduate degree or professional degree' == 1\n",
    "# income_category >= 4 ( + more features that define 'suburban-ness')\n",
    "# gender_Woman == 1\n",
    "\n",
    "demo_df = get_demographic_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17196eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(demo_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c458c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_kwargs = {\n",
    "    'perplexity': min(len(demo_df)-1, 6),\n",
    "    'n_iter': 7500,\n",
    "    'metric': 'cosine'\n",
    "}\n",
    "\n",
    "# ## PLOT BY THE WAY IN WHICH PEOPLE USE THE SAME REPLACED MODE AND CHECK THE SIMILARITY.\n",
    "\n",
    "projections = generate_tsne_plots(demo_df, **tsne_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c023cf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No stratification, pure random.\n",
    "demo_df.reset_index(drop=False, inplace=True)\n",
    "train, test = train_test_split(demo_df, test_size=0.2, random_state=SEED)\n",
    "\n",
    "TRAIN_USERS = train.user_id.unique().tolist()\n",
    "TEST_USERS = test.user_id.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a4391",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape[0], test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630d6c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring that no user information is leaked across sets.\n",
    "assert train.shape[0] + test.shape[0] == len(df.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef77c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_using_similarity(test_df, train_df, metric=SimilarityMetric.COSINE, **metric_kwargs):\n",
    "    \n",
    "    '''\n",
    "    This method treats each user row as a 'fingerprint' (embedding vector). We assume that we\n",
    "    have no idea about the test set labels. To find which replaced mode is most likely for the test\n",
    "    users, we compute the cosine similarity of each test user against the users in the training set.\n",
    "    For the most similar user, we use their target as a proxy for the test user's replaced mode.\n",
    "    This operates on the following intuition: If User A and User B are similar, then their replaced\n",
    "    modes are also similar.\n",
    "    '''\n",
    "    \n",
    "    tr_targets = train_df.target.values\n",
    "    tr = train_df.drop(columns=['target', 'user_id'], inplace=False).reset_index(drop=True, inplace=False)\n",
    "    \n",
    "    te_targets = test_df.target.values\n",
    "    te = test_df.drop(columns=['target', 'user_id'], inplace=False).reset_index(drop=True, inplace=False)\n",
    "    \n",
    "    if metric == SimilarityMetric.COSINE:\n",
    "        # Use cosine similarity to determine which element in the train set this user is closest to.\n",
    "        # Offset the columns from the second entry to exclude the user_id column.\n",
    "        # Returns a (n_te, n_tr) matrix.\n",
    "        sim = cosine_similarity(te.values, tr.values)\n",
    "        \n",
    "        # Compute the argmax across the train set.\n",
    "        argmax = np.argmax(sim, axis=1)\n",
    "\n",
    "        # Index into the training targets to retrieve predicted label.\n",
    "        y_test_pred = tr_targets[argmax]\n",
    "        \n",
    "    elif metric == SimilarityMetric.EUCLIDEAN:\n",
    "        \n",
    "        # Here, we choose the embedding with the smallest L2 distance.\n",
    "        distances = euclidean_distances(te.values, tr.values)\n",
    "        \n",
    "        # We choose argmin\n",
    "        argmin = np.argmin(distances, axis=1)\n",
    "        \n",
    "        # Index into the targets.\n",
    "        y_test_pred = tr_targets[argmin]\n",
    "    \n",
    "    elif metric == SimilarityMetric.KNN:\n",
    "        \n",
    "        n_neighbors = metric_kwargs.pop('n_neighbors', 3)\n",
    "        \n",
    "        if n_neighbors >= len(tr):\n",
    "            return -1.\n",
    "        \n",
    "        # Build the KNN classifier. By default, let it be 3.\n",
    "        knn = KNeighborsClassifier(\n",
    "            n_neighbors=n_neighbors,\n",
    "            weights='distance',\n",
    "            metric=metric_kwargs.pop('knn_metric', 'cosine'),\n",
    "            n_jobs=os.cpu_count()\n",
    "        )\n",
    "        \n",
    "        # Fit the data to the KNN model\n",
    "        knn.fit(tr, tr_targets)\n",
    "        \n",
    "        y_test_pred = knn.predict(te)\n",
    "    \n",
    "    elif metric == SimilarityMetric.KMEANS:\n",
    "        \n",
    "        n_clusters = metric_kwargs.pop('n_clusters', 8)\n",
    "        \n",
    "        if n_clusters >= len(tr):\n",
    "            return -1\n",
    "        \n",
    "        # Build the model.\n",
    "        kmeans = KMeans(\n",
    "            n_clusters=n_clusters,\n",
    "            max_iter=metric_kwargs.pop('max_iter', 300),\n",
    "            n_init='auto',\n",
    "            random_state=SEED\n",
    "        )\n",
    "        \n",
    "        # Fit the clustering model\n",
    "        kmeans.fit(tr)\n",
    "        \n",
    "        # Construct the auxiliary df and merge with the training set.\n",
    "        label_df = pd.DataFrame({'label': kmeans.labels_, 'target': tr_targets}, index=tr.index)\n",
    "        \n",
    "        # Now, perform an inference on the test set.\n",
    "        predicted_labels = kmeans.predict(te)\n",
    "        \n",
    "        y_test_pred = []\n",
    "        for prediction in predicted_labels:\n",
    "            most_likely = label_df.loc[label_df.label == prediction, 'target'].value_counts().idxmax()\n",
    "            y_test_pred.append(most_likely)\n",
    "        \n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown similarity metric\")\n",
    "    \n",
    "    \n",
    "    f1 = f1_score(y_true=te_targets, y_pred=y_test_pred, average='weighted')\n",
    "    print(f\"Test F1 score using {metric.name} = {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a95ad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in [\n",
    "    SimilarityMetric.COSINE, SimilarityMetric.EUCLIDEAN, SimilarityMetric.KNN, SimilarityMetric.KMEANS\n",
    "]:\n",
    "    evaluate_using_similarity(test, train, metric, n_clusters=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e435a6",
   "metadata": {},
   "source": [
    "Not bad - using just a simple random split gives us the following results:\n",
    "\n",
    "$allCEO$:\n",
    "\n",
    "```\n",
    "Test F1 score using COSINE = 0.42692939244663386\n",
    "Test F1 score using EUCLIDEAN = 0.4126984126984127\n",
    "Test F1 score using KNN = 0.4393241167434716\n",
    "Test F1 score using KMEANS = 0.4733893557422969\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f0e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_nll_scorer(clf, X, y):\n",
    "    \n",
    "    # [[yp1, yp2, yp3, ...], [yp1, yp3, ...]]\n",
    "    y_pred = clf.predict_proba(X)\n",
    "    \n",
    "    return -log_loss(y_true=y, y_pred=y_pred, labels=sorted(np.unique(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a6af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_using_model(train, test, **model_kwargs):\n",
    "    \n",
    "    cv = model_kwargs.pop('cv', None)\n",
    "    n_splits = model_kwargs.pop('n_splits', 5)\n",
    "    n_iter = model_kwargs.pop('n_iter', 500)\n",
    "    \n",
    "    if cv is None:\n",
    "        # Define the train-val splitter.\n",
    "        cv = KFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    params = {\n",
    "        'n_estimators': np.arange(100, 1001, 50),\n",
    "        'max_depth': [i for i in range(5, 101, 5)],\n",
    "        'ccp_alpha': np.linspace(0, 1, 10),\n",
    "        'class_weight': ['balanced', 'balanced_subsample', None],\n",
    "        'min_samples_split': np.arange(2, 25, 2),\n",
    "        'min_samples_leaf': np.arange(1, 25)\n",
    "    }\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=SEED)\n",
    "    \n",
    "    # Search over hparams to minimize negative log likelihood.  \n",
    "#     clf = RandomizedSearchCV(\n",
    "#         rf, params, n_iter=n_iter, scoring=custom_nll_scorer, \n",
    "#         n_jobs=os.cpu_count(), cv=cv, random_state=SEED,\n",
    "#         verbose=0\n",
    "#     )\n",
    "    \n",
    "    clf = RandomizedSearchCV(\n",
    "        rf, params, n_iter=n_iter, scoring='f1_weighted', \n",
    "        n_jobs=cpu_count(), cv=cv, random_state=SEED,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    X_tr = train.drop(columns=['user_id', 'target'])\n",
    "    y_tr = train.target.values.ravel()\n",
    "    \n",
    "    scorer = clf.fit(X_tr, y_tr)\n",
    "    \n",
    "    best_model = scorer.best_estimator_\n",
    "    \n",
    "    print(f\"Best val score = {scorer.best_score_}\")\n",
    "    \n",
    "    X_te = test.drop(columns=['user_id', 'target'])\n",
    "    \n",
    "    # Use the best model to compute F1 on the test set.\n",
    "    test_f1 = f1_score(y_true=test.target.values, y_pred=best_model.predict(X_te), average='weighted')\n",
    "    \n",
    "    print(f\"Test F1 = {test_f1}\")\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fef6d1",
   "metadata": {},
   "source": [
    "### Uncomment to run the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fab93ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = estimate_using_model(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2988c1b2",
   "metadata": {},
   "source": [
    "Interesting! The model is slightly on par with K-Means!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b77353",
   "metadata": {},
   "source": [
    "## Experiment 2: Demographics with trip summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7753d4",
   "metadata": {},
   "source": [
    "Now that we've performed experiments with solely demographic data, let's expand the feature set by including \n",
    "trip summary statistics. We would like this approach to do better than the aforementioned baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d46ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_plus_trips = get_demographic_data(\n",
    "    df, \n",
    "    trip_features=['mph', 'section_duration_argmax', 'section_distance_argmax', 'start_local_dt_hour', 'end_local_dt_hour']\n",
    ")\n",
    "\n",
    "demo_plus_trips.fillna(0., inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c1ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_plus_trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6159c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = demo_plus_trips.loc[demo_plus_trips.user_id.isin(TRAIN_USERS), :]\n",
    "test = demo_plus_trips.loc[demo_plus_trips.user_id.isin(TEST_USERS), :]\n",
    "\n",
    "print(train.shape[0], test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e85bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in [\n",
    "    SimilarityMetric.COSINE, SimilarityMetric.EUCLIDEAN, SimilarityMetric.KNN, SimilarityMetric.KMEANS\n",
    "]:\n",
    "    evaluate_using_similarity(test, train, metric, n_clusters=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba795489",
   "metadata": {},
   "source": [
    "Great! Some improvement here and there.\n",
    "\n",
    "$allCEO$\n",
    "```\n",
    "Test F1 score using COSINE = 0.32098765432098775\n",
    "Test F1 score using EUCLIDEAN = 0.36684303350970027\n",
    "Test F1 score using KNN = 0.41269841269841273\n",
    "Test F1 score using KMEANS = 0.4877344877344878\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85483fc4",
   "metadata": {},
   "source": [
    "### Uncomment this to run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acd4b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we try with the model\n",
    "# estimate_using_model(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd94c548",
   "metadata": {},
   "source": [
    "Great! Compared to the previous model, we see definite improvements! I'm sure we can squeeze some more juice out of the models using fancy optimization, but as a baseline, these are good enough.\n",
    "\n",
    "\n",
    "So, to recap:\n",
    "$F1_{cosine} = 0.37$, $F1_{euclidean} = 0.33$, $F1_{knn} = 0.3$, $F1_{kmeans} = 0.36$, $F1_{RF} = 0.4215$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8f6491",
   "metadata": {},
   "source": [
    "### Different groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce90367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip_features = ['mph', 'section_duration_argmax', 'section_distance_argmax', 'start:hour', 'end:hour']\n",
    "\n",
    "# for group_mode in ['section_mode_argmax', 'section_distance_argmax', 'section_duration_argmax', 'duration', 'distance']:\n",
    "    \n",
    "#     if group_mode in trip_features:\n",
    "#         _ = trip_features.pop(trip_features.index(group_mode))\n",
    "    \n",
    "#     exp_df = get_demographic_data(\n",
    "#         df, \n",
    "#         trip_grouping=group_mode,\n",
    "#         trip_features=trip_features,\n",
    "#         use_qcut=True\n",
    "#     )\n",
    "    \n",
    "#     train, test = train_test_split(exp_df, test_size=0.2, random_state=SEED)\n",
    "    \n",
    "#     for sim in [\n",
    "#         SimilarityMetric.COSINE, SimilarityMetric.EUCLIDEAN, SimilarityMetric.KNN, SimilarityMetric.KMEANS\n",
    "#     ]:\n",
    "#         evaluate_using_similarity(test, train, sim, n_clusters=3)\n",
    "    \n",
    "#     # estimate_using_model(train, test, n_iter=200)\n",
    "    \n",
    "#     print(50*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d53f945",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = generate_tsne_plots(\n",
    "    demo_plus_trips, \n",
    "    perplexity=min(len(demo_plus_trips)-1, 6), \n",
    "    n_iter=7500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c339fcc6",
   "metadata": {},
   "source": [
    "# (Experimental) Multi-level modeling\n",
    "\n",
    "## The code below onwards is not tested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213676ec",
   "metadata": {},
   "source": [
    "In this approach, we want to piece together the similarity search and modeling processes. Here's a rough sketch of how it should be implemented:\n",
    "\n",
    "1. For every user in the training set, build a model using their entire trip history.\n",
    "2. Consolidate these user-level models in data structure, preferably a dictionary.\n",
    "3. Now, when we want to perform inference on a new user with no prior trips, we use the similarity search to get the user ID in the training set who is the most similar to the user in question.\n",
    "4. We retrieve the model for this corresponding user and perform an inference. The hypothesis is that since the two users are similar, their trip substitution patterns are also similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48ee430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def drop_columns(df: pd.DataFrame):\n",
    "#     to_drop = [\n",
    "#         'source', 'end_ts', 'end_fmt_time', 'end_loc', 'raw_trip', 'start_ts', \n",
    "#         'start_fmt_time', 'start_loc', 'duration', 'distance', 'start_place', \n",
    "#         'end_place', 'cleaned_trip', 'inferred_labels', 'inferred_trip', 'expectation',\n",
    "#         'confidence_threshold', 'expected_trip', 'user_input', 'start:year', 'start:month', \n",
    "#         'start:day', 'start_local_dt_minute', 'start_local_dt_second', \n",
    "#         'start_local_dt_weekday', 'start_local_dt_timezone', 'end:year', 'end:month', 'end:day', \n",
    "#         'end_local_dt_minute', 'end_local_dt_second', 'end_local_dt_weekday', \n",
    "#         'end_local_dt_timezone', '_id', 'metadata_write_ts', 'additions', \n",
    "#         'mode_confirm', 'purpose_confirm', 'Mode_confirm', 'Trip_purpose', \n",
    "#         'original_user_id', 'program', 'opcode', 'Timestamp', 'birth_year', \n",
    "#         'available_modes', 'section_coordinates_argmax', 'section_mode_argmax'\n",
    "#     ]\n",
    "    \n",
    "#     # Drop section_mode_argmax and available_modes.\n",
    "#     return df.drop(\n",
    "#         columns=to_drop, \n",
    "#         inplace=False\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9e6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def construct_model_dictionary(train: pd.DataFrame):\n",
    "    \n",
    "#     def train_on_user(user_id: str):\n",
    "#         '''\n",
    "#         Given the training set and the user ID to query, filter the dataset and\n",
    "#         retain only the relevant trips. Then, create folds and optimize a model for this user.\n",
    "#         Return the trained model instance.\n",
    "#         '''\n",
    "        \n",
    "#         user_data = train.loc[train.user_id == user_id, :].reset_index(drop=True)\n",
    "        \n",
    "#         # Split user trips into train-test folds.\n",
    "#         u_train, u_test = train_test_split(user_data, test_size=0.2, shuffle=True, random_state=SEED)\n",
    "        \n",
    "#         user_model = estimate_using_model(\n",
    "#             u_train, u_test, \n",
    "#             n_iter=100\n",
    "#         )\n",
    "        \n",
    "#         return user_model\n",
    "    \n",
    "#     for user in train.user_id.unique():\n",
    "#         MODEL_DICT[user]['warm_start'] = train_on_user(user)\n",
    "#         print(50*'=')\n",
    "    \n",
    "#     print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a035c16",
   "metadata": {},
   "source": [
    "## Warm start:\n",
    "\n",
    "If the queried user has prior trips, we know that we we can harness the additional information. So if we encounter such a user, we will first find the most similar user (using only demographics). Once the most similar user is found, we query the trip model for the user and run inference through it.\n",
    "\n",
    "## Cold start:\n",
    "\n",
    "If the queried user has no prior trips, we will use the demo-only model. We first perform a similarity search and then run user inference through the demo-only model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c4e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiLevelModel:\n",
    "#     def __init__(self, model_dict: Dict, train: pd.DataFrame, test: pd.DataFrame, **model_kwargs):\n",
    "        \n",
    "#         self._demographics = [\n",
    "#             'primary_job_commute_time', 'income_category', 'n_residence_members', 'n_residents_u18', \n",
    "#             'n_residents_with_license', 'n_motor_vehicles', 'available_modes', 'age', 'gender_Man', \n",
    "#             'gender_Man;Nonbinary/genderqueer/genderfluid', 'gender_Nonbinary/genderqueer/genderfluid', \n",
    "#             'gender_Prefer not to say', 'gender_Woman', 'gender_Woman;Nonbinary/genderqueer/genderfluid', \n",
    "#             'has_drivers_license_No', 'has_drivers_license_Prefer not to say', 'has_drivers_license_Yes', \n",
    "#             'has_multiple_jobs_No', 'has_multiple_jobs_Prefer not to say', 'has_multiple_jobs_Yes', \n",
    "#             \"highest_education_Bachelor's degree\", 'highest_education_Graduate degree or professional degree', \n",
    "#             'highest_education_High school graduate or GED', 'highest_education_Less than a high school graduate', \n",
    "#             'highest_education_Prefer not to say', 'highest_education_Some college or associates degree', \n",
    "#             'primary_job_type_Full-time', 'primary_job_type_Part-time', 'primary_job_type_Prefer not to say', \n",
    "#             'primary_job_description_Clerical or administrative support', 'primary_job_description_Custodial', \n",
    "#             'primary_job_description_Education', 'primary_job_description_Food service', \n",
    "#             'primary_job_description_Manufacturing, construction, maintenance, or farming', \n",
    "#             'primary_job_description_Medical/healthcare', 'primary_job_description_Other', \n",
    "#             'primary_job_description_Professional, managerial, or technical', \n",
    "#             'primary_job_description_Sales or service', 'primary_job_commute_mode_Active transport', \n",
    "#             'primary_job_commute_mode_Car transport', 'primary_job_commute_mode_Hybrid', \n",
    "#             'primary_job_commute_mode_Public transport', 'primary_job_commute_mode_Unknown', \n",
    "#             'primary_job_commute_mode_WFH', 'is_overnight_trip', 'n_working_residents'\n",
    "#         ]\n",
    "        \n",
    "#         assert all([c in test.columns for c in self._demographics]), \"[test] Demographic features are missing!\"\n",
    "#         assert all([c in train.columns for c in self._demographics]), \"[train] Demographic features are missing!\"\n",
    "        \n",
    "#         self._mdict = model_dict\n",
    "#         self._train = train\n",
    "#         self._test = test\n",
    "#         self.metric = model_kwargs.pop('metric', SimilarityMetric.COSINE)\n",
    "        \n",
    "    \n",
    "#     def _phase1(self):\n",
    "        \n",
    "#         tr = self._train.copy()\n",
    "#         te = self._test.copy()\n",
    "        \n",
    "#         if tr.columns.isin(['user_id', 'target']).sum() == 2:\n",
    "#             tr = tr.drop(columns=['user_id', 'target']).reset_index(drop=True)\n",
    "        \n",
    "#         if te.columns.isin(['user_id', 'target']).sum() == 2:\n",
    "#             te = te.drop(columns=['user_id', 'target']).reset_index(drop=True)\n",
    "\n",
    "#         te_users = self._test.user_id.tolist()\n",
    "\n",
    "#         if self.metric == SimilarityMetric.COSINE:\n",
    "\n",
    "#             sim = cosine_similarity(te.values, tr.values)\n",
    "\n",
    "#             # Compute the argmax across the train set.\n",
    "#             argmax = np.argmax(sim, axis=1)\n",
    "\n",
    "#             # Retrieve the user_id at these indices.\n",
    "#             train_users = self._train.loc[argmax, 'user_id']\n",
    "\n",
    "#         elif self.metric == SimilarityMetric.EUCLIDEAN:\n",
    "\n",
    "#             sim = euclidean_distances(te.values, tr.values)\n",
    "\n",
    "#             # Compute the argmin here!\n",
    "#             argmin = np.argmin(sim, axis=1)\n",
    "\n",
    "#             # Retrieve the train user_ids.\n",
    "#             train_users = self._train.loc[argmin, 'user_id']\n",
    "\n",
    "#         return pd.DataFrame({'test_user_id': te_users, 'train_user_id': train_users})\n",
    "    \n",
    "    \n",
    "#     def _phase2(self, sim_df: pd.DataFrame, cold_start: bool):\n",
    "        \n",
    "#         prediction_df = list()\n",
    "        \n",
    "#         # Now, we use the sim_df to run inference based on whether \n",
    "#         for ix, row in sim_df.iterrows():\n",
    "#             train_user = row['train_user_id']\n",
    "            \n",
    "#             # Retrieve the appropriate model.\n",
    "#             user_models = self._mdict.get(train_user, None)\n",
    "            \n",
    "#             start_type = 'cold_start' if cold_start else 'warm_start'\n",
    "            \n",
    "#             # which specific model?\n",
    "#             sp_model = user_models.get(start_type, None)\n",
    "            \n",
    "#             # Now get the test user data.\n",
    "#             test_user = row['test_user_id']\n",
    "            \n",
    "#             if cold_start:\n",
    "#                 test_data = self._test.loc[self._test.user_id == test_user, self._demographics]\n",
    "#                 test_data = test_data.iloc[0, :]\n",
    "#             else:\n",
    "#                 test_data = self._test.loc[self._test.user_id == test_user, :]\n",
    "            \n",
    "#             predictions = sp_model.predict(test_data)\n",
    "            \n",
    "#             print(f\"test: [{test_user}], predictions: {predictions}\")\n",
    "    \n",
    "    \n",
    "#     def execute_pipeline(self, cold_start: bool = False):\n",
    "#         # For each test user, get the most similar train user.\n",
    "#         sim_df = self._phase1()\n",
    "        \n",
    "#         predictions = self._phase2(sim_df, cold_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb63632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FULL DATA.\n",
    "# train = df.loc[df.user_id.isin(TRAIN_USERS), :]\n",
    "# test = df.loc[df.user_id.isin(TEST_USERS), :]\n",
    "\n",
    "# train_counts = train.user_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2528eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## We only want to train on users who have a good number of trips.\n",
    "# good_users = train_counts[train_counts >= 100].index\n",
    "\n",
    "# bad_users = train_counts[train_counts < 100].index\n",
    "\n",
    "# print(f\"Number of users filtered out of training: {len(bad_users)}\")\n",
    "\n",
    "# filtered_train = train.loc[train.user_id.isin(good_users), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae55b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Full data.\n",
    "\n",
    "# train_df = drop_columns(filtered_train)\n",
    "# test_df = drop_columns(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d0e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37febd6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_dict = construct_model_dictionary(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1249925",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emission",
   "language": "python",
   "name": "emission"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
