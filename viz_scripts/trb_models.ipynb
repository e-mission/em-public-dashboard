{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = None\n",
    "month = None\n",
    "program = \"prepilot\"\n",
    "study_type = \"program\"\n",
    "mode_of_interest = \"pilot_ebike\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = '/plots/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL not formatted, defaulting to \"Stage_database\"\n",
      "Connecting to database URL db\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "\n",
    "from plots import *\n",
    "import scaffolding\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'biogeme'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_246/1955144580.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbiogeme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabase\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbiogeme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiogeme\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbiogeme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'biogeme'"
     ]
    }
   ],
   "source": [
    "# Settings and imports specific to this notebook\n",
    "\n",
    "include_replaced_modes_as_valid = True # Flip this when we want to get results versus generate the replaced_mode correction graphs\n",
    "model_with_sensed = False\n",
    "input_dataset = \"ONLY_LABELED\" # \"ONLY_LABELED\", \"ONLY_SENSED\" or \"BEST_AVAILABLE\" for sensitivity analysis\n",
    "LABEL_ASSIST_THRESHOLD = 0.3\n",
    "\n",
    "# !apt-get update\n",
    "# !apt-get install gcc -y\n",
    "# !apt-get install g++ -y\n",
    "# !pip install biogeme\n",
    "# !pip install tqdm\n",
    "\n",
    "import datetime\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "import biogeme.models as models\n",
    "import biogeme.distributions as dist\n",
    "from biogeme.expressions import Beta, DefineVariable, RandomVariable, exp, PanelLikelihoodTrajectory, bioDraws, log, MonteCarlo, Integrate\n",
    "import biogeme.results as res\n",
    "import pickle\n",
    "import sklearn.metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import emission.core.get_database as edb\n",
    "import emission.core.wrapper.entry as ecwe\n",
    "import emission.storage.decorations.analysis_timeseries_queries as esda\n",
    "import emission.storage.decorations.trip_queries as esdt\n",
    "import emission.storage.decorations.timeline as esdl\n",
    "import emission.storage.timeseries.abstract_timeseries as esta\n",
    "import emission.storage.timeseries.timequery as estt\n",
    "from uuid import UUID\n",
    "import replacement_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reloading modules from Jupyter\n",
    "import importlib\n",
    "importlib.reload(replacement_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not run this notebook at all unless it is for a program; nbclient will run up through this cell\n",
    "if study_type != \"program\":\n",
    "    raise Exception(\"The plots in this notebook are only relevant to programs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading mapping dictionaries from mapping_dictionaries notebook\n",
    "%store -r dic_re\n",
    "%store -r dic_pur\n",
    "\n",
    "# convert a dictionary to a defaultdict\n",
    "dic_re = defaultdict(lambda: 'Other',dic_re)\n",
    "dic_pur = defaultdict(lambda: 'Other',dic_pur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Data From Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_ct, file_suffix, quality_text = scaffolding.load_viz_notebook_data(year,\n",
    "                                                                            month,\n",
    "                                                                            program,\n",
    "                                                                            study_type,\n",
    "                                                                            dic_re,\n",
    "                                                                            dic_pur=dic_pur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the expanded database data to socioeconomic data\n",
    "socio_data = pd.read_csv('./Can Do Colorado eBike Program - en.csv')\n",
    "socio_data.rename(columns={'Unique User ID (auto-filled, do not edit)':'user_id',\n",
    "                          'Please identify which category represents your total household income, before taxes, for last year.':'HHINC',\n",
    "                          'How many motor vehicles are owned, leased, or available for regular use by the people who currently live in your household?':'VEH',\n",
    "                           'In which year were you born?':'AGE',\n",
    "                          'Including yourself, how many people live in your home?':'HHSIZE',\n",
    "                          'How many children under age 18 live in your home?':'CHILDREN',\n",
    "                          'What is your gender?':'GENDER',\n",
    "                          'If you were unable to use your household vehicle(s), which of the following options would be available to you to get you from place to place?':'available_modes',\n",
    "                          'Are you a student?':'STUDENT'}, inplace=True)\n",
    "socio_data = socio_data[~socio_data.user_id.isnull()]\n",
    "\n",
    "# Deal with people who have multiple responses by using most recent\n",
    "socio_data = socio_data.sort_values(by=['user_id', 'Timestamp'])\n",
    "socio_data.drop_duplicates(subset=['user_id'], keep='last', inplace=True)\n",
    "socio_data['user_id_socio'] = socio_data.user_id\n",
    "socio_data = socio_data.drop(labels='user_id', axis=1)\n",
    "\n",
    "# Lose some trips due to people with no survey responses\n",
    "expanded_ct['user_id_socio'] = expanded_ct.user_id.astype(str)\n",
    "expanded_ct.user_id_socio = [i.replace('-','') for i in expanded_ct.user_id_socio] # remove all dashes from strings\n",
    "expanded_ct = expanded_ct.merge(socio_data, on='user_id_socio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add non-label category\n",
    "expanded_ct['replaced_mode'] = expanded_ct['replaced_mode'].fillna('Unlabeled')\n",
    "expanded_ct.loc[expanded_ct['replaced_mode'] == 'Unlabeled', 'Replaced_mode'] = \"Unlabeled\"\n",
    "\n",
    "# Select variables of interest from complete OpenPATH data\n",
    "data = expanded_ct[['Mode_confirm','Replaced_mode','replaced_mode','Trip_purpose','duration','distance_miles','start_local_dt_weekday','available_modes','AGE','HHINC','VEH','HHSIZE','CHILDREN','GENDER','STUDENT','user_id','_id','start_local_dt_year','start_local_dt_month','start_local_dt_day','cleaned_trip','start_fmt_time']].copy()\n",
    "\n",
    "# List of variables to keep in data but not turn into categorical number variables\n",
    "dont_categorize = ['user_id','_id','cleaned_trip']\n",
    "\n",
    "# Make copy of user_id to be categorized since both versions are needed\n",
    "data['user_id_int'] = data['user_id']\n",
    "\n",
    "# Get timestamp from known year/month/day aggregated to days\n",
    "data.rename(columns={'start_local_dt_year':'year','start_local_dt_month':'month','start_local_dt_day':'day'}, inplace=True)\n",
    "data['date_time'] = pd.to_datetime(data[['year','month','day']])\n",
    "data = data.drop(columns=['year','day'])\n",
    "\n",
    "# Get time of day\n",
    "data['hour'] = [int(x[1][:2]) for x in expanded_ct.start_fmt_time.str.split('T')]\n",
    "\n",
    "# Fix age\n",
    "data['AGE'] = 2022 - data['AGE']\n",
    "\n",
    "# Recoded Cyclical Time of Day\n",
    "hours_in_day = 24\n",
    "months_in_year = 12\n",
    "data['sin_time'] = np.sin(2*np.pi*data.hour/hours_in_day)\n",
    "data['cos_time'] = np.cos(2*np.pi*data.hour/hours_in_day)\n",
    "data['sin_month'] = np.sin(2*np.pi*data.month/months_in_year)\n",
    "data['cos_month'] = np.cos(2*np.pi*data.month/months_in_year)\n",
    "\n",
    "# Duration in minutes\n",
    "data['duration'] = data['duration'] / 60\n",
    "\n",
    "# Filter out some responses to data\n",
    "data = data[~data['Mode_confirm'].isin(['Not a Trip','Other'])]\n",
    "data = data[~data['Replaced_mode'].isin(['Not a Trip','Other'])]\n",
    "data = data[~data['available_modes'].isin(['None', 'Prefer not to say'])]\n",
    "data = data[~data['Trip_purpose'].isin(['not_a_trip','Other'])]\n",
    "data = data[~data['HHINC'].isin(['Prefer not to say'])]\n",
    "\n",
    "# Combine variable categories\n",
    "data = data.replace('Gas Car, drove alone', 'car')\n",
    "data = data.replace('Gas Car, with others', 's_car')\n",
    "data = data.replace('Bikeshare', 's_micro')\n",
    "data = data.replace('Scooter share', 's_micro')\n",
    "data = data.replace('Regular Bike', 'p_micro')\n",
    "data = data.replace('Skate board', 'p_micro')\n",
    "data = data.replace('Train', 'transit')\n",
    "data = data.replace('Free Shuttle', 'transit')\n",
    "data = data.replace('Bus', 'transit')\n",
    "data = data.replace('Walk', 'walk')\n",
    "data = data.replace('Taxi/Uber/Lyft', 'ridehail')\n",
    "data = data.replace('E-bike', 'ebike')\n",
    "\n",
    "data['start_local_dt_weekday'] = data['start_local_dt_weekday'].replace(['1','2','3','4','5'],'1')\n",
    "data['start_local_dt_weekday'] = data['start_local_dt_weekday'].replace(['0','6'],'0')\n",
    "\n",
    "data.HHINC = data.HHINC.replace(['Less than $24,999',\n",
    "                                       '$25,000-$49,999',\n",
    "                                       '$50,000-$99,999',\n",
    "                                       '$100,000 -$149,999',\n",
    "                                       '$150,000-$199,999',\n",
    "                                       '$200,000 or more'], [12500,37500,75000,125000,175000,250000])\n",
    "\n",
    "# OHE encode categorical features (keep record)\n",
    "keep = data['Trip_purpose']\n",
    "data = pd.get_dummies(data, columns=['Trip_purpose'], prefix=['purp'])\n",
    "data['Trip_purpose'] = keep\n",
    "\n",
    "# keep = data['month']\n",
    "# data = pd.get_dummies(data, columns=['month'], prefix=['month'])\n",
    "# data['month'] = keep\n",
    "\n",
    "# Calculate travel times for each trip, across every mode\n",
    "def add_all_mode_tt(data, mode_col, duration_col, dist_col):\n",
    "    mode_travel_times = {}\n",
    "    for mode in pd.unique(data[mode_col]):\n",
    "\n",
    "        # Linear model for duration based on distance for trips belonging to each mode\n",
    "        mode_data = data[data[mode_col]==mode]\n",
    "        regr = linear_model.LinearRegression()\n",
    "        regr.fit(mode_data[dist_col].values.reshape(-1,1), mode_data[duration_col].values.reshape(-1,1))\n",
    "\n",
    "        # Make prediction for ALL trips\n",
    "        mode_duration_pred = regr.predict(data[dist_col].values.reshape(-1,1))\n",
    "        mode_travel_times['tt_'+mode] = mode_duration_pred\n",
    "\n",
    "    # Apply for each mode existing in the dataframe\n",
    "    for mode in mode_travel_times:\n",
    "        data[mode] = mode_travel_times[mode]\n",
    "\n",
    "    return data\n",
    "\n",
    "# Calculate all mode travel times and add to dataframe\n",
    "data = add_all_mode_tt(data,'Mode_confirm','duration','distance_miles')\n",
    "\n",
    "# Calculate vehicle costs based roughly on $/mi from: https://www.vtpi.org/tca/tca0501.pdf\n",
    "cost_factors = {'car':0.80,\n",
    "                's_car':0.40,\n",
    "                'ridehail':3.00,\n",
    "                's_micro':1.50,\n",
    "                'transit':0.40}\n",
    "\n",
    "def add_all_mode_cost(data, cost_factors, dist_col):\n",
    "    for factor in cost_factors:\n",
    "        data['cost_'+factor] = cost_factors[factor] * data[dist_col]\n",
    "    return data\n",
    "\n",
    "# Calculate all mode travel costs and add to dataframe\n",
    "add_all_mode_cost(data, cost_factors, 'distance_miles')\n",
    "\n",
    "# Normalize mode cost by income\n",
    "for mode in cost_factors.keys():\n",
    "    data[f\"cost_{mode}\"] = data[f\"cost_{mode}\"] / (data['HHINC'] / 1000)\n",
    "\n",
    "# Labels for modes in the availability survey\n",
    "availability_codes = {'Public transportation (bus, subway, light rail, etc.)':'transit',\n",
    "                      'Get a ride from a friend or family member':'s_car',\n",
    "                      'Rental car (including Zipcar/ Car2Go)':'car',\n",
    "                      'Taxi (regular taxi, Uber, Lyft, etc)':'ridehail',\n",
    "                      'Bicycle':'p_micro',\n",
    "                      'Shared bicycle or scooter':'s_micro',\n",
    "                      'Walk/roll':'walk',\n",
    "                      'Skateboard':'p_micro',\n",
    "                      'ebike':'ebike',\n",
    "                      'None':'none'}\n",
    "\n",
    "def add_mode_availability(data, availability_codes, availability_col, choice_col, replaced_col, is_sp):\n",
    "    mode_list = np.unique(list(availability_codes.values())[:-1])\n",
    "    choice_list = data[choice_col].values\n",
    "    replaced_list = data[replaced_col].values\n",
    "    for mode in mode_list:\n",
    "        mode_avail = []\n",
    "        for i, available in enumerate(data[availability_col].values):\n",
    "            available_modes = [availability_codes[x] for x in available.split(';')]\n",
    "            # For SP: Replacement/stated available should be 1, chosen should be 0\n",
    "            if is_sp:\n",
    "                if mode==choice_list[i]:\n",
    "                    mode_check = False\n",
    "                else:\n",
    "                    mode_check = mode==replaced_list[i] or mode in available_modes\n",
    "            # For RP: Chosen/replacement/stated available should be 1\n",
    "            else:\n",
    "                mode_check = mode==choice_list[i] or mode==replaced_list[i] or mode in available_modes\n",
    "            # Keep binary list of which trips the mode was available for\n",
    "            if mode_check:\n",
    "                mode_avail.append(1)\n",
    "            else:\n",
    "                mode_avail.append(0)\n",
    "        # For each mode add a column with binary availability\n",
    "        data['av_'+mode] = mode_avail\n",
    "\n",
    "    return data\n",
    "\n",
    "# Split data into revealed choice and stated replacement choice (2 obs per trip)\n",
    "data_rp = data.copy()\n",
    "data_sp = data.copy()\n",
    "data_rp['is_sp'] = False\n",
    "data_sp['is_sp'] = True\n",
    "data_rp['mode_choice'] = data_rp['Mode_confirm']\n",
    "data_sp['mode_choice'] = data_sp['Replaced_mode']\n",
    "\n",
    "# The SP data cannot include trips where the chosen/replaced modes are stated the same\n",
    "# because we need to mark the chosen mode as unavailable in the SP data, which breaks the model if they're the same\n",
    "data_sp = data_sp[data_sp.Mode_confirm!=data_sp.Replaced_mode]\n",
    "\n",
    "# Make sure both chosen and replaced modes are in choice sets\n",
    "data_rp = add_mode_availability(data_rp, availability_codes, 'available_modes', 'Mode_confirm', 'Replaced_mode', is_sp=False)\n",
    "data_sp = add_mode_availability(data_sp, availability_codes, 'available_modes', 'Mode_confirm', 'Replaced_mode', is_sp=True)\n",
    "\n",
    "# Combine RP/SP data. Keep RP data separate with a few additional columns for later analysis.\n",
    "data = pd.concat([data_rp, data_sp])\n",
    "data = data[~data['Replaced_mode'].isin(['Unlabeled', 'No Travel'])]\n",
    "\n",
    "# Handle all variables that are ordinal; otherwise they may not end up in correct order\n",
    "# Make sure that all mode variables align after being converted to numeric variables\n",
    "mode_list = ['car','s_car','ridehail','transit','p_micro','s_micro','walk','ebike']\n",
    "data.mode_choice = pd.Categorical(data.mode_choice, ordered=True, categories=mode_list)\n",
    "data.Mode_confirm = pd.Categorical(data.Mode_confirm, ordered=True, categories=mode_list)\n",
    "data.Replaced_mode = pd.Categorical(data.Replaced_mode, ordered=True, categories=mode_list)\n",
    "\n",
    "# Convert categorical variables to numeric\n",
    "cat_columns = data.select_dtypes(['object','category']).columns\n",
    "cat_columns = cat_columns.drop(labels=dont_categorize)\n",
    "all_categories = []\n",
    "for i in range(0,len(cat_columns)):\n",
    "    # Keep a record of what order the categories are in when converted\n",
    "    var_categories = data[cat_columns].astype('category').iloc[:,i].cat.categories\n",
    "    all_categories.append(var_categories)\n",
    "data[cat_columns] = data[cat_columns].apply(lambda x: x.astype('category').cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show listed categories in their order\n",
    "cat_code_lookup = dict(zip(cat_columns.values, [list(x.values) for x in all_categories]))\n",
    "cat_code_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setting up dataframes for different analyses throughout the notebook\n",
    "\n",
    "# Only ebike, labeled trips\n",
    "df_ebike = data_rp[data_rp['Mode_confirm'].isin(['ebike'])].copy()\n",
    "df_ebike = df_ebike[~df_ebike['Replaced_mode'].isin(['Unlabeled','No Travel'])]\n",
    "\n",
    "# Only ebike, unlabeled trips\n",
    "df_ebike_unlabeled = data_rp[data_rp['Mode_confirm'].isin(['ebike'])].copy()\n",
    "df_ebike_unlabeled = df_ebike_unlabeled[df_ebike_unlabeled['Replaced_mode'].isin(['Unlabeled'])].copy()\n",
    "\n",
    "# Only ebike, new trips\n",
    "df_ebike_new_travel = data_rp[data_rp['Mode_confirm'].isin(['ebike'])].copy()\n",
    "df_ebike_new_travel = df_ebike_new_travel[df_ebike_new_travel['Replaced_mode'].isin(['No Travel'])]\n",
    "\n",
    "# RP data only for basic stats and analysis (Removed unlabeled and no travel)\n",
    "df_rp = data[data['is_sp']==False]\n",
    "\n",
    "# For analysis of accurately stated replacements\n",
    "df_replaced_trips = data_rp[~data_rp['Replaced_mode'].isin(['No Travel','Unlabeled'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up K-fold cross validation\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "# Collect all scores to show at end of modeling\n",
    "score_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that mode availability is being set properly\n",
    "# mode_choice should always be available; in RP it is Mode_confirm in SP it is Replaced_mode\n",
    "for i, mode in enumerate(cat_code_lookup['mode_choice']):\n",
    "    print(mode)\n",
    "    assert sum(data[data['mode_choice']==i][f\"av_{mode}\"]) == len(data[data['mode_choice']==i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data stats\n",
    "print(f\"Trips: {len(df_rp)}\")\n",
    "print(f\"Observed Choices: {len(data)}\")\n",
    "print(f\"Users: {len(np.unique(data.user_id))}\")\n",
    "print(f\"Trips per user: {len(data) / len(pd.unique(data.user_id))}\")\n",
    "print(f\"New activity: {len(df_ebike_new_travel) / len(df_ebike)}\")\n",
    "print(f\"Ebike all trips: {len(df_ebike)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['tt_ebike', 'tt_s_car', 'tt_walk', 'tt_p_micro',\n",
    "       'tt_car', 'tt_transit', 'tt_s_micro', 'tt_ridehail', 'cost_car',\n",
    "       'cost_s_car', 'cost_ridehail', 'cost_s_micro', 'cost_transit', 'av_car', 'av_ebike', 'av_p_micro',\n",
    "       'av_ridehail', 'av_s_car', 'av_s_micro', 'av_transit', 'av_walk','purp_Entertainment/Social', 'purp_Home', 'purp_Meal',\n",
    "       'purp_Personal/Medical', 'purp_Recreation/Exercise', 'purp_Religious',\n",
    "       'purp_School', 'purp_Shopping', 'purp_Transit transfer', 'purp_Work','start_local_dt_weekday','sin_time', 'cos_time','sin_month','cos_month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on All Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test model\n",
    "rf, accuracy, f1, confusion = replacement_models.gbdt(data, 'mode_choice', feature_list, kf)\n",
    "\n",
    "# Save scores for model comparison\n",
    "score_results['rf_chosen_chosen'] = (np.mean(accuracy), np.mean(f1))\n",
    "print(f\"Accuracy: {np.mean(accuracy)}\")\n",
    "print(f\"F1: {np.mean(f1)}\")\n",
    "\n",
    "# Average and plot the confusion matrices\n",
    "confusion_mean = np.mean(np.array(confusion), axis=0)\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.heatmap(confusion_mean, annot=True, fmt='.1%', cmap='YlGnBu', linewidths=.5, xticklabels=all_categories[0].values, yticklabels=all_categories[0].values, cbar=False).set(title='Random Forest Confusion Matrix (Chosen)', xlabel='Predicted', ylabel='Actual')\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "\n",
    "rf_keep = rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on Chosen Test on Holdout Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test model (10 users for now)\n",
    "accuracy_holdout = []\n",
    "f1_holdout = []\n",
    "confusion_holdout = []\n",
    "for user in list(np.unique(df_rp.user_id))[:10]:\n",
    "\n",
    "    # Remove user from training data, keep only user in test data\n",
    "    labeled_df = data[data['user_id']!=user]\n",
    "    unlabeled_df = df_rp[df_rp['user_id']==user]\n",
    "\n",
    "    # Set the chosen mode availability to 0\n",
    "    for i in range(0,len(unlabeled_df)):\n",
    "        unlabeled_df[f\"av_{mode_list[unlabeled_df['Mode_confirm'].iloc[i]]}\"].iat[i] = 0\n",
    "\n",
    "    # Train on all trips by other users\n",
    "    rf, accuracy, f1, confusion = replacement_models.rf(labeled_df, 'mode_choice', feature_list, kf)\n",
    "\n",
    "    # Test on the stated replacement for holdout user\n",
    "    X_test = unlabeled_df[feature_list].values\n",
    "    y_pred = rf.predict(X_test)\n",
    "    y_test = unlabeled_df['Replaced_mode'].values\n",
    "\n",
    "    accuracy_holdout.append(sklearn.metrics.accuracy_score(y_test, y_pred))\n",
    "    f1_holdout.append(sklearn.metrics.f1_score(y_test, y_pred, average='weighted'))\n",
    "    confusion_holdout.append(sklearn.metrics.confusion_matrix(y_test, y_pred, labels=[0,1,2,3,4,5,6,7], normalize='pred'))\n",
    "\n",
    "# Save scores for model comparison\n",
    "score_results['rf_holdout_replaced'] = (np.mean(accuracy_holdout), np.mean(f1_holdout))\n",
    "print(f\"Accuracy: {np.mean(accuracy_holdout)}\")\n",
    "print(f\"F1: {np.mean(f1_holdout)}\")\n",
    "\n",
    "# Average and plot the confusion matrices\n",
    "confusion_mean = np.mean(confusion_holdout, axis=0).reshape(8,8)\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.heatmap(confusion_mean, annot=True, fmt='.1%', cmap='YlGnBu', linewidths=.5, xticklabels=all_categories[0].values, yticklabels=all_categories[0].values, cbar=False).set(title='Random Forest Confusion Matrix (Holdout)', xlabel='Predicted', ylabel='Actual')\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on n Samples Chosen Test on Replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test model\n",
    "samples_min = []\n",
    "user_min = []\n",
    "accuracy_min = []\n",
    "f1_min = []\n",
    "for n_samples in range(10,200,10):\n",
    "\n",
    "    # Sample n training data points from all users\n",
    "    labeled_df = data.sample(n_samples)\n",
    "\n",
    "    # Construct model (accuracy/f1 don't matter here; we re-test per user below)\n",
    "    rf, accuracy, f1, confusion = replacement_models.rf(labeled_df, 'mode_choice', feature_list, kf)\n",
    "\n",
    "    # Test on the stated replacement for holdout user\n",
    "    for user in list(np.unique(df_rp.user_id))[:10]:\n",
    "        unlabeled_df = df_rp[df_rp['user_id']==user]\n",
    "\n",
    "        # Set the chosen mode availability to 0\n",
    "        for i in range(0,len(unlabeled_df)):\n",
    "            unlabeled_df[f\"av_{mode_list[unlabeled_df['Mode_confirm'].iloc[i]]}\"].iat[i] = 0\n",
    "\n",
    "        # Test on the stated replacement for holdout user\n",
    "        X_test = unlabeled_df[feature_list].values\n",
    "        y_pred = rf.predict(X_test)\n",
    "        y_test = unlabeled_df['Replaced_mode'].values\n",
    "\n",
    "        accuracy_min.append(sklearn.metrics.accuracy_score(y_test, y_pred))\n",
    "        f1_min.append(sklearn.metrics.f1_score(y_test, y_pred, average='weighted'))\n",
    "        samples_min.append(n_samples)\n",
    "        user_min.append(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.DataFrame({'samples_min':samples_min, 'user_min':user_min, 'accuracy_min':accuracy_min, 'f1_min':f1_min})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,6))\n",
    "sns.boxplot(ax=ax, data=plot_data, x='samples_min', y='accuracy_min', color='purple').set(title='Accuracy on n Samples', xlabel='n Samples', ylabel='Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.DataFrame({'samples_min':samples_min, 'accuracy_min':accuracy_min, 'f1_min':f1_min})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,6))\n",
    "sns.barplot(ax=ax, data=plot_data, x='samples_min', y='accuracy_min', color='darkblue').set(title='Accuracy on n Samples', xlabel='n Samples', ylabel='Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choice Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MXL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on All Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train and test model\n",
    "mxl, accuracy, f1, confusion = replacement_models.mxl(data, 'mode_choice')\n",
    "\n",
    "# Save scores for model comparison\n",
    "score_results['mxl_chosen_chosen'] = (np.mean(accuracy), np.mean(f1))\n",
    "print(f\"Accuracy: {np.mean(accuracy)}\")\n",
    "print(f\"F1: {np.mean(f1)}\")\n",
    "\n",
    "# Average and plot the confusion matrices\n",
    "confusion_mean = np.mean(np.array(confusion), axis=0)\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.heatmap(confusion_mean, annot=True, fmt='.1%', cmap='YlGnBu', linewidths=.5, xticklabels=all_categories[0].values, yticklabels=all_categories[0].values, cbar=False).set(title='MXL Confusion Matrix', xlabel='Predicted', ylabel='Actual')\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "\n",
    "# Save model parameters for prediction\n",
    "mxl_keep = mxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on All Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train and test model\n",
    "mnl, accuracy, f1, confusion = replacement_models.mnl(data, 'mode_choice', kf)\n",
    "\n",
    "# Save scores for model comparison\n",
    "score_results['mnl_chosen_chosen'] = (np.mean(accuracy), np.mean(f1))\n",
    "print(f\"Accuracy: {np.mean(accuracy)}\")\n",
    "print(f\"F1: {np.mean(f1)}\")\n",
    "\n",
    "# Average and plot the confusion matrices\n",
    "confusion_mean = np.mean(np.array(confusion), axis=0)\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.heatmap(confusion_mean, annot=True, fmt='.1%', cmap='YlGnBu', linewidths=.5, xticklabels=all_categories[0].values, yticklabels=all_categories[0].values, cbar=False).set(title='MNL Confusion Matrix', xlabel='Predicted', ylabel='Actual')\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "\n",
    "mnl_keep = mnl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(score_results.keys(), score_results.values()).reset_index()\n",
    "score_df.columns = ['Accuracy','F1','Model']\n",
    "model_types = score_df['Model'].str.split('_', expand=True)\n",
    "model_types.columns = ['Model Type','Train Set','Test Set']\n",
    "score_df = pd.concat([score_df, model_types], axis=1)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various model performances\n",
    "plot_data = score_df[score_df['Train Set']=='chosen']\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Test Set', y='Accuracy', hue='Model Type').set(title='Model Accuracy Trained on Primary', xlabel='Model', ylabel='Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various model performances\n",
    "plot_data = score_df[score_df['Train Set']=='chosen']\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Test Set', y='F1', hue='Model Type').set(title='Model F1 Trained on Primary', xlabel='Model', ylabel='F1')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various model performances\n",
    "plot_data = score_df\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Model', y='Accuracy').set(title='Model Accuracy', xlabel='Model', ylabel='Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various model performances\n",
    "plot_data = score_df\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Model', y='F1').set(title='Model F1', xlabel='Model', ylabel='F1')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ebike Substitution Rates and Emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitution rate of ebike trips not including new trips\n",
    "plot_data = df_ebike.groupby(['Replaced_mode']).count()[['Mode_confirm']].reset_index()\n",
    "plot_data['subst_rate'] = plot_data['Mode_confirm'] / sum(plot_data['Mode_confirm'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Replaced_mode', y='subst_rate').set(title='Ebike Mode Replacement', xlabel='Replaced Mode', ylabel='Substitution Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "print(plot_data['subst_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitution rate of ebike trips not including new trips\n",
    "# Set the chosen mode availability to 0\n",
    "for i in range(0,len(df_ebike_unlabeled)):\n",
    "    df_ebike_unlabeled[f\"av_{df_ebike_unlabeled['Mode_confirm'].iloc[i]}\"].iat[i] = 0\n",
    "\n",
    "# Predict replaced mode for the unlabeled trips\n",
    "y_pred = rf_keep.predict(df_ebike_unlabeled[feature_list].values)\n",
    "df_ebike_unlabeled['Replaced_mode'] = [mode_list[y] for y in y_pred]\n",
    "\n",
    "# Combine labeled and predicted-unlabeled ebike trips\n",
    "plot_data = pd.concat([df_ebike, df_ebike_unlabeled])\n",
    "plot_data = plot_data.groupby(['Replaced_mode']).count()[['Mode_confirm']].reset_index()\n",
    "plot_data['subst_rate'] = plot_data['Mode_confirm'] / sum(plot_data['Mode_confirm'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Replaced_mode', y='subst_rate').set(title='Ebike Mode Replacement (w/Labeling)', xlabel='Replaced Mode', ylabel='Substitution Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "print(plot_data['subst_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From df_EI\n",
    "# Combine variable categories\n",
    "df_EI = df_EI.replace('Car, drove alone', 'car')\n",
    "df_EI = df_EI.replace('Car, with others', 's_car')\n",
    "df_EI = df_EI.replace('Bikeshare', 's_micro')\n",
    "df_EI = df_EI.replace('Scooter share', 's_micro')\n",
    "df_EI = df_EI.replace('Regular Bike', 'p_micro')\n",
    "df_EI = df_EI.replace('Skate board', 'p_micro')\n",
    "df_EI = df_EI.replace('Train', 'transit')\n",
    "df_EI = df_EI.replace('Free Shuttle', 'transit')\n",
    "df_EI = df_EI.replace('Bus', 'transit')\n",
    "df_EI = df_EI.replace('Walk', 'walk')\n",
    "df_EI = df_EI.replace('Taxi/Uber/Lyft', 'ridehail')\n",
    "df_EI = df_EI.replace('Pilot ebike', 'ebike')\n",
    "emission_rates = df_EI.groupby(['mode']).mean().reset_index()[['mode','energy_intensity_factor','CO2_factor']]\n",
    "emission_rates['g_CO2_per_passmi'] = emission_rates.energy_intensity_factor*emission_rates.CO2_factor*0.000001*453.592\n",
    "emission_data = plot_data.merge(emission_rates, left_on='Replaced_mode', right_on='mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From df_EI\n",
    "emission_rates = emission_data.g_CO2_per_passmi.values\n",
    "subst_rates = emission_data.subst_rate.values\n",
    "\n",
    "# g-CO2/mi reduction through ebike availability\n",
    "sum(emission_rates * subst_rates) / sum(subst_rates) - 0.007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From table in paper\n",
    "emission_rates = [343.3, 18.5, 343.3, (343.3/2), 39.8, 123.8, 0.0]\n",
    "subst_rates = plot_data['subst_rate'].values\n",
    "\n",
    "# g-CO2/mi reduction through ebike availability\n",
    "sum(emission_rates * subst_rates) / sum(subst_rates) - 39.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Replaced Mode Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av = {0: 'av_car',\n",
    "      1: 'av_s_car',\n",
    "      2: 'av_ridehail',\n",
    "      3: 'av_transit',\n",
    "      4: 'av_p_micro',\n",
    "      5: 'av_s_micro',\n",
    "      6: 'av_walk',\n",
    "      7: 'av_ebike'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_list = [df_replaced_trips[f\"av_{x}\"].iloc[i] for i, x in enumerate(df_replaced_trips.Replaced_mode)]\n",
    "df_replaced_trips['replaced_in_stated'] = replaced_list\n",
    "\n",
    "# Relabel with original mode names for plotting\n",
    "for mode in av:\n",
    "    mode_text = '_'.join(str(av[mode]).split('_')[1:])\n",
    "    df_replaced_trips['Mode_confirm'] = df_replaced_trips['Mode_confirm'].replace(mode,mode_text)\n",
    "    df_replaced_trips['Replaced_mode'] = df_replaced_trips['Replaced_mode'].replace(mode,mode_text)\n",
    "\n",
    "df_replaced_trips['Mode_confirm'] = df_replaced_trips['Mode_confirm'].replace(7,'ebike')\n",
    "df_replaced_trips['Replaced_mode'] = df_replaced_trips['Replaced_mode'].replace(7,'ebike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurately stated replacement mode for all users\n",
    "plot_data = df_replaced_trips[df_replaced_trips['Mode_confirm']=='ebike']\n",
    "plot_data = plot_data.groupby(['date_time'], as_index=False)['replaced_in_stated'].agg(['sum','count']).apply(lambda x: x.rolling(14,1).mean())\n",
    "plot_data['proportion'] = plot_data['sum'] / plot_data['count']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.lineplot(ax=ax, data=plot_data, x='date_time', y='proportion').set(title='Proportion of Daily E-Bike Trips With Correctly Stated Replacement Mode', xlabel='Date', ylabel='Proportion Correct')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurately stated replacement mode for all users across modes\n",
    "plot_data = df_replaced_trips.groupby(['Mode_confirm'], as_index=False)['replaced_in_stated'].agg(['sum','count']).reset_index()\n",
    "plot_data['proportion'] = 1 - (plot_data['sum'] / plot_data['count'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Mode_confirm', y='proportion').set(title='Proportion of Infeasible Replacements by Primary Mode', xlabel='Primary Mode', ylabel='Proportion Incorrect')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurately stated replacement mode for all users across modes\n",
    "plot_data = df_replaced_trips.groupby(['Replaced_mode'], as_index=False)['replaced_in_stated'].agg(['sum','count']).reset_index()\n",
    "plot_data['proportion'] = 1 - (plot_data['sum'] / plot_data['count'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Replaced_mode', y='proportion').set(title='Proportion of Infeasible Replacements by Replaced Mode', xlabel='Stated Mode Replaced', ylabel='Proportion Incorrect')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurately stated replacement mode for all users\n",
    "df_replaced_trips.user_id = df_replaced_trips.user_id.astype(str)\n",
    "plot_data = df_replaced_trips.groupby(['user_id'], as_index=False)['replaced_in_stated'].agg(['sum','count']).reset_index()\n",
    "plot_data['proportion'] = plot_data['sum'] / plot_data['count']\n",
    "plot_data = plot_data.sort_values('proportion', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='user_id', y='proportion', color='darkblue').set(title='Proportion of Trips With Correctly Stated Replacement Mode', xlabel='User', ylabel='Proportion Correct')\n",
    "plt.xticks(rotation=90)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurately stated replacement mode for all users\n",
    "df_replaced_trips.user_id = df_replaced_trips.user_id.astype(str)\n",
    "plot_data = df_replaced_trips.groupby(['user_id'], as_index=False)['replaced_in_stated'].agg(['sum','count']).reset_index()\n",
    "plot_data['incorrect'] = plot_data['count'] - plot_data['sum']\n",
    "plot_data['user_id'] = plot_data['user_id'].astype(str).str[-4:]\n",
    "plot_data = plot_data.sort_values('incorrect', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='user_id', y='incorrect', color='darkblue').set(title='Trips With Unavailable Stated Replacement Mode', xlabel='User', ylabel='Count Incorrect')\n",
    "plt.xticks(rotation=90)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
