{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = None\n",
    "month = None\n",
    "program = \"prepilot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import datetime\n",
    "\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "import biogeme.models as models\n",
    "import biogeme.distributions as dist\n",
    "from biogeme.expressions import Beta, DefineVariable, RandomVariable, bioDraws, log, MonteCarlo, Integrate\n",
    "import biogeme.results as res\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import emission.core.get_database as edb\n",
    "import emission.core.wrapper.entry as ecwe\n",
    "import emission.storage.decorations.analysis_timeseries_queries as esda\n",
    "import emission.storage.decorations.trip_queries as esdt\n",
    "import emission.storage.decorations.timeline as esdl\n",
    "import emission.storage.timeseries.abstract_timeseries as esta\n",
    "import emission.storage.timeseries.timequery as estt\n",
    "import scaffolding\n",
    "from uuid import UUID\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Data From Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading mapping dictionaries from mapping_dictionaries notebook\n",
    "# Dictionary map is putting all other replaced modes into other\n",
    "%store -r df_EI\n",
    "%store -r dic_re\n",
    "%store -r dic_pur\n",
    "%store -r dic_fuel\n",
    "\n",
    "# convert a dictionary to a defaultdict\n",
    "dic_pur = defaultdict(lambda: 'Other',dic_pur)\n",
    "dic_re = defaultdict(lambda: 'Other',dic_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tq = scaffolding.get_time_query(year, month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's get UUID lists for all the three categories\n",
    "# stage, all, non_stage\n",
    "stage_uuids = []\n",
    "all_uuids = []\n",
    "non_stage_uuids = []\n",
    "for ue in edb.get_uuid_db().find():\n",
    "    all_uuids.append(str(ue['uuid']))\n",
    "    if ue['user_email'].startswith(\"stage_\"):\n",
    "        stage_uuids.append(str(ue['uuid']))\n",
    "    else:\n",
    "        non_stage_uuids.append(str(ue['uuid']))\n",
    "stage_uuids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the proportions across them\n",
    "len(stage_uuids), len(non_stage_uuids), len(all_uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the participant confirmed trips\n",
    "participant_ct_df = scaffolding.load_all_participant_trips(program, tq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait, we have 219 unique trips, which doesn't match any of the numbers\n",
    "len(participant_ct_df.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if this is because of strings; nope\n",
    "participant_ct_df[\"user_id_str\"] = participant_ct_df.user_id.apply(lambda u: str(u))\n",
    "len(participant_ct_df.user_id_str.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see which category the missing trips fit into\n",
    "missing_uuids = set(all_uuids).difference(set(participant_ct_df.user_id_str))\n",
    "len(missing_uuids), 245 - 219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(missing_uuids).intersection(stage_uuids), set(missing_uuids).intersection(non_stage_uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# They seem to be split pretty evenly between stage and non stage\n",
    "len(set(missing_uuids).intersection(stage_uuids)), len(set(missing_uuids).intersection(non_stage_uuids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stage users, comparing string, we find a difference\n",
    "non_stage_ct_df = participant_ct_df[~participant_ct_df['user_id_str'].isin(stage_uuids)]\n",
    "stage_ct_df = participant_ct_df[participant_ct_df['user_id_str'].isin(stage_uuids)]\n",
    "print(len(non_stage_ct_df))\n",
    "print(len(stage_ct_df))\n",
    "print(len(participant_ct_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we have missing UUIDs, let's confirm that none of them have trips in the database\n",
    "# and that we are not missing trips just because of read limits\n",
    "missing_stage_uuids = set(missing_uuids).intersection(stage_uuids)\n",
    "missing_non_stage_uuids = set(missing_uuids).intersection(non_stage_uuids)\n",
    "\n",
    "from uuid import UUID\n",
    "import emission.core.get_database as edb\n",
    "\n",
    "for uuid_str in missing_stage_uuids.union(missing_non_stage_uuids):\n",
    "    print(f\"For {uuid_str}, found %d trips in the database\" % \n",
    "          (edb.get_analysis_timeseries_db().count_documents({\"user_id\": UUID(uuid_str), \"metadata.key\": \"analysis/confirmed_trip\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeled_ct = scaffolding.filter_labeled_trips(participant_ct_df)\n",
    "# expanded_ct = scaffolding.expand_userinputs(labeled_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sensed as well as labeled trips\n",
    "expanded_ct = scaffolding.expand_userinputs(participant_ct_df)\n",
    "expanded_stage_ct = scaffolding.expand_userinputs(stage_ct_df)\n",
    "expanded_non_stage_ct = scaffolding.expand_userinputs(non_stage_ct_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_ct = scaffolding.data_quality_check(expanded_ct)\n",
    "expanded_ct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHANKARI: I am not sure it is OK to fill in the inferred values as `mode_confirm`\n",
    "# mode confirm should be reserved for user input\n",
    "# the inferred labels are generated by the label assist algorithm and have accuracy of ~ 50%\n",
    "\n",
    "# How much data total\n",
    "print(\"Total number of trips\", len(expanded_ct))\n",
    "\n",
    "# data with user specified modes\n",
    "print(\"Trips with user specified labels\", len(expanded_ct[~pd.isna(expanded_ct.mode_confirm)]))\n",
    "      \n",
    "# how much data without labels and with and without label assist\n",
    "no_user_label_ct_df = expanded_ct[pd.isna(expanded_ct.mode_confirm)]\n",
    "print(\"Trips without user specified labels\", len(no_user_label_ct_df))\n",
    "is_empty_check = lambda ll: len(ll) > 0\n",
    "print(\"Trips without user label but with inferred label\", len(no_user_label_ct_df[~no_user_label_ct_df.inferred_labels.apply(is_empty_check)]))\n",
    "print(\"Trips without user label or inferred label\", len(no_user_label_ct_df[no_user_label_ct_df.inferred_labels.apply(is_empty_check)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we really only have 57k labeled trips, not 115k\n",
    "# we can generate results with label assist and/or primary sensed mode for comparison,\n",
    "# but I think that the most principled version of the evaluation should use only labeled trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label assist mode where not filled in\n",
    "\n",
    "# inferred_modes = []\n",
    "# for i in range(0,len(expanded_all_ct)):\n",
    "#     try:\n",
    "#         inferred_modes.append(expanded_all_ct['inferred_labels'].iloc[i][0]['labels']['mode_confirm'])\n",
    "#     except:\n",
    "#         inferred_modes.append(None)\n",
    "\n",
    "# expanded_all_ct['Inferred_mode'] = inferred_modes\n",
    "# expanded_all_ct.mode_confirm.fillna(expanded_all_ct.Inferred_mode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanded_all_ct.Inferred_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping new labels with dictionaries\n",
    "expanded_ct['Trip_purpose'] = expanded_ct['purpose_confirm'].map(dic_pur)\n",
    "expanded_ct['Mode_confirm'] = expanded_ct['mode_confirm'].map(dic_re)\n",
    "expanded_ct['Replaced_mode'] = expanded_ct['replaced_mode'].map(dic_re)\n",
    "\n",
    "# Mapping fuel\n",
    "expanded_ct['Mode_confirm_fuel'] = expanded_ct['Mode_confirm'].map(dic_fuel)\n",
    "expanded_ct['Replaced_mode_fuel'] = expanded_ct['Replaced_mode'].map(dic_fuel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change meters to miles\n",
    "scaffolding.unit_conversions(expanded_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_suffix = scaffolding.get_file_suffix(year, month, program)\n",
    "quality_text = scaffolding.get_quality_text(participant_ct_df, expanded_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate energy impact\n",
    "expanded_ct = scaffolding.energy_intensity(expanded_ct, df_EI, 'distance_miles', 'Replaced_mode', 'Mode_confirm')\n",
    "expanded_ct = scaffolding.energy_impact_kWH(expanded_ct, 'distance_miles', 'Replaced_mode', 'Mode_confirm')\n",
    "expanded_ct = scaffolding.CO2_impact_lb(expanded_ct, 'distance_miles', 'Replaced_mode', 'Mode_confirm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the expanded database data to socioeconomic data\n",
    "socio_data = pd.read_csv('./replacement_modeling/Can Do Colorado eBike Program - en.csv')\n",
    "socio_data.rename(columns={'Unique User ID (auto-filled, do not edit)':'user_id',\n",
    "                          'Please identify which category represents your total household income, before taxes, for last year.':'HHINC',\n",
    "                          'How many motor vehicles are owned, leased, or available for regular use by the people who currently live in your household?':'VEH',\n",
    "                           'In which year were you born?':'AGE',\n",
    "                          'Including yourself, how many people live in your home?':'HHSIZE',\n",
    "                          'How many children under age 18 live in your home?':'CHILDREN',\n",
    "                          'What is your gender?':'GENDER',\n",
    "                          'If you were unable to use your household vehicle(s), which of the following options would be available to you to get you from place to place?':'available_modes',\n",
    "                          'Are you a student?':'STUDENT'}, inplace=True)\n",
    "socio_data = socio_data[~socio_data.user_id.isnull()]\n",
    "\n",
    "# Deal with people who have multiple responses by using most recent\n",
    "socio_data = socio_data.sort_values(by=['user_id', 'Timestamp'])\n",
    "socio_data.drop_duplicates(subset=['user_id'], keep='last', inplace=True)\n",
    "\n",
    "# Lose 15000 trips due to people with no survey responses\n",
    "expanded_ct.user_id = expanded_ct.user_id.astype(str)\n",
    "expanded_ct.user_id = [i.replace('-','') for i in expanded_ct.user_id] # remove all dashes from strings\n",
    "expanded_ct = expanded_ct.merge(socio_data, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_ct.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Select variables of interest from complete OpenPATH data\n",
    "data = expanded_ct[['Mode_confirm','Replaced_mode','replaced_mode','Trip_purpose','duration','distance_miles','start_local_dt_weekday','available_modes','AGE','HHINC','VEH','HHSIZE','CHILDREN','GENDER','STUDENT','user_id','start_local_dt_year','start_local_dt_month','start_local_dt_day']].copy()\n",
    "\n",
    "# Get timestamp from known year/month/day aggregated to days\n",
    "data.rename(columns={'start_local_dt_year':'year','start_local_dt_month':'month','start_local_dt_day':'day'}, inplace=True)\n",
    "data['date_time'] = pd.to_datetime(data[['year','month','day']])\n",
    "data = data.drop(columns=['year','month','day'])\n",
    "\n",
    "# Fix age\n",
    "data['AGE'] = 2022 - data['AGE']\n",
    "\n",
    "# Get number of workers\n",
    "data['WORKERS'] = data['HHSIZE'] - data['CHILDREN']\n",
    "\n",
    "# Duration in minutes\n",
    "data['duration'] = data['duration'] / 60\n",
    "\n",
    "# Filter out some responses to data\n",
    "data = data[~data['Mode_confirm'].isin(['Not a Trip','Other'])]\n",
    "# data = data[~data['Trip_purpose'].isin(['not_a_trip','Other'])]\n",
    "# data = data[~data['Replaced_mode'].isin(['Not a Trip','Other'])]\n",
    "# data = data[~data['HHINC'].isin(['Prefer not to say'])]\n",
    "# data = data[~data['VEH'].isin(['Prefer not to say / Prefiero no decir.'])]\n",
    "# Had to add the \"prefer not to say\" here otherwise I get an KeyError \"KeyError: 'Prefer not to say'\"\n",
    "# -- SHANKARI\n",
    "data = data[~data['available_modes'].isin(['None', 'Prefer not to say'])]\n",
    "\n",
    "# Combine variable categories\n",
    "data = data.replace('Car, drove alone', 'car')\n",
    "data = data.replace('Car, with others', 'car')\n",
    "data = data.replace('Bikeshare', 's_micro')\n",
    "data = data.replace('Scooter share', 's_micro')\n",
    "data = data.replace('Regular Bike', 'p_micro')\n",
    "data = data.replace('Skate board', 'p_micro')\n",
    "data = data.replace('Train', 'transit')\n",
    "data = data.replace('Free Shuttle', 'transit')\n",
    "data = data.replace('Bus', 'transit')\n",
    "data = data.replace('Walk', 'walk')\n",
    "data = data.replace('Taxi/Uber/Lyft', 'ridehail')\n",
    "data = data.replace('Pilot ebike', 'ebike')\n",
    "\n",
    "# data = data.replace(['Home','School','Work'], 'hbw')\n",
    "# data = data.replace(['Entertainment/Social','Meal','Personal/Medical','Pick-up/Drop off','Recreation/Exercise','Religious','Shopping','Transit transfer'], 'non_hbw')\n",
    "\n",
    "# data['start_local_dt_weekday'] = data['start_local_dt_weekday'].replace(['1','2','3','4','5'],'1')\n",
    "# data['start_local_dt_weekday'] = data['start_local_dt_weekday'].replace(['0','6'],'0')\n",
    "\n",
    "# data = data.replace(['By hours ','Custodian','Fire Fighter 2 Training',\n",
    "#  'Graduate','Prefer not to say','Taking prerequisites missing for grad program ',\n",
    "#  'Yes - Full Time College/University',\n",
    "#  'Yes - Part-Time College/University',\n",
    "#  'Yes - Vocation/Technical/Trade School',\n",
    "#  'taking classes toward early childhood licensure'], 'student')\n",
    "# data = data.replace('Not a student', 'non_student')\n",
    "\n",
    "# Calculate travel times for each trip, across every mode\n",
    "def add_all_mode_tt(data, mode_col, duration_col, dist_col):\n",
    "    mode_travel_times = {}\n",
    "    for mode in pd.unique(data[mode_col]):\n",
    "\n",
    "        # Linear model for duration based on distance for trips belonging to each mode\n",
    "        mode_data = data[data[mode_col]==mode]\n",
    "        regr = linear_model.LinearRegression()\n",
    "        regr.fit(mode_data[dist_col].values.reshape(-1,1), mode_data[duration_col].values.reshape(-1,1))\n",
    "\n",
    "        # Make prediction for ALL trips\n",
    "        mode_duration_pred = regr.predict(data[dist_col].values.reshape(-1,1))\n",
    "        mode_travel_times['tt_'+mode] = mode_duration_pred\n",
    "\n",
    "    # Apply for each mode existing in the dataframe\n",
    "    for mode in mode_travel_times:\n",
    "        data[mode] = mode_travel_times[mode]\n",
    "\n",
    "    return data\n",
    "\n",
    "# Calculate all mode travel times and add to dataframe\n",
    "data = add_all_mode_tt(data,'Mode_confirm','duration','distance_miles')\n",
    "\n",
    "# Calculate vehicle costs based roughly on $/mi from: https://www.vtpi.org/tca/tca0501.pdf\n",
    "cost_factors = {'car':0.80,\n",
    "               'ridehail':3.00,\n",
    "               's_micro':1.50,\n",
    "               'transit':0.40}\n",
    "\n",
    "def add_all_mode_cost(data, cost_factors, dist_col):\n",
    "    for factor in cost_factors:\n",
    "        data['cost_'+factor] = cost_factors[factor] * data[dist_col]\n",
    "    return data\n",
    "\n",
    "# Calculate all mode travel costs and add to dataframe\n",
    "add_all_mode_cost(data, cost_factors, 'distance_miles')\n",
    "\n",
    "# Labels for modes in the availability survey\n",
    "availability_codes = {'Public transportation (bus, subway, light rail, etc.)':'transit',\n",
    "                    'Get a ride from a friend or family member':'car',\n",
    "                    'Rental car (including Zipcar/ Car2Go)':'car',\n",
    "                    'Taxi (regular taxi, Uber, Lyft, etc)':'ridehail',\n",
    "                    'Bicycle':'p_micro',\n",
    "                    'Shared bicycle or scooter':'s_micro',\n",
    "                    'Walk/roll':'walk',\n",
    "                    'Skateboard':'p_micro'}\n",
    "\n",
    "# Create columns for available modes under each trip\n",
    "def add_mode_availability(data, availability_codes, availability_col, choice_col, replaced_col):\n",
    "    mode_list = np.unique(list(availability_codes.values()))\n",
    "    available_list = data[availability_col].values\n",
    "    choice_list = data[choice_col].values\n",
    "    replaced_list = data[replaced_col].values\n",
    "    for mode in mode_list:\n",
    "        mode_avail = []\n",
    "        i=0\n",
    "        for available in available_list:\n",
    "            if 'None' in available:\n",
    "                mode_avail.append(1)\n",
    "                i+=1\n",
    "                continue\n",
    "            options = [availability_codes[x] for x in available.split(';')]\n",
    "            # Chosen mode must be in the available modes list, if mode was chosen it is assumed available\n",
    "            # SWAP THIS LINE TO INCLUDE REPLACED MODE IN THE CHOICE SET (FOR VISUALS AT END)\n",
    "            if mode in options or mode==choice_list[i] or mode==replaced_list[i]:\n",
    "#             if mode in options or mode==choice_list[i]:\n",
    "                mode_avail.append(1)\n",
    "            else:\n",
    "                mode_avail.append(0)\n",
    "            i+=1\n",
    "        data['av_'+mode] = mode_avail\n",
    "\n",
    "    return data\n",
    "\n",
    "# Add availability variables to data\n",
    "data = add_mode_availability(data, availability_codes, 'available_modes', 'Mode_confirm', 'Replaced_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle all variables that are ordinal; otherwise they may not end up in correct order\n",
    "# data.HHINC = pd.Categorical(data.HHINC,\n",
    "#                             ordered=True,\n",
    "#                             categories=['Less than $24,999',\n",
    "#                                        '$25,000-$49,999',\n",
    "#                                        '$50,000-$99,999',\n",
    "#                                        '$100,000 -$149,999',\n",
    "#                                        '$150,000-$199,999',\n",
    "#                                        '$200,000 or more'])\n",
    "# data.VEH = pd.Categorical(data.VEH,\n",
    "#                             ordered=True,\n",
    "#                             categories=['0',\n",
    "#                                        '1',\n",
    "#                                        '2',\n",
    "#                                        '3',\n",
    "#                                        '4+'])\n",
    "\n",
    "# Make sure that the confirmed and replaced modes align after being converted to numeric variables\n",
    "data.Mode_confirm = pd.Categorical(data.Mode_confirm,\n",
    "                            ordered=True,\n",
    "                            categories=['car',\n",
    "                                       'p_micro',\n",
    "                                       'ridehail',\n",
    "                                       's_micro',\n",
    "                                       'transit',\n",
    "                                       'walk',\n",
    "                                       'ebike'])\n",
    "data.Replaced_mode = pd.Categorical(data.Replaced_mode,\n",
    "                            ordered=True,\n",
    "                            categories=['car',\n",
    "                                       'p_micro',\n",
    "                                       'ridehail',\n",
    "                                       's_micro',\n",
    "                                       'transit',\n",
    "                                       'walk',\n",
    "                                       'ebike',\n",
    "                                       'No Travel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert categorical variables to numeric\n",
    "cat_columns = data.select_dtypes(['object','category']).columns\n",
    "all_categories = []\n",
    "for i in range(0,len(cat_columns)):\n",
    "    # Keep a record of what order the categories are in when converted\n",
    "    var_categories = data[cat_columns].astype('category').iloc[:,i].cat.categories\n",
    "    all_categories.append(var_categories)\n",
    "data[cat_columns] = data[cat_columns].apply(lambda x: x.astype('category').cat.codes)\n",
    "\n",
    "# Show listed categories in their order\n",
    "print(cat_columns)\n",
    "print(all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unlabeled replacement trips (to be labeled after modeling)\n",
    "df_rep_unlabeled = data.copy()\n",
    "data = data[~data['Replaced_mode'].isin([-1])]\n",
    "\n",
    "# Remove ebike (mode 6) trips from data (assume ebike would not be chosen to replace ebike)\n",
    "df_non_ebike = data[~data['Mode_confirm'].isin([6])]\n",
    "df_train, df_test = train_test_split(df_non_ebike, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['tt_car','tt_walk','tt_p_micro','tt_transit','tt_s_micro','tt_ridehail',\n",
    "             'cost_car','cost_ridehail','cost_s_micro','cost_transit',\n",
    "             'av_car','av_walk','av_p_micro','av_transit','av_s_micro','av_ridehail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_train[['Mode_confirm']].values.flatten()\n",
    "X = df_train[feature_list].values\n",
    "\n",
    "Y_test = df_test[['Mode_confirm']].values.flatten()\n",
    "X_test = df_test[feature_list].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train random forest on non-ebike trip training set\n",
    "rf = RandomForestClassifier(n_estimators=50)\n",
    "rf.fit(X,Y);\n",
    "\n",
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test random forest on the test set\n",
    "Y_pred = rf.predict(X_test)\n",
    "accuracy = sum(Y_pred==Y_test) / len(Y_test)\n",
    "print(f\"Accuracy on Primary Choice: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test random forest on the replaced mode\n",
    "df_ebike = data[data['Mode_confirm']==6]\n",
    "df_ebike_new_trips = df_ebike[~df_ebike['Replaced_mode'].isin([6,7])]\n",
    "Y_rep = df_ebike_new_trips['Replaced_mode'].values.flatten()\n",
    "X_rep = df_ebike_new_trips[feature_list].values\n",
    "Choice_rep = df_ebike_new_trips['Mode_confirm'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is actually unnecessary since chosen mode is ebike which is not an option in model\n",
    "# # Returns highest probability mode that is not the chosen mode\n",
    "# # Needs restructure to also iterate over choice array\n",
    "# def replaced_mode_prediction(class_probs, choice):\n",
    "#     best_alt = None\n",
    "#     best_prob = -1\n",
    "#     for i in range(0,len(class_probs)):\n",
    "#         if (class_probs[i] > best_prob) and (i != choice):\n",
    "#             best_alt = i\n",
    "#             best_prob = class_probs[i]    \n",
    "#     return best_alt\n",
    "\n",
    "# simulatedValues = rf.predict_proba(X_rep)\n",
    "# result = np.apply_along_axis(replaced_mode_prediction, choice=Choice_rep, axis=1, arr=simulatedValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test random forest on the test set stated replaced mode\n",
    "Y_rep_pred = rf.predict(X_rep)\n",
    "accuracy = sum(Y_rep_pred==Y_rep) / len(Y_rep)\n",
    "print(f\"Accuracy on Replaced Choice: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Biogeme Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_biogeme = df_train.drop(columns=['date_time'])\n",
    "df_test_biogeme = df_test.drop(columns=['date_time'])\n",
    "database_train = db.Database('openpath_trips', df_train_biogeme)\n",
    "database_test = db.Database('openpath_trips', df_test_biogeme)\n",
    "globals().update(database_train.variables)\n",
    "globals().update(database_test.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial logit model in Biogeme\n",
    "\n",
    "# Alternative specific constants\n",
    "ASC_CAR = Beta('ASC_CAR',0,None,None,1)\n",
    "ASC_EBIKE = Beta('ASC_EBIKE',0,None,None,0)\n",
    "ASC_P_MICRO = Beta('ASC_P_MICRO',0,None,None,0)\n",
    "ASC_RIDEHAIL = Beta('ASC_RIDEHAIL',0,None,None,0)\n",
    "ASC_S_MICRO = Beta('ASC_S_MICRO',0,None,None,0)\n",
    "ASC_TRANSIT = Beta('ASC_TRANSIT',0,None,None,0)\n",
    "ASC_WALK = Beta('ASC_WALK',0,None,None,0)\n",
    "\n",
    "# Trip parameters\n",
    "B_COST = Beta('B_COST',0,None,None,0)\n",
    "B_TT = Beta('B_TT',0,None,None,0)\n",
    "B_PURP = Beta('B_PURP',0,None,None,0)\n",
    "B_WKND = Beta('B_WKND',0,None,None,0)\n",
    "\n",
    "# Individual parameters\n",
    "B_AGE = Beta('B_AGE',0,None,None,0)\n",
    "B_INC = Beta('B_INC',0,None,None,0)\n",
    "B_VEH = Beta('B_VEH',0,None,None,0)\n",
    "B_GENDER = Beta('B_GENDER',0,None,None,0)\n",
    "B_WORKERS = Beta('B_WORKERS',0,None,None,0)\n",
    "B_STUDENT = Beta('B_STUDENT',0,None,None,0)\n",
    "\n",
    "B_ASV_TT_MOTOR = Beta('B_ASV_TT_MOTOR',0,None,None,1)\n",
    "B_ASV_TT_PHYS = Beta('B_ASV_TT_PHYS',0,None,None,0)\n",
    "\n",
    "B_ASV_NP_PHYS = Beta('B_ASV_NP_PHYS',0,None,None,1)\n",
    "B_ASV_P_PHYS = Beta('B_ASV_P_PHYS',0,None,None,0)\n",
    "\n",
    "# Alternative Specific Variables\n",
    "B_ASV_VEH_CAR = Beta('B_ASV_VEH_CAR',0,None,None,1)\n",
    "B_ASV_VEH_EBIKE = Beta('B_ASV_VEH_EBIKE',0,None,None,0)\n",
    "B_ASV_VEH_P_MICRO = Beta('B_ASV_VEH_P_MICRO',0,None,None,0)\n",
    "B_ASV_VEH_RIDEHAIL = Beta('B_ASV_VEH_RIDEHAIL',0,None,None,0)\n",
    "B_ASV_VEH_S_MICRO = Beta('B_ASV_VEH_S_MICRO',0,None,None,0)\n",
    "B_ASV_VEH_TRANSIT = Beta('B_ASV_VEH_TRANSIT',0,None,None,0)\n",
    "B_ASV_VEH_WALK = Beta('B_ASV_VEH_WALK',0,None,None,0)\n",
    "\n",
    "B_ASV_HHINC_CAR = Beta('B_ASV_HHINC_CAR',0,None,None,1)\n",
    "B_ASV_HHINC_EBIKE = Beta('B_ASV_HHINC_EBIKE',0,None,None,0)\n",
    "B_ASV_HHINC_P_MICRO = Beta('B_ASV_HHINC_P_MICRO',0,None,None,0)\n",
    "B_ASV_HHINC_RIDEHAIL = Beta('B_ASV_HHINC_RIDEHAIL',0,None,None,0)\n",
    "B_ASV_HHINC_S_MICRO = Beta('B_ASV_HHINC_S_MICRO',0,None,None,0)\n",
    "B_ASV_HHINC_TRANSIT = Beta('B_ASV_HHINC_TRANSIT',0,None,None,0)\n",
    "B_ASV_HHINC_WALK = Beta('B_ASV_HHINC_WALK',0,None,None,0)\n",
    "\n",
    "# Utility functions\n",
    "V0 = ASC_CAR + \\\n",
    "B_COST * cost_car + \\\n",
    "B_ASV_TT_MOTOR * tt_car\n",
    "\n",
    "V1 = ASC_P_MICRO + \\\n",
    "B_ASV_TT_PHYS * tt_p_micro\n",
    "\n",
    "V2 = ASC_RIDEHAIL + \\\n",
    "B_COST * cost_ridehail + \\\n",
    "B_ASV_TT_MOTOR * tt_ridehail\n",
    "\n",
    "V3 = ASC_S_MICRO + \\\n",
    "B_COST * cost_s_micro + \\\n",
    "B_ASV_TT_PHYS * tt_s_micro\n",
    "\n",
    "V4 = ASC_TRANSIT + \\\n",
    "B_COST * cost_transit + \\\n",
    "B_ASV_TT_MOTOR * tt_transit\n",
    "\n",
    "V5 = ASC_WALK + \\\n",
    "B_ASV_TT_PHYS * tt_walk\n",
    "\n",
    "# Map modes to utility functions\n",
    "V = {0: V0,\n",
    "    1: V1,\n",
    "    2: V2,\n",
    "    3: V3,\n",
    "    4: V4,\n",
    "    5: V5}\n",
    "\n",
    "# Mode availability\n",
    "av = {0: av_car,\n",
    "    1: av_p_micro,\n",
    "    2: av_ridehail,\n",
    "    3: av_s_micro,\n",
    "    4: av_transit,\n",
    "    5: av_walk}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model parameters\n",
    "logprob = models.loglogit(V, av, Mode_confirm)\n",
    "biogeme = bio.BIOGEME(database_train, logprob)\n",
    "biogeme.modelName = 'openpath_mnl'\n",
    "biogeme.generateHtml = True\n",
    "biogeme.generatePickle = True\n",
    "results = biogeme.estimate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mixed logit model in Biogeme\n",
    "# # Best so far: openpath_mxl~05\n",
    "\n",
    "# # Alternative specific constants\n",
    "# ASC_CAR = Beta('ASC_CAR',0,None,None,1)\n",
    "# ASC_EBIKE = Beta('ASC_EBIKE',0,None,None,0)\n",
    "# ASC_P_MICRO = Beta('ASC_P_MICRO',0,None,None,0)\n",
    "# ASC_RIDEHAIL = Beta('ASC_RIDEHAIL',0,None,None,0)\n",
    "# ASC_S_MICRO = Beta('ASC_S_MICRO',0,None,None,0)\n",
    "# ASC_TRANSIT = Beta('ASC_TRANSIT',0,None,None,0)\n",
    "# ASC_WALK = Beta('ASC_WALK',0,None,None,0)\n",
    "\n",
    "# # Define a random parameter, normally distributed, designed to be used\n",
    "# # for Monte-Carlo simulation\n",
    "# B_TIME = Beta('B_TIME', 0, None, None, 0)\n",
    "# B_COST = Beta('B_COST', 0, None, None, 0)\n",
    "\n",
    "# # Alternative specific variables\n",
    "# B_HHINC = Beta('B_HHINC', 0, None, None, 0)\n",
    "\n",
    "# # It is advised not to use 0 as starting value for the following parameter.\n",
    "# B_TIME_S = Beta('B_TIME_S', 1, None, None, 0)\n",
    "# B_TIME_RND = B_TIME + B_TIME_S * bioDraws('B_TIME_RND', 'NORMAL')\n",
    "\n",
    "# # Utility functions\n",
    "# V0 = ASC_CAR + \\\n",
    "# B_TIME_RND * tt_car + \\\n",
    "# B_COST * cost_car\n",
    "\n",
    "# V1 = ASC_P_MICRO + \\\n",
    "# B_TIME_RND * tt_p_micro\n",
    "\n",
    "# V2 = ASC_RIDEHAIL + \\\n",
    "# B_TIME_RND * tt_ridehail + \\\n",
    "# B_COST * cost_ridehail\n",
    "\n",
    "# V3 = ASC_S_MICRO + \\\n",
    "# B_TIME_RND * tt_s_micro + \\\n",
    "# B_COST * cost_s_micro\n",
    "\n",
    "# V4 = ASC_TRANSIT + \\\n",
    "# B_TIME_RND * tt_transit + \\\n",
    "# B_COST * cost_transit\n",
    "\n",
    "# V5 = ASC_WALK + \\\n",
    "# B_TIME_RND * tt_walk\n",
    "\n",
    "# # Map modes to utility functions\n",
    "# V = {0: V0,\n",
    "#     1: V1,\n",
    "#     2: V2,\n",
    "#     3: V3,\n",
    "#     4: V4,\n",
    "#     5: V5}\n",
    "\n",
    "# # Mode availability\n",
    "# av = {0: av_car,\n",
    "#     1: av_p_micro,\n",
    "#     2: av_ridehail,\n",
    "#     3: av_s_micro,\n",
    "#     4: av_transit,\n",
    "#     5: av_walk}\n",
    "\n",
    "# # Conditional to B_TIME_RND, we have a logit model (called the kernel)\n",
    "# prob = models.logit(V, av, Mode_confirm)\n",
    "\n",
    "# # We integrate over B_TIME_RND using Monte-Carlo\n",
    "# logprob = log(MonteCarlo(prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model parameters\n",
    "# biogeme = bio.BIOGEME(database_train, logprob)\n",
    "# biogeme.modelName = 'openpath_mxl'\n",
    "# biogeme.generateHtml = True\n",
    "# biogeme.generatePickle = True\n",
    "# results = biogeme.estimate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The estimation results are read from the pickle file\n",
    "# results = res.bioResults(pickleFile='openpath_mxl~05.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MXL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Conditional to B_TIME_RND, we have a logit model (called the kernel)\n",
    "# prob = models.logit(V, av, Mode_confirm)\n",
    "\n",
    "# # We calculate the integration error. Note that this formula assumes\n",
    "# # independent draws, and is not valid for Haltom or antithetic draws.\n",
    "# numberOfDraws = 1000\n",
    "# integral = MonteCarlo(prob)\n",
    "# integralSquare = MonteCarlo(prob * prob)\n",
    "# variance = integralSquare - integral * integral\n",
    "# error = (variance / 2.0) ** 0.5\n",
    "\n",
    "# # And the value of the individual parameters\n",
    "# numerator = MonteCarlo(B_TIME_RND * prob)\n",
    "# denominator = integral\n",
    "\n",
    "# simulate = {\n",
    "#     'Numerator': numerator,\n",
    "#     'Denominator': denominator,\n",
    "#     'Integral': integral,\n",
    "#     'Integration error': error,\n",
    "# }\n",
    "\n",
    "# # Create the Biogeme object\n",
    "# biosim = bio.BIOGEME(database_test, simulate, numberOfDraws=numberOfDraws)\n",
    "# biosim.modelName = \"openpath_mxl_simul\"\n",
    "\n",
    "# # Simulate the requested quantities. The output is a Pandas data frame\n",
    "# simresults = biosim.simulate(results.getBetaValues())\n",
    "\n",
    "# # 95% confidence interval on the log likelihood.\n",
    "# simresults['left'] = np.log(\n",
    "#     simresults['Integral'] - 1.96 * simresults['Integration error']\n",
    "# )\n",
    "# simresults['right'] = np.log(\n",
    "#     simresults['Integral'] + 1.96 * simresults['Integration error']\n",
    "# )\n",
    "\n",
    "# print(f'Log likelihood: {np.log(simresults[\"Integral\"]).sum()}')\n",
    "# print(\n",
    "#     f'Integration error for {numberOfDraws} draws: '\n",
    "#     f'{simresults[\"Integration error\"].sum()}'\n",
    "# )\n",
    "# print(f'In average {simresults[\"Integration error\"].mean()} per observation.')\n",
    "# print(\n",
    "#     f'95% confidence interval: [{simresults[\"left\"].sum()}-'\n",
    "#     f'{simresults[\"right\"].sum()}]'\n",
    "# )\n",
    "\n",
    "# # Post processing to obtain the individual parameters\n",
    "# simresults['beta'] = simresults['Numerator'] / simresults['Denominator']\n",
    "\n",
    "# # Plot the histogram of individual parameters\n",
    "# simresults['beta'].plot(kind='hist', density=True, bins=20)\n",
    "\n",
    "# # Plot the general distribution of beta\n",
    "# def normalpdf(v, mu=0.0, s=1.0):\n",
    "#     \"\"\"\n",
    "#     Calculate the pdf of the normal distribution, for plotting purposes.\n",
    "\n",
    "#     \"\"\"\n",
    "#     d = -(v - mu) * (v - mu)\n",
    "#     n = 2.0 * s * s\n",
    "#     a = d / n\n",
    "#     num = np.exp(a)\n",
    "#     den = s * 2.506628275\n",
    "#     p = num / den\n",
    "#     return p\n",
    "\n",
    "\n",
    "# betas = results.getBetaValues(['B_TIME', 'B_TIME_S'])\n",
    "# x = np.arange(simresults['beta'].min(), simresults['beta'].max(), 0.01)\n",
    "# plt.plot(x, normalpdf(x, betas['B_TIME'], betas['B_TIME_S']), '-')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MNL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble utility functions for testing modes\n",
    "prob_car = models.logit(V, av, 0)\n",
    "prob_p_micro = models.logit(V, av, 1)\n",
    "prob_ridehail = models.logit(V, av, 2)\n",
    "prob_s_micro = models.logit(V, av, 3)\n",
    "prob_transit = models.logit(V, av, 4)\n",
    "prob_walk = models.logit(V, av, 5)\n",
    "\n",
    "simulate ={'Prob. car': prob_car,\n",
    "           'Prob. p_micro': prob_p_micro,\n",
    "           'Prob. ridehail': prob_ridehail,\n",
    "           'Prob. s_micro': prob_s_micro,\n",
    "           'Prob. transit': prob_transit,\n",
    "           'Prob. walk': prob_walk}\n",
    "\n",
    "betas = results.getBetaValues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate utility values for each row in the test database\n",
    "biogeme = bio.BIOGEME(database_test, simulate)\n",
    "biogeme.modelName = 'openpath_mnl_test'\n",
    "simulatedValues = biogeme.simulate(betas)\n",
    "simulatedValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predicting maximum mode utility as choice\n",
    "# Identify the column of highest probability, replace with number corresponding to the mode\n",
    "prob_max = simulatedValues.idxmax(axis=1)\n",
    "prob_max = prob_max.replace({'Prob. car': 0,\n",
    "                             'Prob. p_micro': 1,\n",
    "                             'Prob. ridehail':2,\n",
    "                             'Prob. s_micro':3,\n",
    "                             'Prob. transit':4,\n",
    "                             'Prob. walk':5})\n",
    "data_res = {'y_Actual':df_test['Mode_confirm'],'y_Predicted': prob_max}\n",
    "\n",
    "# Test predicting car every time\n",
    "data_res['y_Predicted_Car'] = np.repeat(0,len(data_res['y_Actual']))\n",
    "\n",
    "# Test predicting probabilistically\n",
    "def probabilistic_mode_choice(probs):\n",
    "    return np.random.choice(np.arange(0,len(probs)), p=probs)\n",
    "data_res['y_Predicted_Prob'] = np.apply_along_axis(probabilistic_mode_choice, axis=1, arr=simulatedValues.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ALWAYS CAR METHOD\")\n",
    "# Cross tabulate to see accuracy for each mode\n",
    "df = pd.DataFrame(data_res, columns=['y_Actual','y_Predicted_Car'])\n",
    "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted_Car'], rownames=['Actual'], colnames=['Predicted'],normalize=True)\n",
    "\n",
    "print(round(confusion_matrix,2))\n",
    "accuracy = len(df[df['y_Actual']==df['y_Predicted_Car']])/len(df)\n",
    "print('Global accuracy of the model:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PROBABILISTIC METHOD\")\n",
    "# Cross tabulate to see accuracy for each mode\n",
    "df = pd.DataFrame(data_res, columns=['y_Actual','y_Predicted_Prob'])\n",
    "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted_Prob'], rownames=['Actual'], colnames=['Predicted'],normalize=True)\n",
    "\n",
    "print(round(confusion_matrix,2))\n",
    "accuracy = len(df[df['y_Actual']==df['y_Predicted_Prob']])/len(df)\n",
    "print('Global accuracy of the model:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAX UTILITY METHOD\")\n",
    "# Cross tabulate to see accuracy for each mode\n",
    "df = pd.DataFrame(data_res, columns=['y_Actual','y_Predicted'])\n",
    "confusion_matrix = pd.crosstab(df['y_Actual'],df['y_Predicted'],rownames=['Actual'],colnames=['Predicted'],normalize=True)\n",
    "\n",
    "print(round(confusion_matrix,2))\n",
    "accuracy = len(df[df['y_Actual']==df['y_Predicted']])/len(df)\n",
    "print('Global accuracy of the model:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for ebike trips, that replaced a mode in the model, and compare to stated replaced mode\n",
    "df_ebike = data.drop(columns=['date_time'])\n",
    "df_ebike = df_ebike[df_ebike['Mode_confirm']==6]\n",
    "df_ebike_new_trips = df_ebike[~df_ebike['Replaced_mode'].isin([6,7])]\n",
    "\n",
    "database_ebike = db.Database('openpath_trips', df_ebike_new_trips)\n",
    "globals().update(database_ebike.variables)\n",
    "\n",
    "biogeme = bio.BIOGEME(database_ebike, simulate)\n",
    "biogeme.modelName = 'openpath_mnl_w_replaced'\n",
    "simulatedValues = biogeme.simulate(betas)\n",
    "\n",
    "prob_max = simulatedValues.idxmax(axis=1)\n",
    "prob_max = prob_max.replace({'Prob. car': 0,\n",
    "                             'Prob. p_micro': 1,\n",
    "                             'Prob. ridehail':2,\n",
    "                             'Prob. s_micro':3,\n",
    "                             'Prob. transit':4,\n",
    "                             'Prob. walk':5})\n",
    "data_res = {'y_Actual':df_ebike_new_trips['Replaced_mode'],'y_Predicted': prob_max}\n",
    "df = pd.DataFrame(data_res, columns=['y_Actual','y_Predicted'])\n",
    "confusion_matrix = pd.crosstab(df['y_Actual'],df['y_Predicted'],rownames=['Actual'],colnames=['Predicted'],normalize=True)\n",
    "\n",
    "print(round(confusion_matrix,2))\n",
    "print(f\"Car only: {sum(data_res['y_Actual'] == 0) / len(df_ebike_new_trips)}\")\n",
    "print(f\"Max utility: {sum(data_res['y_Actual'] == data_res['y_Predicted']) / len(df_ebike_new_trips)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ebike Substitution Rates and Emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ebike = data.drop(columns=['date_time'])\n",
    "df_ebike = df_ebike[df_ebike['Mode_confirm']==6]\n",
    "df_ebike_new_trips = df_ebike[~df_ebike['Replaced_mode'].isin([6,7])].copy()\n",
    "\n",
    "# Relabel with original mode names for plotting\n",
    "for mode in av:\n",
    "    mode_text = '_'.join(str(av[mode]).split('_')[1:])\n",
    "    df_ebike_new_trips['Mode_confirm'] = df_ebike_new_trips['Mode_confirm'].replace(mode,mode_text)\n",
    "    df_ebike_new_trips['Replaced_mode'] = df_ebike_new_trips['Replaced_mode'].replace(mode,mode_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Substitution rate of ebike trips not including new trips\n",
    "plot_data = df_ebike_new_trips.groupby(['Replaced_mode']).count()[['Mode_confirm']].reset_index()\n",
    "plot_data['subst_rate'] = plot_data['Mode_confirm'] / sum(plot_data['Mode_confirm'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Replaced_mode', y='subst_rate').set(title='Ebike Mode Replacement', xlabel='Replaced Mode', ylabel='Substitution Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "# ax.figure.savefig(\"/plots/ts_emissions_user%s.png\"%file_suffix, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now label the replaced mode\n",
    "# Make predictions for ebike trips\n",
    "df_ebike = df_rep_unlabeled.drop(columns=['date_time'])\n",
    "df_ebike = df_ebike[df_ebike['Mode_confirm']==6]\n",
    "df_ebike_new_trips = df_ebike[~df_ebike['Replaced_mode'].isin([6,7])].copy()\n",
    "\n",
    "database_ebike = db.Database('openpath_trips', df_ebike_new_trips)\n",
    "globals().update(database_ebike.variables)\n",
    "\n",
    "biogeme = bio.BIOGEME(database_ebike, simulate)\n",
    "biogeme.modelName = 'openpath_mnl_test'\n",
    "simulatedValues = biogeme.simulate(betas)\n",
    "\n",
    "prob_max = simulatedValues.idxmax(axis=1)\n",
    "prob_max = prob_max.replace({'Prob. car': 0,\n",
    "                             'Prob. p_micro': 1,\n",
    "                             'Prob. ridehail':2,\n",
    "                             'Prob. s_micro':3,\n",
    "                             'Prob. transit':4,\n",
    "                             'Prob. walk':5})\n",
    "data_res = {'y_Actual':df_ebike_new_trips['Replaced_mode'],'y_Predicted': prob_max}\n",
    "df = pd.DataFrame(data_res, columns=['y_Actual','y_Predicted'])\n",
    "df['y_Actual'] = np.where(df['y_Actual'] == -1, df['y_Predicted'], df['y_Actual'])\n",
    "df_ebike_new_trips['Replaced_mode'] = df['y_Actual']\n",
    "\n",
    "# Relabel with original mode names for plotting\n",
    "for mode in av:\n",
    "    mode_text = '_'.join(str(av[mode]).split('_')[1:])\n",
    "    df_ebike_new_trips['Mode_confirm'] = df_ebike_new_trips['Mode_confirm'].replace(mode,mode_text)\n",
    "    df_ebike_new_trips['Replaced_mode'] = df_ebike_new_trips['Replaced_mode'].replace(mode,mode_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitution rate of ebike trips not including new trips (with labeled replacements)\n",
    "plot_data = df_ebike_new_trips.groupby(['Replaced_mode']).count()[['Mode_confirm']].reset_index()\n",
    "plot_data['subst_rate'] = plot_data['Mode_confirm'] / sum(plot_data['Mode_confirm'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Replaced_mode', y='subst_rate').set(title='Ebike Mode Replacement', xlabel='Replaced Mode', ylabel='Substitution Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "# ax.figure.savefig(\"/plots/ts_emissions_user%s.png\"%file_suffix, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From table in paper\n",
    "emission_rates = [343.3, 18.5, 343.3, 39.8, 123.8, 0.0]\n",
    "subst_rates = plot_data['subst_rate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g-CO2/mi reduction through ebike availability\n",
    "sum(emission_rates * subst_rates) / sum(subst_rates) - 39.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# New activity\n",
    "df_ebike = df_rep_unlabeled.drop(columns=['date_time'])\n",
    "df_ebike = df_ebike[df_ebike['Mode_confirm']==6]\n",
    "df_ebike_new_trips = df_ebike[df_ebike['Replaced_mode']==7].copy()\n",
    "sum(df_ebike_new_trips.distance_miles) / sum(df_ebike.distance_miles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Replaced Mode Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at av column corresponding to stated replaced mode; 1 if available\n",
    "df_replaced_trips = data[~data['Replaced_mode'].isin([6,7])].copy()\n",
    "replaced_list = [df_replaced_trips[str(av[x])].iloc[i] for i, x in enumerate(df_replaced_trips.Replaced_mode)]\n",
    "df_replaced_trips['replaced_in_stated'] = replaced_list\n",
    "\n",
    "# Relabel with original mode names for plotting\n",
    "for mode in av:\n",
    "    mode_text = '_'.join(str(av[mode]).split('_')[1:])\n",
    "    df_replaced_trips['Mode_confirm'] = df_replaced_trips['Mode_confirm'].replace(mode,mode_text)\n",
    "    df_replaced_trips['Replaced_mode'] = df_replaced_trips['Replaced_mode'].replace(mode,mode_text)\n",
    "\n",
    "\n",
    "df_replaced_trips['Mode_confirm'] = df_replaced_trips['Mode_confirm'].replace(6,'ebike')\n",
    "df_replaced_trips['Replaced_mode'] = df_replaced_trips['Replaced_mode'].replace(6,'ebike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurately stated replacement mode for all users\n",
    "plot_data = df_replaced_trips[df_replaced_trips['Mode_confirm']=='ebike']\n",
    "plot_data = plot_data.groupby(['date_time'], as_index=False)['replaced_in_stated'].agg(['sum','count']).apply(lambda x: x.rolling(14,1).mean())\n",
    "plot_data['proportion'] = plot_data['sum'] / plot_data['count']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.lineplot(ax=ax, data=plot_data, x='date_time', y='proportion').set(title='Proportion of Daily E-Bike Trips With Correctly Stated Replacement Mode', xlabel='Date', ylabel='Proportion Correct')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "# ax.figure.savefig(\"/plots/ts_emissions_user%s.png\"%file_suffix, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurately stated replacement mode for all users across modes\n",
    "plot_data = df_replaced_trips.groupby(['Mode_confirm'], as_index=False)['replaced_in_stated'].agg(['sum','count']).reset_index()\n",
    "plot_data['proportion'] = plot_data['sum'] / plot_data['count']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Mode_confirm', y='proportion').set(title='Distribution of Modes Which Replaced a Non-Available Mode', xlabel='Primary Mode', ylabel='Proportion Correct')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "# ax.figure.savefig(\"/plots/ts_emissions_user%s.png\"%file_suffix, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurately stated replacement mode for all users across modes\n",
    "plot_data = df_replaced_trips.groupby(['Replaced_mode'], as_index=False)['replaced_in_stated'].agg(['sum','count']).reset_index()\n",
    "plot_data['proportion'] = 1 - (plot_data['sum'] / plot_data['count'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Replaced_mode', y='proportion').set(title='Distribution of Anomalously Stated Replacement Modes', xlabel='Stated Mode Replaced', ylabel='Proportion Incorrect')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "# ax.figure.savefig(\"/plots/ts_emissions_user%s.png\"%file_suffix, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurately stated replacement mode for all users\n",
    "df_replaced_trips.user_id = df_replaced_trips.user_id.astype(str)\n",
    "plot_data = df_replaced_trips.groupby(['user_id'], as_index=False)['replaced_in_stated'].agg(['sum','count']).reset_index()\n",
    "plot_data['proportion'] = plot_data['sum'] / plot_data['count']\n",
    "plot_data = plot_data.sort_values('proportion', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='user_id', y='proportion', color='darkblue').set(title='Proportion of Trips With Correctly Stated Replacement Mode', xlabel='User', ylabel='Proportion Correct')\n",
    "plt.xticks(rotation=90)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "# ax.figure.savefig(\"/plots/ts_emissions_user%s.png\"%file_suffix, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurately stated replacement mode for all users\n",
    "df_replaced_trips.user_id = df_replaced_trips.user_id.astype(str)\n",
    "plot_data = df_replaced_trips.groupby(['user_id'], as_index=False)['replaced_in_stated'].agg(['sum','count']).reset_index()\n",
    "plot_data['incorrect'] = plot_data['count'] - plot_data['sum']\n",
    "plot_data['user_id'] = plot_data['user_id'].astype(str).str[-4:]\n",
    "plot_data = plot_data.sort_values('incorrect', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='user_id', y='incorrect', color='darkblue').set(title='Trips With Unavailable Stated Replacement Mode', xlabel='User', ylabel='Count Incorrect')\n",
    "plt.xticks(rotation=90)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "# ax.figure.savefig(\"/plots/ts_emissions_user%s.png\"%file_suffix, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_replaced_trips) / len(pd.unique(df_replaced_trips.user_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
