{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = None\n",
    "month = None\n",
    "program = \"prepilot\"\n",
    "include_replaced_modes_as_valid = True # Flip this when we want to get results versus generate the replaced_mode correction graphs\n",
    "model_with_sensed = False\n",
    "input_dataset = \"ONLY_LABELED\" # \"ONLY_LABELED\", \"ONLY_SENSED\" or \"BEST_AVAILABLE\" for sensitivity analysis\n",
    "LABEL_ASSIST_THRESHOLD = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import datetime\n",
    "\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "import biogeme.models as models\n",
    "import biogeme.distributions as dist\n",
    "from biogeme.expressions import Beta, DefineVariable, RandomVariable, exp, PanelLikelihoodTrajectory, bioDraws, log, MonteCarlo, Integrate\n",
    "import biogeme.results as res\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import sklearn.metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import emission.core.get_database as edb\n",
    "import emission.core.wrapper.entry as ecwe\n",
    "import emission.storage.decorations.analysis_timeseries_queries as esda\n",
    "import emission.storage.decorations.trip_queries as esdt\n",
    "import emission.storage.decorations.timeline as esdl\n",
    "import emission.storage.timeseries.abstract_timeseries as esta\n",
    "import emission.storage.timeseries.timequery as estt\n",
    "import scaffolding\n",
    "from uuid import UUID\n",
    "\n",
    "import replacement_models\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(replacement_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Data From Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading mapping dictionaries from mapping_dictionaries notebook\n",
    "# Dictionary map is putting all other replaced modes into other\n",
    "%store -r df_EI\n",
    "%store -r dic_re\n",
    "%store -r dic_pur\n",
    "%store -r dic_fuel\n",
    "\n",
    "# convert a dictionary to a defaultdict\n",
    "dic_pur = defaultdict(lambda: 'Other',dic_pur)\n",
    "dic_re = defaultdict(lambda: 'Other',dic_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tq = scaffolding.get_time_query(year, month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's get UUID lists for all the three categories\n",
    "# stage, all, non_stage\n",
    "stage_uuids = []\n",
    "all_uuids = []\n",
    "non_stage_uuids = []\n",
    "for ue in edb.get_uuid_db().find():\n",
    "    all_uuids.append(str(ue['uuid']))\n",
    "    if ue['user_email'].startswith(\"stage_\"):\n",
    "        stage_uuids.append(str(ue['uuid']))\n",
    "    else:\n",
    "        non_stage_uuids.append(str(ue['uuid']))\n",
    "stage_uuids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the proportions across them\n",
    "len(stage_uuids), len(non_stage_uuids), len(all_uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the participant confirmed trips\n",
    "participant_ct_df = scaffolding.load_all_participant_trips(program, tq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait, we have 219 unique trips, which doesn't match any of the numbers\n",
    "len(participant_ct_df.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if this is because of strings; nope\n",
    "participant_ct_df[\"user_id_str\"] = participant_ct_df.user_id.apply(lambda u: str(u))\n",
    "len(participant_ct_df.user_id_str.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see which category the missing trips fit into\n",
    "missing_uuids = set(all_uuids).difference(set(participant_ct_df.user_id_str))\n",
    "len(missing_uuids), 245 - 219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(missing_uuids).intersection(stage_uuids), set(missing_uuids).intersection(non_stage_uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# They seem to be split pretty evenly between stage and non stage\n",
    "len(set(missing_uuids).intersection(stage_uuids)), len(set(missing_uuids).intersection(non_stage_uuids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stage users, comparing string, we find a difference\n",
    "non_stage_ct_df = participant_ct_df[~participant_ct_df['user_id_str'].isin(stage_uuids)]\n",
    "stage_ct_df = participant_ct_df[participant_ct_df['user_id_str'].isin(stage_uuids)]\n",
    "print(len(non_stage_ct_df))\n",
    "print(len(stage_ct_df))\n",
    "print(len(participant_ct_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we have missing UUIDs, let's confirm that none of them have trips in the database\n",
    "# and that we are not missing trips just because of read limits\n",
    "missing_stage_uuids = set(missing_uuids).intersection(stage_uuids)\n",
    "missing_non_stage_uuids = set(missing_uuids).intersection(non_stage_uuids)\n",
    "\n",
    "from uuid import UUID\n",
    "import emission.core.get_database as edb\n",
    "\n",
    "for uuid_str in missing_stage_uuids.union(missing_non_stage_uuids):\n",
    "    print(f\"For {uuid_str}, found %d trips in the database\" % \n",
    "          (edb.get_analysis_timeseries_db().count_documents({\"user_id\": UUID(uuid_str), \"metadata.key\": \"analysis/confirmed_trip\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeled_ct = scaffolding.filter_labeled_trips(participant_ct_df)\n",
    "# expanded_ct = scaffolding.expand_userinputs(labeled_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sensed as well as labeled trips\n",
    "expanded_ct = scaffolding.expand_userinputs(participant_ct_df)\n",
    "expanded_stage_ct = scaffolding.expand_userinputs(stage_ct_df)\n",
    "expanded_non_stage_ct = scaffolding.expand_userinputs(non_stage_ct_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using non-stage users\n",
    "expanded_ct = scaffolding.data_quality_check(expanded_non_stage_ct)\n",
    "expanded_ct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SHANKARI: I am not sure it is OK to fill in the inferred values as `mode_confirm`\n",
    "# mode confirm should be reserved for user input\n",
    "# the inferred labels are generated by the label assist algorithm and have accuracy of ~ 50%\n",
    "\n",
    "def describe_labels(ct_df):\n",
    "    # How much data total\n",
    "    print(\"Total number of trips\", len(ct_df))\n",
    "\n",
    "    # data with user specified modes\n",
    "    print(\"Trips with user specified labels\", len(ct_df[~pd.isna(ct_df.mode_confirm)]))\n",
    "      \n",
    "    # how much data without labels and with and without label assist\n",
    "    no_user_label_ct_df = ct_df[pd.isna(ct_df.mode_confirm)]\n",
    "    print(\"Trips without user specified labels\", len(no_user_label_ct_df))\n",
    "    is_empty_check = lambda ll: len(ll) == 0\n",
    "    print(\"Trips without user label but with inferred label\", len(no_user_label_ct_df[~no_user_label_ct_df.inferred_labels.apply(is_empty_check)]))\n",
    "    print(\"Trips without user label or inferred label\", len(no_user_label_ct_df[no_user_label_ct_df.inferred_labels.apply(is_empty_check)]))\n",
    "\n",
    "describe_labels(expanded_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_user_label_ct_df[no_user_label_ct_df.inferred_labels.apply(is_empty_check)][[\"inferred_labels\", \"start_fmt_time\", \"end_fmt_time\", \"mode_confirm\", \"purpose_confirm\", \"user_id\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we really only have 57k labeled trips, not 115k\n",
    "# we can generate results with label assist and/or primary sensed mode for comparison,\n",
    "# but I think that the most principled version of the evaluation should use only labeled trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small unit test\n",
    "# mode_split_map = pd.Series({'bicycling': 0.3244066758052265, 'walking': 0.6755933241947736})\n",
    "# mode_split_map.index[mode_split_map.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from https://github.com/allenmichael099/e-mission-eval-private-data/blob/hybrid_labeling_analysis_Michael/Error_bars/add_new_label_fields.py#L45\n",
    "# TODO: Need to clean up later instead of copy-paste\n",
    "def get_primary_sensed_mode(ct_row):\n",
    "    # These keys were found in emission/core/wrapper/modeprediction.py:\n",
    "    sensed_mode_types = {0: \"unknown\", 1: \"drove_alone\",2: \"bike\",\n",
    "                     3: \"bus\", 4: \"train\", 5: \"car\", 6: \"air_or_hsr\",\n",
    "                     7: \"train\", 8: \"train\", 9: \"train\"}\n",
    "\n",
    "    # Get the segments for the trip.\n",
    "    #cleaned_section will only have walk/bike/automotive, inferred_section is the one that has bus/train/car etc \n",
    "    segments = esdt.get_sections_for_trip(key = \"analysis/inferred_section\", user_id = ct_row[\"user_id\"], trip_id = ct_row['cleaned_trip'])\n",
    "\n",
    "    # get pairs of mode type and duration\n",
    "    trip_mode_durations = {}\n",
    "    total_dur = 0\n",
    "    for s in segments:\n",
    "\n",
    "        # the sensed mode is a number in the database, so I'm relabeling it as a string.\n",
    "        mode = sensed_mode_types[s['data']['sensed_mode']]\n",
    "        duration = s['data']['duration']\n",
    "\n",
    "        if mode not in trip_mode_durations.keys(): trip_mode_durations[mode] = 0\n",
    "        trip_mode_durations[mode] += duration\n",
    "\n",
    "        total_dur += duration\n",
    "    # convert the durations to fractions of the total segment moving time (not the trip time, since trips include stop times)\n",
    "    # output is something like {'bicycling': 0.3244066758052265, 'walking': 0.6755933241947736}\n",
    "    mode_split_map = pd.Series({mode: duration/total_dur  for mode,duration in trip_mode_durations.items()})\n",
    "    primary_mode = mode_split_map.index[mode_split_map.argmax()]\n",
    "#     print(f\"After processing {len(segments)} segments for trip {ct_row['_id']} for user {ct_row['user_id']}, returning {primary_mode}\")\n",
    "    return primary_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_prob_label(inferred_label_list, p_threshold):\n",
    "    # copied from emission/storage/decorations/trip_queries.py\n",
    "    # Two columns: \"labels\" and \"p\"\n",
    "    label_prob_df = pd.DataFrame(inferred_label_list)\n",
    "    # logging.debug(label_prob_df)\n",
    "    # idxmax returns the index corresponding to the max data value in each column\n",
    "    max_p = label_prob_df.p.max()\n",
    "    if max_p > p_threshold:\n",
    "        max_p_idx = label_prob_df.p.idxmax()\n",
    "        # logging.debug(max_p_idx)\n",
    "        # now we look up the labels for that index\n",
    "        return label_prob_df.loc[max_p_idx].labels\n",
    "    else:\n",
    "        print(f\"max_p {max_p} < threshold {p_threshold}, returning None\")\n",
    "        return None\n",
    "\n",
    "def get_best_label_assist_mode(ct_row, p_threshold):\n",
    "    # copied and modified from emission/storage/decorations/trip_queries.py line 290-ish\n",
    "    all_inferred_labels = ct_row.inferred_labels\n",
    "    if len(all_inferred_labels) > 0:\n",
    "        max_p_labels = get_max_prob_label(all_inferred_labels, p_threshold)\n",
    "        return max_p_labels[\"mode_confirm\"] if max_p_labels is not None else None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_best_hybrid_mode(ct_row):\n",
    "    if ct_row.mode_confirm is not None:\n",
    "        return ct_row\n",
    "    else:\n",
    "        best_label_assist_mode = get_best_label_assist_mode(ct_row, LABEL_ASSIST_THRESHOLD)\n",
    "        if best_label_assist_mode is not None:\n",
    "            return best_label_assist_mode\n",
    "        else:\n",
    "            return get_primary_sensed_mode(ct_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Basic sanity checks\n",
    "sanity_test_df = expanded_ct.sample(n=50, random_state=1234)\n",
    "print(\"Sanity testing characteristics \")\n",
    "describe_labels(sanity_test_df)\n",
    "\n",
    "only_sensed_df = sanity_test_df.copy()\n",
    "only_sensed_df.mode_confirm = sanity_test_df.apply(lambda row: get_primary_sensed_mode(row), axis=1)\n",
    "# This should be zero\n",
    "print(only_sensed_df[pd.isna(only_sensed_df.mode_confirm)])\n",
    "\n",
    "only_label_assist_df = sanity_test_df.copy()\n",
    "only_label_assist_df.mode_confirm = sanity_test_df.apply(lambda row: get_best_label_assist_mode(row, LABEL_ASSIST_THRESHOLD), axis=1)\n",
    "print(only_label_assist_df[pd.isna(only_label_assist_df.mode_confirm)][[\"start_fmt_time\", \"end_fmt_time\"]])\n",
    "\n",
    "hybrid_df = sanity_test_df.copy()\n",
    "hybrid_df.mode_confirm = sanity_test_df.apply(lambda row: get_best_hybrid_mode(row), axis=1)\n",
    "print(hybrid_df[pd.isna(hybrid_df.mode_confirm)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_dataset == \"ONLY_LABELED\":\n",
    "    expanded_ct = scaffolding.filter_labeled_trips(expanded_ct)\n",
    "elif input_dataset == \"BEST_AVAILABLE\":\n",
    "    expanded_ct = expanded_ct.apply(lambda row: get_best_hybrid_mode(row), axis=1)\n",
    "elif input_dataset == \"ONLY_SENSED\":\n",
    "    expanded_ct.mode_confirm = expanded_ct.apply(lambda row: get_primary_sensed_mode(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mapping new labels with dictionaries\n",
    "expanded_ct['Trip_purpose'] = expanded_ct['purpose_confirm'].map(dic_pur)\n",
    "expanded_ct['Mode_confirm'] = expanded_ct['mode_confirm'].map(dic_re)\n",
    "expanded_ct['Replaced_mode'] = expanded_ct['replaced_mode'].map(dic_re)\n",
    "\n",
    "# Mapping fuel\n",
    "expanded_ct['Mode_confirm_fuel'] = expanded_ct['Mode_confirm'].map(dic_fuel)\n",
    "expanded_ct['Replaced_mode_fuel'] = expanded_ct['Replaced_mode'].map(dic_fuel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change meters to miles\n",
    "scaffolding.unit_conversions(expanded_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_suffix = scaffolding.get_file_suffix(year, month, program)\n",
    "quality_text = scaffolding.get_quality_text(participant_ct_df, expanded_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate energy impact\n",
    "expanded_ct = scaffolding.energy_intensity(expanded_ct, df_EI, 'distance_miles', 'Replaced_mode', 'Mode_confirm')\n",
    "expanded_ct = scaffolding.energy_impact_kWH(expanded_ct, 'distance_miles', 'Replaced_mode', 'Mode_confirm')\n",
    "expanded_ct = scaffolding.CO2_impact_lb(expanded_ct, 'distance_miles', 'Replaced_mode', 'Mode_confirm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the expanded database data to socioeconomic data\n",
    "socio_data = pd.read_csv('./Can Do Colorado eBike Program - en.csv')\n",
    "socio_data.rename(columns={'Unique User ID (auto-filled, do not edit)':'user_id',\n",
    "                          'Please identify which category represents your total household income, before taxes, for last year.':'HHINC',\n",
    "                          'How many motor vehicles are owned, leased, or available for regular use by the people who currently live in your household?':'VEH',\n",
    "                           'In which year were you born?':'AGE',\n",
    "                          'Including yourself, how many people live in your home?':'HHSIZE',\n",
    "                          'How many children under age 18 live in your home?':'CHILDREN',\n",
    "                          'What is your gender?':'GENDER',\n",
    "                          'If you were unable to use your household vehicle(s), which of the following options would be available to you to get you from place to place?':'available_modes',\n",
    "                          'Are you a student?':'STUDENT'}, inplace=True)\n",
    "socio_data = socio_data[~socio_data.user_id.isnull()]\n",
    "\n",
    "# Deal with people who have multiple responses by using most recent\n",
    "socio_data = socio_data.sort_values(by=['user_id', 'Timestamp'])\n",
    "socio_data.drop_duplicates(subset=['user_id'], keep='last', inplace=True)\n",
    "socio_data['user_id_socio'] = socio_data.user_id\n",
    "socio_data = socio_data.drop(labels='user_id', axis=1)\n",
    "\n",
    "# Lose some trips due to people with no survey responses\n",
    "expanded_ct['user_id_socio'] = expanded_ct.user_id.astype(str)\n",
    "expanded_ct.user_id_socio = [i.replace('-','') for i in expanded_ct.user_id_socio] # remove all dashes from strings\n",
    "expanded_ct = expanded_ct.merge(socio_data, on='user_id_socio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add non-label category\n",
    "expanded_ct['replaced_mode'] = expanded_ct['replaced_mode'].fillna('Unlabeled')\n",
    "expanded_ct.loc[expanded_ct['replaced_mode'] == 'Unlabeled', 'Replaced_mode'] = \"Unlabeled\"\n",
    "\n",
    "# Select variables of interest from complete OpenPATH data\n",
    "data = expanded_ct[['Mode_confirm','Replaced_mode','replaced_mode','Trip_purpose','duration','distance_miles','start_local_dt_weekday','available_modes','AGE','HHINC','VEH','HHSIZE','CHILDREN','GENDER','STUDENT','user_id','_id','start_local_dt_year','start_local_dt_month','start_local_dt_day','cleaned_trip']].copy()\n",
    "\n",
    "# List of variables to keep in data but not turn into categorical number variables\n",
    "dont_categorize = ['user_id','_id','cleaned_trip']\n",
    "\n",
    "# Make copy of user_id to be categorized since both versions are needed\n",
    "data['user_id_int'] = data['user_id']\n",
    "\n",
    "# Get timestamp from known year/month/day aggregated to days\n",
    "data.rename(columns={'start_local_dt_year':'year','start_local_dt_month':'month','start_local_dt_day':'day'}, inplace=True)\n",
    "data['date_time'] = pd.to_datetime(data[['year','month','day']])\n",
    "data = data.drop(columns=['year','month','day'])\n",
    "\n",
    "# Fix age\n",
    "data['AGE'] = 2022 - data['AGE']\n",
    "\n",
    "# Get number of workers\n",
    "data['WORKERS'] = data['HHSIZE'] - data['CHILDREN']\n",
    "\n",
    "# Duration in minutes\n",
    "data['duration'] = data['duration'] / 60\n",
    "\n",
    "# Filter out some responses to data\n",
    "data = data[~data['Mode_confirm'].isin(['Not a Trip','Other'])]\n",
    "data = data[~data['Replaced_mode'].isin(['Not a Trip','Other'])]\n",
    "data = data[~data['available_modes'].isin(['None', 'Prefer not to say'])]\n",
    "# data = data[~data['Trip_purpose'].isin(['not_a_trip','Other'])]\n",
    "# data = data[~data['HHINC'].isin(['Prefer not to say'])]\n",
    "# data = data[~data['VEH'].isin(['Prefer not to say / Prefiero no decir.'])]\n",
    "\n",
    "# Combine variable categories\n",
    "data = data.replace('Car, drove alone', 'car')\n",
    "data = data.replace('Car, with others', 's_car')\n",
    "data = data.replace('Bikeshare', 's_micro')\n",
    "data = data.replace('Scooter share', 's_micro')\n",
    "data = data.replace('Regular Bike', 'p_micro')\n",
    "data = data.replace('Skate board', 'p_micro')\n",
    "data = data.replace('Train', 'transit')\n",
    "data = data.replace('Free Shuttle', 'transit')\n",
    "data = data.replace('Bus', 'transit')\n",
    "data = data.replace('Walk', 'walk')\n",
    "data = data.replace('Taxi/Uber/Lyft', 'ridehail')\n",
    "data = data.replace('Pilot ebike', 'ebike')\n",
    "\n",
    "# data = data.replace(['Home','School','Work'], 'hbw')\n",
    "# data = data.replace(['Entertainment/Social','Meal','Personal/Medical','Pick-up/Drop off','Recreation/Exercise','Religious','Shopping','Transit transfer'], 'non_hbw')\n",
    "\n",
    "# data['start_local_dt_weekday'] = data['start_local_dt_weekday'].replace(['1','2','3','4','5'],'1')\n",
    "# data['start_local_dt_weekday'] = data['start_local_dt_weekday'].replace(['0','6'],'0')\n",
    "\n",
    "# data = data.replace(['By hours ','Custodian','Fire Fighter 2 Training',\n",
    "#  'Graduate','Prefer not to say','Taking prerequisites missing for grad program ',\n",
    "#  'Yes - Full Time College/University',\n",
    "#  'Yes - Part-Time College/University',\n",
    "#  'Yes - Vocation/Technical/Trade School',\n",
    "#  'taking classes toward early childhood licensure'], 'student')\n",
    "# data = data.replace('Not a student', 'non_student')\n",
    "\n",
    "# Calculate travel times for each trip, across every mode\n",
    "def add_all_mode_tt(data, mode_col, duration_col, dist_col):\n",
    "    mode_travel_times = {}\n",
    "    for mode in pd.unique(data[mode_col]):\n",
    "\n",
    "        # Linear model for duration based on distance for trips belonging to each mode\n",
    "        mode_data = data[data[mode_col]==mode]\n",
    "        regr = linear_model.LinearRegression()\n",
    "        regr.fit(mode_data[dist_col].values.reshape(-1,1), mode_data[duration_col].values.reshape(-1,1))\n",
    "\n",
    "        # Make prediction for ALL trips\n",
    "        mode_duration_pred = regr.predict(data[dist_col].values.reshape(-1,1))\n",
    "        mode_travel_times['tt_'+mode] = mode_duration_pred\n",
    "\n",
    "    # Apply for each mode existing in the dataframe\n",
    "    for mode in mode_travel_times:\n",
    "        data[mode] = mode_travel_times[mode]\n",
    "\n",
    "    return data\n",
    "\n",
    "# Calculate all mode travel times and add to dataframe\n",
    "data = add_all_mode_tt(data,'Mode_confirm','duration','distance_miles')\n",
    "\n",
    "# Calculate vehicle costs based roughly on $/mi from: https://www.vtpi.org/tca/tca0501.pdf\n",
    "cost_factors = {'car':0.80,\n",
    "                's_car':0.40,\n",
    "                'ridehail':3.00,\n",
    "                's_micro':1.50,\n",
    "                'transit':0.40}\n",
    "\n",
    "def add_all_mode_cost(data, cost_factors, dist_col):\n",
    "    for factor in cost_factors:\n",
    "        data['cost_'+factor] = cost_factors[factor] * data[dist_col]\n",
    "    return data\n",
    "\n",
    "# Calculate all mode travel costs and add to dataframe\n",
    "add_all_mode_cost(data, cost_factors, 'distance_miles')\n",
    "\n",
    "# Labels for modes in the availability survey\n",
    "availability_codes = {'Public transportation (bus, subway, light rail, etc.)':'transit',\n",
    "                      'Get a ride from a friend or family member':'s_car',\n",
    "                      'Rental car (including Zipcar/ Car2Go)':'car',\n",
    "                      'Taxi (regular taxi, Uber, Lyft, etc)':'ridehail',\n",
    "                      'Bicycle':'p_micro',\n",
    "                      'Shared bicycle or scooter':'s_micro',\n",
    "                      'Walk/roll':'walk',\n",
    "                      'Skateboard':'p_micro',\n",
    "                      'ebike':'ebike',\n",
    "                      'None':'none'}\n",
    "\n",
    "def add_mode_availability(data, availability_codes, availability_col, choice_col, replaced_col, is_sp):\n",
    "    mode_list = np.unique(list(availability_codes.values())[:-1])\n",
    "    choice_list = data[choice_col].values\n",
    "    replaced_list = data[replaced_col].values\n",
    "    for mode in mode_list:\n",
    "        mode_avail = []\n",
    "        for i, available in enumerate(data[availability_col].values):\n",
    "            available_modes = [availability_codes[x] for x in available.split(';')]\n",
    "            # For SP: Replacement/stated available should be 1, chosen should be 0\n",
    "            if is_sp:\n",
    "                if mode==choice_list[i]:\n",
    "                    mode_check = False\n",
    "                else:\n",
    "                    mode_check = mode==replaced_list[i] or mode in available_modes\n",
    "            # For RP: Chosen/replacement/stated available should be 1\n",
    "            else:\n",
    "                mode_check = mode==choice_list[i] or mode==replaced_list[i] or mode in available_modes\n",
    "            # Keep binary list of which trips the mode was available for\n",
    "            if mode_check:\n",
    "                mode_avail.append(1)\n",
    "            else:\n",
    "                mode_avail.append(0)\n",
    "        # For each mode add a column with binary availability\n",
    "        data['av_'+mode] = mode_avail\n",
    "\n",
    "    return data\n",
    "\n",
    "# Split data into revealed choice and stated replacement choice (2 obs per trip)\n",
    "data_rp = data.copy()\n",
    "data_sp = data.copy()\n",
    "data_rp['is_sp'] = False\n",
    "data_sp['is_sp'] = True\n",
    "data_rp['mode_choice'] = data_rp['Mode_confirm']\n",
    "data_sp['mode_choice'] = data_sp['Replaced_mode']\n",
    "\n",
    "# The SP data cannot include trips where the chosen/replaced modes are stated the same\n",
    "# We need to mark the chosen mode as unavailable in the SP data, which breaks the model if they're the same\n",
    "data_sp = data_sp[data_sp.Mode_confirm!=data_sp.Replaced_mode]\n",
    "\n",
    "# Make sure both chosen and replaced modes are in choice sets\n",
    "data_rp = add_mode_availability(data_rp, availability_codes, 'available_modes', 'Mode_confirm', 'Replaced_mode', is_sp=False)\n",
    "data_sp = add_mode_availability(data_sp, availability_codes, 'available_modes', 'Mode_confirm', 'Replaced_mode', is_sp=True)\n",
    "\n",
    "# Combine RP/SP data. Keep RP data separate with a few additional columns for later analysis.\n",
    "data = pd.concat([data_rp, data_sp])\n",
    "data = data[~data['Replaced_mode'].isin(['Unlabeled', 'No Travel'])]\n",
    "\n",
    "# Handle all variables that are ordinal; otherwise they may not end up in correct order\n",
    "# data.HHINC = pd.Categorical(data.HHINC,\n",
    "#                             ordered=True,\n",
    "#                             categories=['Less than $24,999',\n",
    "#                                        '$25,000-$49,999',\n",
    "#                                        '$50,000-$99,999',\n",
    "#                                        '$100,000 -$149,999',\n",
    "#                                        '$150,000-$199,999',\n",
    "#                                        '$200,000 or more'])\n",
    "# data.VEH = pd.Categorical(data.VEH,\n",
    "#                             ordered=True,\n",
    "#                             categories=['0',\n",
    "#                                        '1',\n",
    "#                                        '2',\n",
    "#                                        '3',\n",
    "#                                        '4+'])\n",
    "\n",
    "# Make sure that all mode variables align after being converted to numeric variables\n",
    "mode_list = ['car','s_car','ridehail','transit','p_micro','s_micro','walk','ebike']\n",
    "data.mode_choice = pd.Categorical(data.mode_choice, ordered=True, categories=mode_list)\n",
    "data.Mode_confirm = pd.Categorical(data.Mode_confirm, ordered=True, categories=mode_list)\n",
    "data.Replaced_mode = pd.Categorical(data.Replaced_mode, ordered=True, categories=mode_list)\n",
    "\n",
    "# Convert categorical variables to numeric\n",
    "cat_columns = data.select_dtypes(['object','category']).columns\n",
    "cat_columns = cat_columns.drop(labels=dont_categorize)\n",
    "all_categories = []\n",
    "for i in range(0,len(cat_columns)):\n",
    "    # Keep a record of what order the categories are in when converted\n",
    "    var_categories = data[cat_columns].astype('category').iloc[:,i].cat.categories\n",
    "    all_categories.append(var_categories)\n",
    "data[cat_columns] = data[cat_columns].apply(lambda x: x.astype('category').cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show listed categories in their order\n",
    "cat_code_lookup = dict(zip(cat_columns.values, [list(x.values) for x in all_categories]))\n",
    "cat_code_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setting up dataframes for different analyses throughout the notebook\n",
    "\n",
    "# Only ebike, labeled trips\n",
    "df_ebike = data_rp[data_rp['Mode_confirm'].isin(['ebike'])].copy()\n",
    "df_ebike = df_ebike[~df_ebike['Replaced_mode'].isin(['Unlabeled','No Travel'])]\n",
    "\n",
    "# Only ebike, unlabeled trips\n",
    "df_ebike_unlabeled = data_rp[data_rp['Mode_confirm'].isin(['ebike'])].copy()\n",
    "df_ebike_unlabeled = df_ebike_unlabeled[df_ebike_unlabeled['Replaced_mode'].isin(['Unlabeled'])].copy()\n",
    "\n",
    "# Only ebike, new trips\n",
    "df_ebike_new_travel = data_rp[data_rp['Mode_confirm'].isin(['ebike'])].copy()\n",
    "df_ebike_new_travel = df_ebike_new_travel[df_ebike_new_travel['Replaced_mode'].isin(['No Travel'])]\n",
    "\n",
    "# RP data only for basic stats and analysis (Removed unlabeled and no travel)\n",
    "df_rp = data[data['is_sp']==False]\n",
    "\n",
    "# For analysis of accurately stated replacements\n",
    "df_replaced_trips = data_rp[~data_rp['Replaced_mode'].isin(['No Travel','Unlabeled'])].copy()\n",
    "\n",
    "# Set up K-fold cross validation\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "# Collect all scores to show at end of modeling\n",
    "score_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that mode availability is being set properly\n",
    "# mode_choice should always be available; in RP it is Mode_confirm in SP it is Replaced_mode\n",
    "for i, mode in enumerate(cat_code_lookup['mode_choice']):\n",
    "    print(mode)\n",
    "    assert sum(data[data['mode_choice']==i][f\"av_{mode}\"]) == len(data[data['mode_choice']==i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data stats\n",
    "print(f\"Trips: {len(df_rp)}\")\n",
    "print(f\"Observed Choices: {len(data)}\")\n",
    "print(f\"Users: {len(np.unique(data.user_id))}\")\n",
    "print(f\"Trips per user: {len(data) / len(pd.unique(data.user_id))}\")\n",
    "print(f\"New activity: {len(df_ebike_new_travel) / len(df_ebike)}\")\n",
    "print(f\"Ebike all trips: {len(df_ebike)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitution rate of ebike trips not including new trips\n",
    "plot_data = df_rp.copy()\n",
    "plot_data['Trip_purpose'] = plot_data['Trip_purpose'].replace([0,1,2,3,4,5,6,7,8,9,10], cat_code_lookup['Trip_purpose'])\n",
    "plot_data['mode_choice'] = plot_data['mode_choice'].replace([0,1,2,3,4,5,6,7], cat_code_lookup['mode_choice'])\n",
    "plot_data = plot_data[~plot_data['Trip_purpose'].isin(['not_a_trip'])].groupby(['Trip_purpose']).count()[['mode_choice']].reset_index()\n",
    "plot_data = plot_data.sort_values('mode_choice', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,6))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Trip_purpose', y='mode_choice', color='darkblue').set(title='Trip Purpose', xlabel='Stated Purpose', ylabel='Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitution rate of ebike trips\n",
    "plot_data = df_rp.copy()\n",
    "plot_data['Trip_purpose'] = plot_data['Trip_purpose'].replace([0,1,2,3,4,5,6,7,8,9,10], cat_code_lookup['Trip_purpose'])\n",
    "plot_data['mode_choice'] = plot_data['mode_choice'].replace([0,1,2,3,4,5,6,7], cat_code_lookup['mode_choice'])\n",
    "plot_data = plot_data[plot_data['distance_miles']<10]\n",
    "plot_data['Mode'] = plot_data['mode_choice']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,8))\n",
    "sns.histplot(ax=ax, data=plot_data, x='distance_miles', hue='Mode', kde=True).set(title='Trip Distance', xlabel='Distance (mi)', ylabel='Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['tt_ebike', 'tt_s_car', 'tt_walk', 'tt_p_micro',\n",
    "       'tt_car', 'tt_transit', 'tt_s_micro', 'tt_ridehail', 'cost_car',\n",
    "       'cost_s_car', 'cost_ridehail', 'cost_s_micro', 'cost_transit', 'av_car', 'av_ebike', 'av_p_micro',\n",
    "       'av_ridehail', 'av_s_car', 'av_s_micro', 'av_transit', 'av_walk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on All Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test model\n",
    "rf, accuracy, f1, confusion = replacement_models.random_forest(data, 'mode_choice', feature_list, kf)\n",
    "\n",
    "# Save scores for model comparison\n",
    "score_results['rf_chosen_chosen'] = (np.mean(accuracy), np.mean(f1))\n",
    "print(f\"Accuracy: {np.mean(accuracy)}\")\n",
    "print(f\"F1: {np.mean(f1)}\")\n",
    "\n",
    "# Average and plot the confusion matrices\n",
    "confusion_mean = np.mean(np.array(confusion), axis=0)\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.heatmap(confusion_mean, annot=True, fmt='.1%', cmap='YlGnBu', linewidths=.5, xticklabels=all_categories[0].values, yticklabels=all_categories[0].values, cbar=False).set(title='Random Forest Confusion Matrix (Chosen)', xlabel='Predicted', ylabel='Actual')\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "\n",
    "rf_keep = rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on Chosen Test on Holdout Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test model (10 users for now)\n",
    "accuracy_holdout = []\n",
    "f1_holdout = []\n",
    "confusion_holdout = []\n",
    "for user in list(np.unique(df_rp.user_id))[:10]:\n",
    "\n",
    "    # Remove user from training data, keep only user in test data\n",
    "    labeled_df = data[data['user_id']!=user]\n",
    "    unlabeled_df = df_rp[df_rp['user_id']==user]\n",
    "\n",
    "    # Set the chosen mode availability to 0\n",
    "    for i in range(0,len(unlabeled_df)):\n",
    "        unlabeled_df[f\"av_{mode_list[unlabeled_df['Mode_confirm'].iloc[i]]}\"].iat[i] = 0\n",
    "\n",
    "    # Train on all trips by other users\n",
    "    rf, accuracy, f1, confusion = replacement_models.random_forest(labeled_df, 'mode_choice', feature_list, kf)\n",
    "\n",
    "    # Test on the stated replacement for holdout user\n",
    "    X_test = unlabeled_df[feature_list].values\n",
    "    y_pred = rf.predict(X_test)\n",
    "    y_test = unlabeled_df['Replaced_mode'].values\n",
    "\n",
    "    accuracy_holdout.append(sklearn.metrics.accuracy_score(y_test, y_pred))\n",
    "    f1_holdout.append(sklearn.metrics.f1_score(y_test, y_pred, average='weighted'))\n",
    "    confusion_holdout.append(sklearn.metrics.confusion_matrix(y_test, y_pred, labels=[0,1,2,3,4,5,6,7], normalize='pred'))\n",
    "\n",
    "# Save scores for model comparison\n",
    "score_results['rf_holdout_replaced'] = (np.mean(accuracy_holdout), np.mean(f1_holdout))\n",
    "print(f\"Accuracy: {np.mean(accuracy_holdout)}\")\n",
    "print(f\"F1: {np.mean(f1_holdout)}\")\n",
    "\n",
    "# Average and plot the confusion matrices\n",
    "confusion_mean = np.mean(confusion_holdout, axis=0).reshape(8,8)\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.heatmap(confusion_mean, annot=True, fmt='.1%', cmap='YlGnBu', linewidths=.5, xticklabels=all_categories[0].values, yticklabels=all_categories[0].values, cbar=False).set(title='Random Forest Confusion Matrix (Holdout)', xlabel='Predicted', ylabel='Actual')\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on n Samples Chosen Test on Replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test model\n",
    "samples_min = []\n",
    "user_min = []\n",
    "accuracy_min = []\n",
    "f1_min = []\n",
    "for n_samples in range(10,200,10):\n",
    "\n",
    "    # Sample n training data points from all users\n",
    "    labeled_df = data.sample(n_samples)\n",
    "\n",
    "    # Construct model (accuracy/f1 don't matter here; we re-test per user below)\n",
    "    rf, accuracy, f1, confusion = replacement_models.random_forest(labeled_df, 'mode_choice', feature_list, kf)\n",
    "\n",
    "    # Test on the stated replacement for holdout user\n",
    "    for user in list(np.unique(df_rp.user_id))[:10]:\n",
    "        unlabeled_df = df_rp[df_rp['user_id']==user]\n",
    "\n",
    "        # Set the chosen mode availability to 0\n",
    "        for i in range(0,len(unlabeled_df)):\n",
    "            unlabeled_df[f\"av_{mode_list[unlabeled_df['Mode_confirm'].iloc[i]]}\"].iat[i] = 0\n",
    "\n",
    "        # Test on the stated replacement for holdout user\n",
    "        X_test = unlabeled_df[feature_list].values\n",
    "        y_pred = rf.predict(X_test)\n",
    "        y_test = unlabeled_df['Replaced_mode'].values\n",
    "\n",
    "        accuracy_min.append(sklearn.metrics.accuracy_score(y_test, y_pred))\n",
    "        f1_min.append(sklearn.metrics.f1_score(y_test, y_pred, average='weighted'))\n",
    "        samples_min.append(n_samples)\n",
    "        user_min.append(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.DataFrame({'samples_min':samples_min, 'user_min':user_min, 'accuracy_min':accuracy_min, 'f1_min':f1_min})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,6))\n",
    "sns.boxplot(ax=ax, data=plot_data, x='samples_min', y='accuracy_min', color='purple').set(title='Accuracy on n Samples', xlabel='n Samples', ylabel='Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.DataFrame({'samples_min':samples_min, 'accuracy_min':accuracy_min, 'f1_min':f1_min})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,6))\n",
    "sns.barplot(ax=ax, data=plot_data, x='samples_min', y='accuracy_min', color='darkblue').set(title='Accuracy on n Samples', xlabel='n Samples', ylabel='Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choice Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MXL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on All Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(replacement_models)\n",
    "\n",
    "# Train and test model\n",
    "mxl, accuracy, f1, confusion = replacement_models.mxl(data, 'mode_choice')\n",
    "\n",
    "# Save scores for model comparison\n",
    "score_results['mxl_chosen_chosen'] = (np.mean(accuracy), np.mean(f1))\n",
    "print(f\"Accuracy: {np.mean(accuracy)}\")\n",
    "print(f\"F1: {np.mean(f1)}\")\n",
    "\n",
    "# Average and plot the confusion matrices\n",
    "confusion_mean = np.mean(np.array(confusion), axis=0)\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.heatmap(confusion_mean, annot=True, fmt='.1%', cmap='YlGnBu', linewidths=.5, xticklabels=all_categories[0].values, yticklabels=all_categories[0].values, cbar=False).set(title='MXL Confusion Matrix', xlabel='Predicted', ylabel='Actual')\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "\n",
    "# Save model parameters for prediction\n",
    "mxl_keep = mxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on All Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train and test model\n",
    "mnl, accuracy, f1, confusion = replacement_models.mnl(data, 'mode_choice', kf)\n",
    "\n",
    "# Save scores for model comparison\n",
    "score_results['mnl_chosen_chosen'] = (np.mean(accuracy), np.mean(f1))\n",
    "print(f\"Accuracy: {np.mean(accuracy)}\")\n",
    "print(f\"F1: {np.mean(f1)}\")\n",
    "\n",
    "# Average and plot the confusion matrices\n",
    "confusion_mean = np.mean(np.array(confusion), axis=0)\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.heatmap(confusion_mean, annot=True, fmt='.1%', cmap='YlGnBu', linewidths=.5, xticklabels=all_categories[0].values, yticklabels=all_categories[0].values, cbar=False).set(title='MNL Confusion Matrix', xlabel='Predicted', ylabel='Actual')\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "\n",
    "mnl_keep = mnl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(score_results.keys(), score_results.values()).reset_index()\n",
    "score_df.columns = ['Accuracy','F1','Model']\n",
    "model_types = score_df['Model'].str.split('_', expand=True)\n",
    "model_types.columns = ['Model Type','Train Set','Test Set']\n",
    "score_df = pd.concat([score_df, model_types], axis=1)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various model performances\n",
    "plot_data = score_df[score_df['Train Set']=='chosen']\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Test Set', y='Accuracy', hue='Model Type').set(title='Model Accuracy Trained on Primary', xlabel='Model', ylabel='Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various model performances\n",
    "plot_data = score_df[score_df['Train Set']=='chosen']\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Test Set', y='F1', hue='Model Type').set(title='Model F1 Trained on Primary', xlabel='Model', ylabel='F1')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various model performances\n",
    "plot_data = score_df\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Model', y='Accuracy').set(title='Model Accuracy', xlabel='Model', ylabel='Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various model performances\n",
    "plot_data = score_df\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Model', y='F1').set(title='Model F1', xlabel='Model', ylabel='F1')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ebike Substitution Rates and Emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitution rate of ebike trips not including new trips\n",
    "plot_data = df_ebike.groupby(['Replaced_mode']).count()[['Mode_confirm']].reset_index()\n",
    "plot_data['subst_rate'] = plot_data['Mode_confirm'] / sum(plot_data['Mode_confirm'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Replaced_mode', y='subst_rate').set(title='Ebike Mode Replacement', xlabel='Replaced Mode', ylabel='Substitution Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "print(plot_data['subst_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitution rate of ebike trips not including new trips\n",
    "# Set the chosen mode availability to 0\n",
    "for i in range(0,len(df_ebike_unlabeled)):\n",
    "    df_ebike_unlabeled[f\"av_{df_ebike_unlabeled['Mode_confirm'].iloc[i]}\"].iat[i] = 0\n",
    "\n",
    "# Predict replaced mode for the unlabeled trips\n",
    "y_pred = rf_keep.predict(df_ebike_unlabeled[feature_list].values)\n",
    "df_ebike_unlabeled['Replaced_mode'] = [mode_list[y] for y in y_pred]\n",
    "\n",
    "# Combine labeled and predicted-unlabeled ebike trips\n",
    "plot_data = pd.concat([df_ebike, df_ebike_unlabeled])\n",
    "plot_data = plot_data.groupby(['Replaced_mode']).count()[['Mode_confirm']].reset_index()\n",
    "plot_data['subst_rate'] = plot_data['Mode_confirm'] / sum(plot_data['Mode_confirm'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Replaced_mode', y='subst_rate').set(title='Ebike Mode Replacement (w/Labeling)', xlabel='Replaced Mode', ylabel='Substitution Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "print(plot_data['subst_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From df_EI\n",
    "# Combine variable categories\n",
    "df_EI = df_EI.replace('Car, drove alone', 'car')\n",
    "df_EI = df_EI.replace('Car, with others', 's_car')\n",
    "df_EI = df_EI.replace('Bikeshare', 's_micro')\n",
    "df_EI = df_EI.replace('Scooter share', 's_micro')\n",
    "df_EI = df_EI.replace('Regular Bike', 'p_micro')\n",
    "df_EI = df_EI.replace('Skate board', 'p_micro')\n",
    "df_EI = df_EI.replace('Train', 'transit')\n",
    "df_EI = df_EI.replace('Free Shuttle', 'transit')\n",
    "df_EI = df_EI.replace('Bus', 'transit')\n",
    "df_EI = df_EI.replace('Walk', 'walk')\n",
    "df_EI = df_EI.replace('Taxi/Uber/Lyft', 'ridehail')\n",
    "df_EI = df_EI.replace('Pilot ebike', 'ebike')\n",
    "emission_rates = df_EI.groupby(['mode']).mean().reset_index()[['mode','energy_intensity_factor','CO2_factor']]\n",
    "emission_rates['g_CO2_per_passmi'] = emission_rates.energy_intensity_factor*emission_rates.CO2_factor*0.000001*453.592\n",
    "emission_data = plot_data.merge(emission_rates, left_on='Replaced_mode', right_on='mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From df_EI\n",
    "emission_rates = emission_data.g_CO2_per_passmi.values\n",
    "subst_rates = emission_data.subst_rate.values\n",
    "\n",
    "# g-CO2/mi reduction through ebike availability\n",
    "sum(emission_rates * subst_rates) / sum(subst_rates) - 0.007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From table in paper\n",
    "emission_rates = [343.3, 18.5, 343.3, (343.3/2), 39.8, 123.8, 0.0]\n",
    "subst_rates = plot_data['subst_rate'].values\n",
    "\n",
    "# g-CO2/mi reduction through ebike availability\n",
    "sum(emission_rates * subst_rates) / sum(subst_rates) - 39.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Replaced Mode Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av = {0: 'av_car',\n",
    "      1: 'av_s_car',\n",
    "      2: 'av_ridehail',\n",
    "      3: 'av_transit',\n",
    "      4: 'av_p_micro',\n",
    "      5: 'av_s_micro',\n",
    "      6: 'av_walk',\n",
    "      7: 'av_ebike'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_list = [df_replaced_trips[f\"av_{x}\"].iloc[i] for i, x in enumerate(df_replaced_trips.Replaced_mode)]\n",
    "df_replaced_trips['replaced_in_stated'] = replaced_list\n",
    "\n",
    "# Relabel with original mode names for plotting\n",
    "for mode in av:\n",
    "    mode_text = '_'.join(str(av[mode]).split('_')[1:])\n",
    "    df_replaced_trips['Mode_confirm'] = df_replaced_trips['Mode_confirm'].replace(mode,mode_text)\n",
    "    df_replaced_trips['Replaced_mode'] = df_replaced_trips['Replaced_mode'].replace(mode,mode_text)\n",
    "\n",
    "df_replaced_trips['Mode_confirm'] = df_replaced_trips['Mode_confirm'].replace(7,'ebike')\n",
    "df_replaced_trips['Replaced_mode'] = df_replaced_trips['Replaced_mode'].replace(7,'ebike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurately stated replacement mode for all users\n",
    "plot_data = df_replaced_trips[df_replaced_trips['Mode_confirm']=='ebike']\n",
    "plot_data = plot_data.groupby(['date_time'], as_index=False)['replaced_in_stated'].agg(['sum','count']).apply(lambda x: x.rolling(14,1).mean())\n",
    "plot_data['proportion'] = plot_data['sum'] / plot_data['count']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.lineplot(ax=ax, data=plot_data, x='date_time', y='proportion').set(title='Proportion of Daily E-Bike Trips With Correctly Stated Replacement Mode', xlabel='Date', ylabel='Proportion Correct')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurately stated replacement mode for all users across modes\n",
    "plot_data = df_replaced_trips.groupby(['Mode_confirm'], as_index=False)['replaced_in_stated'].agg(['sum','count']).reset_index()\n",
    "plot_data['proportion'] = 1 - (plot_data['sum'] / plot_data['count'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Mode_confirm', y='proportion').set(title='Proportion of Infeasible Replacements by Primary Mode', xlabel='Primary Mode', ylabel='Proportion Incorrect')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurately stated replacement mode for all users across modes\n",
    "plot_data = df_replaced_trips.groupby(['Replaced_mode'], as_index=False)['replaced_in_stated'].agg(['sum','count']).reset_index()\n",
    "plot_data['proportion'] = 1 - (plot_data['sum'] / plot_data['count'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='Replaced_mode', y='proportion').set(title='Proportion of Infeasible Replacements by Replaced Mode', xlabel='Stated Mode Replaced', ylabel='Proportion Incorrect')\n",
    "plt.xticks(rotation=45)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurately stated replacement mode for all users\n",
    "df_replaced_trips.user_id = df_replaced_trips.user_id.astype(str)\n",
    "plot_data = df_replaced_trips.groupby(['user_id'], as_index=False)['replaced_in_stated'].agg(['sum','count']).reset_index()\n",
    "plot_data['proportion'] = plot_data['sum'] / plot_data['count']\n",
    "plot_data = plot_data.sort_values('proportion', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='user_id', y='proportion', color='darkblue').set(title='Proportion of Trips With Correctly Stated Replacement Mode', xlabel='User', ylabel='Proportion Correct')\n",
    "plt.xticks(rotation=90)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurately stated replacement mode for all users\n",
    "df_replaced_trips.user_id = df_replaced_trips.user_id.astype(str)\n",
    "plot_data = df_replaced_trips.groupby(['user_id'], as_index=False)['replaced_in_stated'].agg(['sum','count']).reset_index()\n",
    "plot_data['incorrect'] = plot_data['count'] - plot_data['sum']\n",
    "plot_data['user_id'] = plot_data['user_id'].astype(str).str[-4:]\n",
    "plot_data = plot_data.sort_values('incorrect', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "sns.barplot(ax=ax, data=plot_data, x='user_id', y='incorrect', color='darkblue').set(title='Trips With Unavailable Stated Replacement Mode', xlabel='User', ylabel='Count Incorrect')\n",
    "plt.xticks(rotation=90)\n",
    "plt.subplots_adjust(bottom=0.25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
