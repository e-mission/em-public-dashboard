{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e578da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/JGreenlee/e-mission-common.git\n",
    "# %pip install geopy tqdm\n",
    "\n",
    "# it wont work until you restart the kernel.\n",
    "# so if you run into error, you may have to restart the kernel and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd2637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scaffolding\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import asyncio\n",
    "import zipfile\n",
    "import tarfile\n",
    "import glob\n",
    "\n",
    "# from geopy.geocoders import Nominatim\n",
    "# from tqdm import tqdm\n",
    "\n",
    "import matplotlib.transforms as mtrans\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from plots import *\n",
    "\n",
    "\n",
    "import emcommon.diary.base_modes as emcb\n",
    "import emcommon.metrics.footprint.util as emcfu\n",
    "import emcommon.metrics.footprint.footprint_calculations as emcfc\n",
    "import emcommon.util as emcommonutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b476f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.set_loglevel (level = 'warning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c28fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all columns when viewing dataframes\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a5687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pur = pd.read_csv(r'auxiliary_files/purpose_labels.csv')\n",
    "df_re = pd.read_csv(r'auxiliary_files/mode_labels.csv')\n",
    "df_ei = pd.read_csv(r'auxiliary_files/energy_intensity.csv')\n",
    "\n",
    "#dictionaries:\n",
    "dic_pur = dict(zip(df_pur['purpose_confirm'],df_pur['bin_purpose'])) # bin purpose\n",
    "dic_re  = dict(zip(df_re['replaced_mode'],df_re['mode_clean'])) # bin modes\n",
    "dic_fuel = dict(zip(df_ei['mode'],df_ei['fuel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6de8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert a dictionary to a defaultdict\n",
    "dic_re = defaultdict(lambda: 'Other',dic_re)\n",
    "dic_pur = defaultdict(lambda: 'Other',dic_pur)\n",
    "dic_fuel = defaultdict(lambda: 'Other',dic_fuel)\n",
    "\n",
    "mode_of_interest = \"E-bike\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cbaaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here begins the naive calculation.\n",
    "# These functions are meant for naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a18e562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_traceback_handler(exception_type, exception, traceback):\n",
    "    print(\"%s: %s\" % (exception_type.__name__, exception), file=sys.stderr)\n",
    "\n",
    "\n",
    "\n",
    "# CASE 2 of https://github.com/e-mission/em-public-dashboard/issues/69#issuecomment-1256835867\n",
    "unique_users = lambda df: len(df.user_id.unique()) if \"user_id\" in df.columns else 0\n",
    "trip_label_count = lambda s, df: len(df[s].dropna()) if s in df.columns else 0\n",
    "\n",
    "\n",
    "def add_energy_labels(expanded_ct, df_ei, dic_fuel):\n",
    "    \"\"\" Inputs:\n",
    "    expanded_ct = dataframe of trips that has had Mode_confirm and Replaced_mode added\n",
    "    dic/df_* = label mappings for energy impact and fuel\n",
    "    \"\"\"\n",
    "    expanded_ct['Mode_confirm_fuel']= expanded_ct['Mode_confirm'].map(dic_fuel)\n",
    "    expanded_ct = energy_intensity(expanded_ct, df_ei, 'Mode_confirm')\n",
    "    expanded_ct = energy_footprint_kWH(expanded_ct, 'distance_miles', 'Mode_confirm')\n",
    "    expanded_ct = CO2_footprint_lb(expanded_ct, 'distance_miles', 'Mode_confirm')\n",
    "    return expanded_ct\n",
    "\n",
    "def add_energy_impact(expanded_ct, df_ei, dic_fuel):\n",
    "    # Let's first calculate everything for the mode confirm\n",
    "    # And then calculate everything for the replaced mode\n",
    "    expanded_ct = add_energy_labels(expanded_ct, df_ei, dic_fuel)\n",
    "    expanded_ct['Replaced_mode_fuel']= expanded_ct['Replaced_mode'].map(dic_fuel)\n",
    "    expanded_ct = energy_intensity(expanded_ct, df_ei, 'Replaced_mode')\n",
    "    # and then compute the impacts\n",
    "    expanded_ct = energy_impact_kWH(expanded_ct, 'distance_miles')\n",
    "    expanded_ct = CO2_impact_lb(expanded_ct, 'distance_miles')\n",
    "    return expanded_ct\n",
    "\n",
    "def get_quality_text(before_df, after_df, mode_of_interest=None, include_test_users=False):\n",
    "    \"\"\" Inputs:\n",
    "    before_df = dataframe prior to filtering (usually participant_ct_df)\n",
    "    after_df = dataframe after filtering (usually expanded_ct)\n",
    "    mode_of_interest = optional detail to include in the text string\n",
    "    \"\"\"\n",
    "    # CASE 1 of https://github.com/e-mission/em-public-dashboard/issues/69#issuecomment-1256835867\n",
    "    after_pct = (len(after_df) * 100) / len(before_df) if len(before_df) != 0 else np.nan\n",
    "    cq = (len(after_df), unique_users(after_df), len(before_df), unique_users(before_df),\n",
    "        after_pct, )\n",
    "    interest_str = mode_of_interest + ' ' if mode_of_interest is not None else ''\n",
    "    total_str = 'confirmed' if mode_of_interest is not None else ''\n",
    "    user_str = 'testers and participants' if include_test_users else 'users'\n",
    "    quality_text = f\"Based on %s confirmed {interest_str}trips from %d {user_str}\\nof %s total {total_str} trips from %d users (%.2f%%)\" % cq\n",
    "    print(quality_text)\n",
    "    return quality_text\n",
    "\n",
    "\n",
    "\n",
    "def data_quality_check(expanded_ct):\n",
    "    '''1. Delete rows where the mode_confirm was pilot_ebike and repalced_mode was pilot_ebike.\n",
    "       2. Delete rows where the mode_confirm was pilot_ebike and repalced_mode was same_mode.\n",
    "       3. Replace same_mode for the mode_confirm for Energy Impact Calcualtion.'''\n",
    "\n",
    "    # TODO: This is only really required for the initial data collection around the minipilot\n",
    "    # in subsequent deployes, we removed \"same mode\" and \"pilot_ebike\" from the options, so the\n",
    "    # dataset did not contain of these data quality issues\n",
    "\n",
    "    if 'replaced_mode' in expanded_ct.columns:\n",
    "        expanded_ct.drop(expanded_ct[(expanded_ct['mode_confirm'] == 'pilot_ebike') & (expanded_ct['replaced_mode'] == 'pilot_ebike')].index, inplace=True)\n",
    "        expanded_ct.drop(expanded_ct[(expanded_ct['mode_confirm'] == 'pilot_ebike') & (expanded_ct['replaced_mode'] == 'same_mode')].index, inplace=True)\n",
    "        expanded_ct['replaced_mode'] = np.where(expanded_ct['replaced_mode'] == 'same_mode',expanded_ct['mode_confirm'], expanded_ct['replaced_mode'])\n",
    "    \n",
    "    return expanded_ct\n",
    "\n",
    "def unit_conversions(df):\n",
    "    df['distance_miles']= df[\"distance\"]*0.00062 #meters to miles\n",
    "\n",
    "def energy_intensity(trip_df,mode_intensity_df,col):\n",
    "    \"\"\" Inputs:\n",
    "    trip_df = dataframe with data\n",
    "    mode_intensity_df = dataframe with energy/cost/time factors\n",
    "    col = the column for which we want to map the intensity\n",
    "    \"\"\"\n",
    "\n",
    "    mode_intensity_df = mode_intensity_df.copy()\n",
    "    mode_intensity_df[col] = mode_intensity_df['mode']\n",
    "    dic_ei_factor = dict(zip(mode_intensity_df[col],mode_intensity_df['energy_intensity_factor']))\n",
    "    dic_CO2_factor = dict(zip(mode_intensity_df[col],mode_intensity_df['CO2_factor']))\n",
    "    dic_ei_trip = dict(zip(mode_intensity_df[col],mode_intensity_df['(kWH)/trip']))\n",
    "\n",
    "    trip_df['ei_'+col] = trip_df[col].map(dic_ei_factor)\n",
    "    trip_df['CO2_'+col] = trip_df[col].map(dic_CO2_factor)\n",
    "    trip_df['ei_trip_'+col] = trip_df[col].map(dic_ei_trip)\n",
    "    return trip_df\n",
    "\n",
    "def energy_footprint_kWH(df,distance_miles,col):\n",
    "    \"\"\" Inputs:\n",
    "    df = dataframe with data\n",
    "    distance = distance in miles\n",
    "    col = Replaced_mode or Mode_confirm\n",
    "    \"\"\"\n",
    "    conditions_col = [(df[col+'_fuel'] =='gasoline'),\n",
    "                       (df[col+'_fuel'] == 'diesel'),\n",
    "                       (df[col+'_fuel'] == 'electric')]\n",
    "    gasoline_col = (df[distance_miles]*df['ei_'+col]*0.000293071) # 1 BTU = 0.000293071 kWH\n",
    "    diesel_col   = (df[distance_miles]*df['ei_'+col]*0.000293071)\n",
    "    electric_col = (df[distance_miles]*df['ei_'+col])+ df['ei_trip_'+col]\n",
    "    values_col = [gasoline_col,diesel_col,electric_col]\n",
    "    df[col+'_EI(kWH)'] = np.select(conditions_col, values_col)\n",
    "    return df\n",
    "\n",
    "def energy_impact_kWH(df,distance_miles):\n",
    "    if 'Mode_confirm_EI(kWH)' not in df.columns:\n",
    "        print(\"Mode confirm footprint not found, computing before impact\")\n",
    "        df = energy_footprint_kWH(df, distance_miles, \"Mode_confirm\")\n",
    "    df = energy_footprint_kWH(df, distance_miles, \"Replaced_mode\")\n",
    "    df['Energy_Impact(kWH)']  = round((df['Replaced_mode_EI(kWH)'] - df['Mode_confirm_EI(kWH)']),3)\n",
    "    return df\n",
    "\n",
    "def CO2_footprint_lb(df, distance_miles, col):\n",
    "    \"\"\" Inputs:\n",
    "    df = dataframe with data\n",
    "    distance = distance in miles\n",
    "    col = Replaced_mode or Mode_confirm\n",
    "    \"\"\"\n",
    "    conditions_col = [(df[col+'_fuel'] =='gasoline'),\n",
    "                       (df[col+'_fuel'] == 'diesel'),\n",
    "                       (df[col+'_fuel'] == 'electric')]\n",
    "   \n",
    "    gasoline_col = (df[distance_miles]*df['ei_'+col]*0.000001)* df['CO2_'+col]\n",
    "    diesel_col   = (df[distance_miles]*df['ei_'+col]*0.000001)* df['CO2_'+col]\n",
    "    electric_col = (((df[distance_miles]*df['ei_'+col])+df['ei_trip_'+col])*0.001)*df['CO2_'+col]\n",
    "\n",
    "    values_col = [gasoline_col,diesel_col,electric_col]\n",
    "    df[col+'_lb_CO2'] = np.select(conditions_col, values_col)\n",
    "    return df\n",
    "    \n",
    "def CO2_impact_lb(df,distance_miles):\n",
    "    if 'Mode_confirm_lb_CO2' not in df.columns:\n",
    "        print(\"Mode confirm footprint not found, computing before impact\")\n",
    "        df = CO2_footprint_lb(df, distance_miles, \"Mode_confirm\")\n",
    "    df = CO2_footprint_lb(df, distance_miles, \"Replaced_mode\")\n",
    "    df['CO2_Impact(lb)']  = round((df['Replaced_mode_lb_CO2'] - df['Mode_confirm_lb_CO2']),3)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9079775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path configuration\n",
    "to_data_folder = \"PaperVizualizations/Data/abby_ceo/sc\" #data folder, where composite data was written from the TSDC_data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73190bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e99ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('viz_scripts/abby_ceo/sc/analysis_confirmed_trip.csv')\n",
    "# we are using smart commute data. zip with this csv taken from onedrive.\n",
    "df = pd.read_csv(to_data_folder + \"/analysis_confirmed_trip.csv\")\n",
    "# expanded_ct_2=pd.read_csv(to_data_folder + \"/tsdc_filtered_merged_trips.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78adcf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326a8740",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pprint(dic_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb74d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def calculate_naive_and_cheer(passed_df: pd.DataFrame):\n",
    "    # rename columns for easier access\n",
    "    passed_df.rename(columns={\n",
    "        'user_id_socio': 'user_id',\n",
    "        'please_identify_which_category_represents_your_total_household_': 'HHINC',\n",
    "        'how_many_motor_vehicles_are_owned_leased_or_available_for_regul': 'VEH',\n",
    "        ' how_many_motor_vehicles_are_owned_leased_or_available_for_regul': 'VEH',\n",
    "        'how_many_motor_vehicles_are_owned_leased_or_available_for_regul ': 'VEH',\n",
    "        'in_which_year_were_you_born?': 'AGE',\n",
    "        'including_yourself_how_many_people_live_in_your_home?': 'HHSIZE',\n",
    "        'how_many_children_under_age_18_live_in_your_home?': 'CHILDREN',\n",
    "        'what_is_your_gender?': 'GENDER',\n",
    "        'if_you_were_unable_to_use_your_household_vehicles_which_of_the_': 'available_modes',\n",
    "        'are_you_a_student?': 'STUDENT',\n",
    "        'data_duration': 'duration',\n",
    "        'data_distance': 'distance'\n",
    "    }, inplace=True, errors='ignore')\n",
    "    \n",
    "    df_mapped = passed_df.copy()\n",
    "\n",
    "    # map modes, replaced modes, and trip purposes\n",
    "    df_mapped['Mode_confirm'] = df_mapped['data_user_input_mode_confirm'].map(dic_re)\n",
    "    df_mapped['Replaced_mode'] = df_mapped['data_user_input_replaced_mode'].map(dic_re)\n",
    "    df_mapped['Trip_purpose'] = df_mapped['data_user_input_purpose_confirm'].map(dic_pur)\n",
    "    \n",
    "    # date and duration transformations\n",
    "    df_mapped.rename(columns={'data_start_local_dt_year': 'year', 'data_start_local_dt_month': 'month', 'data_start_local_dt_day': 'day'}, inplace=True)\n",
    "    df_mapped['date_time'] = pd.to_datetime(df_mapped[['year', 'month', 'day']])\n",
    "    df_mapped['duration'] = df_mapped['duration'] / 60  # Convert to minutes\n",
    "    df_mapped['distance_miles'] = df_mapped['distance'] * 0.0006213712  # Convert to miles\n",
    "    df_mapped['distance_km'] = df_mapped['distance'] * 0.001  # Convert to kilometers\n",
    "\n",
    "    # add energy impact\n",
    "    expanded_ct = add_energy_impact(df_mapped, df_ei, dic_fuel) if len(df_mapped) > 0 else df_mapped\n",
    "\n",
    "    # prepare quality text and summary stats\n",
    "    data_eb = expanded_ct.query(f\"Mode_confirm == '{mode_of_interest}'\") if \"Mode_confirm\" in expanded_ct.columns else expanded_ct\n",
    "    quality_text = get_quality_text(expanded_ct, data_eb, mode_of_interest)\n",
    "    ebei = data_eb.groupby('Replaced_mode').agg({'Energy_Impact(kWH)': ['sum', 'mean']})\n",
    "    ebei.columns = ['Sketch of Total Energy_Impact(kWH)', 'Sketch of Average Energy_Impact(kWH)']\n",
    "    ebei = ebei.reset_index().sort_values(by='Sketch of Total Energy_Impact(kWH)', ascending=False)\n",
    "    net_energy_saved = round(sum(ebei['Sketch of Total Energy_Impact(kWH)']), 2)\n",
    "\n",
    "    # modify default_json to include pilot_ebike\n",
    "    default_json = await emcfu.read_json_resource('label-options.default.json')\n",
    "    default_json['MODE'].append({\"value\": \"pilot_ebike\", \"base_mode\": \"E_BIKE\"})\n",
    "\n",
    "    # drop rows without a mode or marked as \"Not a Trip\"\n",
    "    expanded_ct = expanded_ct.dropna(subset=['data_user_input_mode_confirm'])\n",
    "    expanded_ct = expanded_ct[expanded_ct['Mode_confirm'] != 'Not a Trip']\n",
    "\n",
    "    # commute data calculation helper function\n",
    "    async def get_commute_data(row, labels):\n",
    "        trip_object = {\n",
    "            \"_id\": row['_id'],\n",
    "            \"distance\": row['distance'],\n",
    "            \"start_fmt_time\": row['data_start_fmt_time'],\n",
    "            \"start_loc\": {\"coordinates\": [row['data_start_loc_longitude'], row['data_start_loc_latitude']]},\n",
    "            \"user_input\": {\n",
    "                \"mode_confirm\": row['data_user_input_mode_confirm'],\n",
    "                \"replaced_mode_confirm\": row['data_user_input_replaced_mode']\n",
    "            }\n",
    "        }\n",
    "        footprint = await emcfc.calc_footprint_for_trip(trip_object, labels)\n",
    "        replaced_footprint = await emcfc.calc_footprint_for_trip(trip_object, labels, 'replaced_mode') if not pd.isna(row['data_user_input_replaced_mode']) else {}\n",
    "\n",
    "        return {'footprint': footprint, 'replaced_footprint': replaced_footprint}\n",
    "\n",
    "    async def get_commute_data_task(row, index, expanded_ct, labels):\n",
    "        commute_data = await get_commute_data(row, labels)\n",
    "\n",
    "        # update expanded_ct with commute data\n",
    "        if 'kg_co2' in commute_data['footprint'][0] and 'kwh' in commute_data['footprint'][0]:\n",
    "            expanded_ct.at[index, 'cheer_kg_co2'] = commute_data['footprint'][0]['kg_co2']\n",
    "            expanded_ct.at[index, 'cheer_kwh'] = commute_data['footprint'][0]['kwh']\n",
    "            if len(commute_data['replaced_footprint']) > 0:\n",
    "                expanded_ct.at[index, 'cheer_replaced_kg_co2'] = commute_data['replaced_footprint'][0]['kg_co2']\n",
    "                expanded_ct.at[index, 'cheer_replaced_kwh'] = commute_data['replaced_footprint'][0]['kwh']\n",
    "                for uncertain_column in ['kg_co2_uncertain', 'kwh_uncertain']:\n",
    "                    if uncertain_column in commute_data['replaced_footprint'][0]:\n",
    "                        expanded_ct.at[index, f'cheer_replaced_{uncertain_column}'] = commute_data['replaced_footprint'][0][uncertain_column]\n",
    "\n",
    "#         print(commute_data)\n",
    "        # conditional assignment of UACE\n",
    "        if row['data_user_input_mode_confirm'] == 'bus':\n",
    "            if 'ntd_uace_code' in commute_data['footprint'][1]:\n",
    "                expanded_ct.at[index, 'UACE'] = commute_data['footprint'][1]['ntd_uace_code']\n",
    "            else:\n",
    "                expanded_ct.at[index, 'UACE'] = float('nan')  # Set to NaN if UACE is not provided\n",
    "        else:\n",
    "            expanded_ct.at[index, 'UACE'] = float('nan')  # Set to NaN if mode is not 'bus'\n",
    "                        \n",
    "        expanded_ct.at[index, 'Mode_confirm_kg_CO2'] = row['Mode_confirm_lb_CO2'] * 0.453592\n",
    "\n",
    "    async def run_tasks_concurrently():\n",
    "        # this is meant to speed up the async calls of cheer\n",
    "        concurrency_limit = 200\n",
    "        semaphore = asyncio.Semaphore(concurrency_limit)\n",
    "\n",
    "        async def sem_task(row, index, expanded_ct, labels):\n",
    "            async with semaphore:\n",
    "                await get_commute_data_task(row, index, expanded_ct, labels)\n",
    "\n",
    "        tasks = [\n",
    "            sem_task(row, index, expanded_ct, default_json)\n",
    "            for index, row in expanded_ct.iterrows()\n",
    "        ]\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "    await run_tasks_concurrently()\n",
    "    return expanded_ct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5d493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the necessary directories exist\n",
    "os.makedirs('figures/pertrip', exist_ok=True)\n",
    "os.makedirs('figures/perkm', exist_ok=True)\n",
    "os.makedirs('figures/cumulative', exist_ok=True)\n",
    "os.makedirs('figures/naivenaive', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d5c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(passed_expanded_ct: pd.DataFrame, name_of_dataset: str):\n",
    "    bar_width = 0.4\n",
    "        \n",
    "    print(name_of_dataset)\n",
    "    print(list(passed_expanded_ct.columns))\n",
    "    \n",
    "\n",
    "    # filter out 'Air' and 'Other' from Mode_confirm\n",
    "    expanded_ct_filtered = passed_expanded_ct[~passed_expanded_ct['Mode_confirm'].isin(['Air', 'Other'])]\n",
    "\n",
    "    # calculate per-trip average emissions for the all-years combined plot\n",
    "    grouped_data_filtered = expanded_ct_filtered.groupby('Mode_confirm')[['Mode_confirm_kg_CO2', 'cheer_kg_co2']].mean()\n",
    "\n",
    "    # function to create and save a comparison plot for all years combined (per trip)\n",
    "    def calculation_comparison_all_years(scale: str):\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "        x = np.arange(len(grouped_data_filtered.index))  # x locations for the groups\n",
    "\n",
    "        ax.bar(x - bar_width / 2, grouped_data_filtered['Mode_confirm_kg_CO2'], width=bar_width, color='lightblue', label='(Dashboard, 2020)')\n",
    "        ax.bar(x + bar_width / 2, grouped_data_filtered['cheer_kg_co2'], width=bar_width, color='orange', label='CHEER')\n",
    "\n",
    "        # title and labels\n",
    "#         plt.title(f'Average CO2 Emissions per Trip for Each Mode of Transportation\\n{name_of_dataset} Dataset ({scale.capitalize()} Scale)')\n",
    "        plt.ylabel('Average CO2 Emissions per Trip (kg)')\n",
    "        plt.xlabel('Mode of Transportation')\n",
    "\n",
    "        # apply scale settings\n",
    "        if scale == 'log':\n",
    "            ax.set_yscale('log')\n",
    "#             ax.set_ylim(0.01, 16)\n",
    "            ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:g}'))\n",
    "#         else:\n",
    "#             ax.set_ylim(0, 16)\n",
    "\n",
    "        # shift x-tick labels slightly\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(grouped_data_filtered.index, rotation=45, ha='right')\n",
    "        trans = mtrans.Affine2D().translate(10, 0)\n",
    "        for t in ax.get_xticklabels():\n",
    "            t.set_transform(t.get_transform() + trans)\n",
    "\n",
    "        # set legend and show\n",
    "        plt.legend(loc='upper center')\n",
    "        plt.tight_layout()\n",
    "\n",
    "\n",
    "        # save as PDF and PNG in the pertrip directory\n",
    "        plt.savefig(f'figures/pertrip/{name_of_dataset.lower().replace(\" \", \"_\")}_{scale}_per_trip.pdf')\n",
    "        plt.savefig(f'figures/pertrip/{name_of_dataset.lower().replace(\" \", \"_\")}_{scale}_per_trip.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    # Function to create cumulative emissions plot\n",
    "    def cumulative_emissions_plot(y_naive: str, y_cheer: str, y_label: str, file_suffix: str):\n",
    "        \"\"\"\n",
    "        Plots cumulative emissions using specified columns for Naive and CHEER calculations.\n",
    "        :param y_naive: Column name for Naive emissions.\n",
    "        :param y_cheer: Column name for CHEER emissions.\n",
    "        :param y_label: Y-axis label for the plot.\n",
    "        :param file_suffix: Suffix for file names.\n",
    "        \"\"\"\n",
    "        # calculate cumulative emissions for each mode\n",
    "        cumulative_emissions = expanded_ct_filtered.groupby('Mode_confirm')[[y_naive, y_cheer]].sum()\n",
    "\n",
    "        # filter out modes with zero total emissions for both calculations\n",
    "        cumulative_emissions = cumulative_emissions[(cumulative_emissions[y_naive] > 0) | (cumulative_emissions[y_cheer] > 0)]\n",
    "\n",
    "        # plot cumulative emissions\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "        x = np.arange(len(cumulative_emissions.index))\n",
    "\n",
    "        # naive emissions\n",
    "        ax.bar(\n",
    "            x - bar_width / 2,\n",
    "            cumulative_emissions[y_naive],\n",
    "            width=bar_width,\n",
    "            color='green',\n",
    "            label='(Dashboard, 2020)',\n",
    "            edgecolor='black'\n",
    "        )\n",
    "\n",
    "        # CHEER emissions\n",
    "        ax.bar(\n",
    "            x + bar_width / 2,\n",
    "            cumulative_emissions[y_cheer],\n",
    "            width=bar_width,\n",
    "            color='purple',\n",
    "            label='CHEER',\n",
    "            edgecolor='black'\n",
    "        )\n",
    "\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_xlabel('Mode of Transportation')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(cumulative_emissions.index, rotation=45, ha='right')\n",
    "        \n",
    "        \n",
    "        plt.legend(loc='upper left')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'figures/cumulative/{name_of_dataset.lower().replace(\" \", \"_\")}_{file_suffix}_cumulative_emissions.png')\n",
    "        plt.savefig(f'figures/cumulative/{name_of_dataset.lower().replace(\" \", \"_\")}_{file_suffix}_cumulative_emissions.pdf')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    # function for yearly comparison with average per km\n",
    "    def calculation_comparison_for_each_year():\n",
    "        years = expanded_ct_filtered['year'].unique()\n",
    "        num_years = len(years)\n",
    "        fig, axes = plt.subplots(1, num_years, figsize=(6 * num_years, 5), sharey=True)\n",
    "\n",
    "        # ensure axes is iterable\n",
    "        if num_years == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for i, year in enumerate(sorted(years)):\n",
    "            year_data = expanded_ct_filtered[expanded_ct_filtered['year'] == year]\n",
    "\n",
    "            # calculate per-km average emissions\n",
    "            year_data['CO2_per_km'] = year_data['Mode_confirm_kg_CO2'] / year_data['distance_km']\n",
    "            year_data['cheer_CO2_per_km'] = year_data['cheer_kg_co2'] / year_data['distance_km']\n",
    "            grouped_year_data = year_data.groupby('Mode_confirm')[['CO2_per_km', 'cheer_CO2_per_km']].mean()\n",
    "\n",
    "            x = np.arange(len(grouped_year_data.index))\n",
    "\n",
    "            axes[i].bar(x - bar_width / 2, grouped_year_data['CO2_per_km'], width=bar_width, color='lightblue', label='(Dashboard, 2020)')\n",
    "            axes[i].bar(x + bar_width / 2, grouped_year_data['cheer_CO2_per_km'], width=bar_width, color='orange', label='CHEER')\n",
    "\n",
    "            # titles and labels for each subplot\n",
    "            axes[i].set_title(f'Year {int(year)}\\n{name_of_dataset} Dataset')\n",
    "            axes[i].set_ylabel('Average CO2 Emissions per km (kg)' if i == 0 else \"\")\n",
    "            axes[i].set_xlabel('Mode of Transportation')\n",
    "            axes[i].set_ylim(0, 0.65)\n",
    "            axes[i].legend(loc='upper right')\n",
    "\n",
    "            # shift x-tick labels\n",
    "            axes[i].set_xticks(x)\n",
    "            axes[i].set_xticklabels(grouped_year_data.index, rotation=45, ha='right')\n",
    "            trans = mtrans.Affine2D().translate(10, 0)\n",
    "            for t in axes[i].get_xticklabels():\n",
    "                t.set_transform(t.get_transform() + trans)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'figures/perkm/{name_of_dataset.lower().replace(\" \", \"_\")}_yearly_comparison_per_km.pdf')\n",
    "        plt.savefig(f'figures/perkm/{name_of_dataset.lower().replace(\" \", \"_\")}_yearly_comparison_per_km.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def generate_latex_table():\n",
    "        years = sorted(expanded_ct_filtered['year'].unique())\n",
    "\n",
    "        # dataframe for average CHEER CO2 emissions per km with modes as rows and years as columns\n",
    "        modes = expanded_ct_filtered['Mode_confirm'].unique()\n",
    "        average_co2_df = pd.DataFrame(index=modes, columns=years)\n",
    "\n",
    "        # calculate average CO2 per km for CHEER only, for each mode and year\n",
    "        for year in years:\n",
    "            year_data = expanded_ct_filtered[expanded_ct_filtered['year'] == year]\n",
    "\n",
    "            # calculate `cheer_kg_co2` per km\n",
    "            year_data['cheer_CO2_per_km'] = year_data['cheer_kg_co2'] / year_data['distance_km']\n",
    "            avg_cheer_co2_per_km = year_data.groupby('Mode_confirm')['cheer_CO2_per_km'].mean()\n",
    "\n",
    "            # assign the calculated averages to the DataFrame for each year\n",
    "            average_co2_df[year] = avg_cheer_co2_per_km\n",
    "\n",
    "        # calculate percentage change between the first and last year and add as a new column\n",
    "        if len(years) > 1:\n",
    "            percentage_change = ((average_co2_df[years[-1]] - average_co2_df[years[0]]) / average_co2_df[years[0]]) * 100\n",
    "            average_co2_df['% Change'] = percentage_change\n",
    "\n",
    "        # drop rows where all values in the relevant columns (years and % Change) are zero or NaN\n",
    "        #  explicitly drop specific modes like \"Walk\", \"Regular Bike\", and \"Bikeshare\"\n",
    "        rows_to_drop = [\"Walk\", \"Regular Bike\", \"Bikeshare\"]\n",
    "        average_co2_df = average_co2_df.drop(rows_to_drop, errors='ignore')  # Ignore errors if the row isn't there\n",
    "        average_co2_df = average_co2_df[(average_co2_df != 0).any(axis=1)]  # Drop rows with all zeros or NaN\n",
    "\n",
    "        # sort the DataFrame by index (modes) alphabetically\n",
    "        average_co2_df = average_co2_df.sort_index()\n",
    "\n",
    "        \n",
    "        #  full table environment for paper\n",
    "        latex_code = r\"\\begin{table}[h!]\" + \"\\n\" \\\n",
    "                     r\"\\centering\" + \"\\n\" \\\n",
    "                     r\"\\caption{Average CHEER CO2 Emissions per km by Mode and Year for CanBikeCO.}\" + \"\\n\" \\\n",
    "                     r\"\\label{tab:avg_canbikeco_cheer}\" + \"\\n\" \\\n",
    "                     + average_co2_df.to_latex(index=True, header=True, na_rep=\"--\", float_format=\"%.4f\", column_format=\"l\" + \"r\" * (len(years) + 1)) + \"\\n\" \\\n",
    "                     + r\"\\end{table}\"\n",
    "\n",
    "        print(latex_code)\n",
    "\n",
    "\n",
    "    def calculate_percentage_difference_table():\n",
    "        # calculate cumulative CO2 emissions for each mode\n",
    "        cumulative_emissions = expanded_ct_filtered.groupby('Mode_confirm')[['Mode_confirm_kg_CO2', 'cheer_kg_co2']].sum()\n",
    "\n",
    "        # calculate percentage difference between naive and CHEER\n",
    "        cumulative_emissions['percentage_diff'] = ((cumulative_emissions['cheer_kg_co2'] - cumulative_emissions['Mode_confirm_kg_CO2']) / cumulative_emissions['Mode_confirm_kg_CO2']) * 100\n",
    "\n",
    "        # reset index and filter out rows where Mode_confirm is \"Walk\", \"Regular Bike\", \"Bikeshare\", or \"Skateboard\"\n",
    "        cumulative_emissions.reset_index(inplace=True)\n",
    "        cumulative_emissions = cumulative_emissions[~cumulative_emissions['Mode_confirm'].isin(['Walk', 'Regular Bike', 'Bikeshare', 'Skate board'])]\n",
    "\n",
    "        # create a dictionary from the filtered df\n",
    "        percentage_diff_dict = cumulative_emissions.set_index('Mode_confirm')['percentage_diff'].to_dict()\n",
    "\n",
    "        # return the dictionary in a format suitable for the main dictionary structure\n",
    "        return {name_of_dataset: percentage_diff_dict}\n",
    "\n",
    "\n",
    "\n",
    "    # create per-trip average plot for all years\n",
    "    calculation_comparison_all_years(scale='normal')\n",
    "    calculation_comparison_all_years(scale='log')\n",
    "\n",
    "    # call the function for both kg and kWh plots\n",
    "    cumulative_emissions_plot(\n",
    "        y_naive='Mode_confirm_kg_CO2',\n",
    "        y_cheer='cheer_kg_co2',\n",
    "        y_label='Cumulative CO2 Emissions (kg)',\n",
    "        file_suffix='kg'\n",
    "    )\n",
    "\n",
    "    cumulative_emissions_plot(\n",
    "        y_naive='Mode_confirm_EI(kWH)',\n",
    "        y_cheer='cheer_kwh',\n",
    "        y_label='Cumulative Energy Impact (kWh)',\n",
    "        file_suffix='kwh'\n",
    "    )\n",
    "\n",
    "    # create per-km average plot for each year\n",
    "    calculation_comparison_for_each_year()\n",
    "\n",
    "    # generate table for percentage change in CO2\n",
    "    generate_latex_table()\n",
    "    \n",
    "    # generate  table for percentage difference in cumulative emissions between Naive and CHEER\n",
    "    print('lastly, naive and cheer percentage')\n",
    "\n",
    "    \n",
    "    return calculate_percentage_difference_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb6d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('figures', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd9855",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the purpose for this function is because calling cheer functions\n",
    "# takes a long time\n",
    "# this could even be made faster if we used shapefiles instead\n",
    "# of http calls in CHEER. but we would have to made code changes to e mission common for that.\n",
    "async def load_or_fetch_data(dataset_name: str, original_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads a dataset from a CSV file if it exists, otherwise fetches it asynchronously, \n",
    "    processes it, and saves it with an updated filename.\n",
    "    \n",
    "    Parameters:\n",
    "        dataset_name (str): The base name of the dataset (used in the filename).\n",
    "        original_df (pd.DataFrame): The original DataFrame to process if the CSV does not exist.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The loaded or newly processed dataset.\n",
    "    \"\"\"\n",
    "    filename = f\"{dataset_name}-with-emissions.csv\"\n",
    "    \n",
    "    if not os.path.exists(filename):\n",
    "        # fetch data asynchronously and process it\n",
    "        data = await calculate_naive_and_cheer(original_df)\n",
    "        \n",
    "        # save to CSV file\n",
    "        data.to_csv(filename, index=False)\n",
    "    else:\n",
    "        # load data from CSV file\n",
    "        data = pd.read_csv(filename)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "smartcommute = await load_or_fetch_data(\"smart_commute\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d532bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_difference = plotter(smartcommute, \"Smart Commute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633c90a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sc_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1918f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup dictionary for city/program names and folder codes\n",
    "lookupdictionary = {\n",
    "    \"sc\": \"sc_21\",\n",
    "    \"boulder\": \"cc_21\",\n",
    "    \"fortcollins\": \"fc_21\",\n",
    "    \"pueblo\": \"pc_21\",\n",
    "    \"durango\": \"4c_21\",\n",
    "    \"vail\": \"vail_22\",\n",
    "}\n",
    "\n",
    "# list to store datasets\n",
    "datasets = []\n",
    "\n",
    "for biggername, program_code in lookupdictionary.items():\n",
    "    print(f'\\nStarting with {biggername} ({program_code})')\n",
    "    \n",
    "    \n",
    "    # this is custom made for the data that was given to us by tsdc.\n",
    "    trip_file = f\"CanBikeCO_2/ceo_{program_code}/analysis_confirmed_trip.csv\"\n",
    "\n",
    "    \n",
    "    trips = pd.read_csv(trip_file, engine=\"python\", on_bad_lines='skip')\n",
    "    trips.reset_index() # this is really important for canbikeco or else data got mixed togehter\n",
    "    print(len(trips), 'trips')\n",
    "    print(trips.perno.nunique(), 'people')\n",
    "    \n",
    "\n",
    "    # add program code to the dataset\n",
    "    trips['program'] = program_code.upper()\n",
    "    \n",
    "    # append merged data to datasets list\n",
    "    datasets.append(trips)\n",
    "\n",
    "# concatenate all datasets into single df\n",
    "full_data = pd.concat(datasets, ignore_index=True)\n",
    "print(len(full_data), 'trips')\n",
    "print(full_data.perno.nunique(), 'unique users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929e86f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# TEMPORARY. REMOVE\n",
    "#\n",
    "# full_data = full_data[full_data['data_user_input_mode_confirm'] == 'walk'].head(55)\n",
    "# full_data = full_data.head(20000)\n",
    "# full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2174cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_data['data_user_input_mode_confirm'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b99cc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "canbikeco = await load_or_fetch_data(\"canbikeco\",\n",
    "                                     full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd22022",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(canbikeco['data_start_loc_longitude'].unique()))\n",
    "canbikeco[canbikeco['data_user_input_mode_confirm'] == 'bus'].head(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3328b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "buses = canbikeco[canbikeco['data_user_input_mode_confirm'] == 'bus']\n",
    "\n",
    "# calculate the frequency and percentage of each unique value in the UACE column, including NaN\n",
    "uace_counts = buses['UACE'].value_counts(dropna=False)\n",
    "uace_percentages = (uace_counts / len(buses)) * 100  # Use the correct length of 'buses' for percentage calculation\n",
    "\n",
    "# combine the counts and percentages into one df\n",
    "uace_summary = pd.DataFrame({\n",
    "    'Count': uace_counts,\n",
    "    'Percentage': uace_percentages\n",
    "})\n",
    "\n",
    "\n",
    "print(uace_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c4abdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the year and calculate the census year\n",
    "year = 2020\n",
    "census_year = year - (year % 10)  # round down to nearest decade\n",
    "\n",
    "# filter rows where UACE is NaN\n",
    "buses_with_nan_uace = buses[buses['UACE'].isna()]\n",
    "\n",
    "# iterate through the rows and print the formatted URL\n",
    "for index, row in buses_with_nan_uace.iterrows():\n",
    "    coords = [row['data_start_loc_longitude'], row['data_start_loc_latitude']]\n",
    "    url = \"https://geocoding.geo.census.gov/geocoder/geographies/coordinates?\" + \\\n",
    "        f\"x={coords[0]}&y={coords[1]}\" + \\\n",
    "        f\"&benchmark=Public_AR_Current&vintage=Census{census_year}_Current&layers=87&format=json\"\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d4ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average 'Mode_confirm_kg_CO2' where 'UACE' equals 23527, which is denver area code\n",
    "average_mode_confirm_kg_co2_uace_23527 = buses[buses['UACE'] == 23527]['Mode_confirm_kg_CO2'].mean()\n",
    "average_all_naive = buses['Mode_confirm_kg_CO2'].mean()\n",
    "\n",
    "print(\"Average Mode_confirm_kg_CO2 for UACE 23527:\", average_mode_confirm_kg_co2_uace_23527)\n",
    "print(average_all_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a99728",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import requests\n",
    "\n",
    "# def get_state(lat, lon):\n",
    "#     try:\n",
    "#         url = f\"https://nominatim.openstreetmap.org/reverse?lat={lat}&lon={lon}&format=json&addressdetails=1\"\n",
    "#         response = requests.get(url, verify=False)  # Disable SSL verification\n",
    "#         data = response.json()\n",
    "#         if \"address\" in data and \"state\" in data[\"address\"]:\n",
    "#             print(data[\"address\"][\"state\"])\n",
    "#             return data[\"address\"][\"state\"]\n",
    "#         return \"Unknown\"\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error for coordinates ({lat}, {lon}): {e}\")\n",
    "#         return \"Unknown\"\n",
    "\n",
    "# # Apply to the dataframe\n",
    "# buses['State'] = buses.progress_apply(\n",
    "#     lambda row: get_state(row['data_start_loc_latitude'], row['data_start_loc_longitude']), axis=1\n",
    "# )\n",
    "\n",
    "# # Count occurrences of each state\n",
    "# state_counts = buses['State'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c61f254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a bar chart\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# state_counts.plot(kind='bar', color='skyblue')\n",
    "# plt.title('Number of Trips by State')\n",
    "# plt.xlabel('State')\n",
    "# plt.ylabel('Number of Trips')\n",
    "# plt.yscale('log')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7512c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate  mean of cheer_kg_co2\n",
    "mean_cheer_kg_co2 = buses['cheer_kg_co2'].mean()\n",
    "\n",
    "# replace NaN in UACE with a string label \"Unknown\" for plotting\n",
    "buses['UACE_filled'] = buses['UACE'].fillna('Unknown')\n",
    "\n",
    "# convert UACE_filled to a numerical category for plotting\n",
    "buses['UACE_numeric'] = buses['UACE_filled'].astype('category').cat.codes\n",
    "\n",
    "# scatter plot of UACE vs cheer_kg_co2\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(buses['UACE_numeric'], buses['cheer_kg_co2'], alpha=0.5)\n",
    "\n",
    "# horizontal line for the mean cheer_kg_co2\n",
    "plt.axhline(mean_cheer_kg_co2, color='red', linestyle='--', linewidth=1, label=f'Mean cheer_kg_co2 = {mean_cheer_kg_co2:.2f}')\n",
    "\n",
    "plt.title('Scatter Plot of UACE vs cheer_kg_co2')\n",
    "plt.xlabel('UACE (as Numeric)')\n",
    "plt.ylabel('cheer_kg_co2')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "uace_unique = buses['UACE_filled'].unique()\n",
    "plt.xticks(\n",
    "    ticks=range(len(uace_unique)), \n",
    "    labels=uace_unique,\n",
    "    rotation=45\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b024fc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "\n",
    "# function to format the y-axis with commas\n",
    "def format_y_axis(value, _):\n",
    "    return f\"{int(value):,}\"\n",
    "\n",
    "# histogram of cheer_kg_co2\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(buses['cheer_kg_co2'], bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "\n",
    "plt.title('Histogram of CHEER in bus trips for CanBikeCO')\n",
    "plt.xlabel('cheer_kg_co2')\n",
    "plt.ylabel('Frequency')\n",
    "plt.yscale('log')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# commas needed for readability\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(format_y_axis))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(buses['Mode_confirm_kg_CO2'], bins=30, alpha=0.7, color='green', edgecolor='black')\n",
    "\n",
    "plt.title('Histogram of Dashboard 2020 in bus trips for CanBikeCO')\n",
    "plt.xlabel('Mode_confirm_kg_CO2')\n",
    "plt.ylabel('Frequency')\n",
    "plt.yscale('log')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(format_y_axis))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbffe573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which UACE correspond to higher CO2 emissions?\n",
    "# make a scatterplot to find out.\n",
    "\n",
    "# consider distance\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(\n",
    "    buses['UACE_numeric'], \n",
    "    buses['cheer_kg_co2'], \n",
    "    c=buses['distance'],  # Color represents data_distance\n",
    "    cmap='cool',            # Choose a colormap\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# color represents data_distance\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('distance')\n",
    "\n",
    "uace_unique = buses['UACE_filled'].unique()\n",
    "plt.xticks(\n",
    "    ticks=range(len(uace_unique)),\n",
    "    labels=uace_unique,\n",
    "    rotation=45\n",
    ")\n",
    "\n",
    "plt.title('UACE vs cheer_kg_co2 with data_distance as Color')\n",
    "plt.xlabel('UACE')\n",
    "plt.ylabel('cheer_kg_co2')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb032839",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bus_data = canbikeco[canbikeco['Mode_confirm'] == 'Bus']\n",
    "average_cheer_kg_co2_bus = bus_data['cheer_kg_co2'].mean()\n",
    "avg_naive = bus_data['Mode_confirm_kg_CO2'].mean()\n",
    "avg_distance = bus_data['distance'].mean()\n",
    "\n",
    "# print(list(canbikeco.columns))\n",
    "testerrr = canbikeco[canbikeco['data_user_input_mode_confirm'] == 'bus']\n",
    "print(testerrr['cheer_kg_co2'].mean())\n",
    "print('?')\n",
    "\n",
    "print(f\"The average CHEER COâ‚‚ emissions for 'Bus' is: {average_cheer_kg_co2_bus} kg\")\n",
    "print(f\"Naive avg co2 emissions for bus\", avg_naive)\n",
    "print('distance', avg_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d9074c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8825f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug cheer\n",
    "# for some reason, walk was showing as having emissions. this was because we werent resetting index\n",
    "# this is fixed now but this stays just for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d72131",
   "metadata": {},
   "outputs": [],
   "source": [
    "whatsthis = canbikeco[(canbikeco['Mode_confirm'] == 'Walk') & (canbikeco['cheer_kg_co2'] > 0)]\n",
    "# drop specified columns from the DataFrame before selecting the first row\n",
    "whatsthis.head(1)\n",
    "# whatsthis_filtered = whatsthis.drop(columns=['cheer_kg_co2', 'cheer_kwh', 'cheer_replaced_kg_co2', 'cheer_replaced_kwh'])\n",
    "\n",
    "# # Select the first row and convert it to a dictionary\n",
    "# first_row_dict = whatsthis_filtered.iloc[0].to_dict()\n",
    "\n",
    "# # Print the dictionary\n",
    "# # print(first_row_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac534884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# goodone = canbikeco[(canbikeco['Mode_confirm'] == 'Walk') & (canbikeco['cheer_kg_co2'] == 0)]\n",
    "# print(goodone.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb6d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# combined_df = pd.concat([whatsthis_filtered.iloc[0], goodone.head(1)], ignore_index=True)\n",
    "# combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062a3b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_difference = plotter(canbikeco, \"CanBikeCO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62d21ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(co_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9e4da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_test = canbikeco[canbikeco['Mode_confirm'] == 'Walk'].head(2)\n",
    "a_test\n",
    "# a_test = pd.DataFrame(a_test\n",
    "#                      )\n",
    "# row = a_test.iloc[0]\n",
    "# print(a_test.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde0fb00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474938f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(replaced_footprint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d31773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bull Durham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710450ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('bull'):\n",
    "    if not os.path.isfile('tsdc-2022-bull-e-bike-pilot-program-study-full-survey-data 2.zip'):\n",
    "        raise ValueError(\"i need the zip, ask TSDC\")\n",
    "    else:\n",
    "        # Unzip the file to the 'bull' directory\n",
    "        with zipfile.ZipFile('tsdc-2022-bull-e-bike-pilot-program-study-full-survey-data 2.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall('bull')\n",
    "        print(\"Unzipped to 'bull' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85c4d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bull = pd.read_csv('bull/tsdc-2022-bull-e-bike-pilot-program-study-full-survey-data 2/data/analysis_confirmed_trip.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea068144",
   "metadata": {},
   "outputs": [],
   "source": [
    "bull_loaded = await load_or_fetch_data(\"bull-durham\",\n",
    "                                     bull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda14393",
   "metadata": {},
   "outputs": [],
   "source": [
    "bull_difference = plotter(bull_loaded, \"Bull (Durham, NC) eBike\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c28723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MassCEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7209ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if 'MassCEC' directory exists\n",
    "if not os.path.isdir('MassCEC'):\n",
    "    # check if the tar.gz file exists\n",
    "    if not os.path.isfile('mass_jacques.tar.gz'):\n",
    "        raise ValueError(\"I need the tar.gz file, ask TSDC\")\n",
    "    else:\n",
    "        # extract the tar.gz file to the 'MassCEC' directory\n",
    "        with tarfile.open('mass_jacques.tar.gz', 'r:gz') as tar_ref:\n",
    "            tar_ref.extractall('MassCEC')\n",
    "        print(\"Extracted to 'MassCEC' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83b647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass = pd.read_csv('MassCEC/mass_jacques/analysis_confirmed_trip.csv')\n",
    "# print(mass.columns)\n",
    "print(mass['data_user_input_mode_confirm'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass[mass['data_user_input_mode_confirm'] == 'bus'].head(55)\n",
    "print(len(mass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006d199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_loaded = await load_or_fetch_data(\"masscec\",\n",
    "                                       mass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea96015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass_loaded[mass_loaded['Mode_confirm'] == 'bus'].head(55)\n",
    "print(len(mass_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e6a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mass_loaded['Mode_confirm'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed07037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_difference = plotter(mass_loaded, \"MassCEC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271ad45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(mass_loaded.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e197bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895dac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanded_ct.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c29b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dictionaries\n",
    "differences = [co_difference, bull_difference, mass_difference]\n",
    "\n",
    "# map dataset names to acronyms\n",
    "dataset_map = {\n",
    "    'CanBikeCO': 'CO',\n",
    "    'Bull (Durham, NC) eBike': 'NC',\n",
    "    'MassCEC': 'MA'\n",
    "}\n",
    "\n",
    "# extract dataset names and modes\n",
    "dataset_names = [dataset_map[list(d.keys())[0]] for d in differences]\n",
    "modes = sorted(set().union(*[d[list(d.keys())[0]].keys() for d in differences]))\n",
    "\n",
    "# create a dataframe with each dataset's percentage differences, replacing None or NaN with \"--\"\n",
    "table_data = {\n",
    "    dataset_map[name]: [\n",
    "        fr\"{float(d[name].get(mode)):.2f}\\%\" if d[name].get(mode) not in [\"NaN\", None] else \"--\"\n",
    "        for mode in modes\n",
    "    ]\n",
    "    for d in differences\n",
    "    for name in d\n",
    "}\n",
    "table_data['Mode'] = modes\n",
    "\n",
    "# convert to dataframe and set 'Mode' as the first column\n",
    "df_table = pd.DataFrame(table_data)\n",
    "df_table = df_table[['Mode'] + dataset_names]\n",
    "\n",
    "# convert to latex, now `--` will appear instead of `NaN`\n",
    "latex_code = df_table.to_latex(\n",
    "    index=False,\n",
    "    header=True,\n",
    "    column_format=\"|l|c|c|c|\",\n",
    "    escape=False,\n",
    "    caption=\"Percentage differences in cumulative CO2 emissions by mode for each dataset between naive and CHEER, for the average trip taken of that mode.\",\n",
    "    label=\"tab:naive_cheer_percent_diff\"  # Specify the label here\n",
    ")\n",
    "print(latex_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c5fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ac05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emission.core.wrapper.modeprediction import PredictedModeTypes\n",
    "import ast\n",
    "\n",
    "\n",
    "def section_reader_naive_naive(dataframe: pd.DataFrame,\n",
    "                               dataset_name: str,\n",
    "                               full_dataframe: pd.DataFrame):\n",
    "\n",
    "    # determine the correct column name to use for trip IDs\n",
    "    trip_id_column = 'data_trip_id' if 'data_trip_id' in dataframe.columns \\\n",
    "        else 'tripno' if 'tripno' in dataframe.columns \\\n",
    "        else 'data_cleaned_trip'\n",
    "\n",
    "    # filter dataframe to include only rows where the trip IDs are in full_dataframe\n",
    "    filtered_dataframe = dataframe[dataframe[trip_id_column].isin(full_dataframe['data_cleaned_trip'])]\n",
    "\n",
    "    print(f\"Number of sections before filtering: {len(dataframe)}\")\n",
    "    print(f\"Number of sections after filtering: {len(filtered_dataframe)}\")\n",
    "\n",
    "\n",
    "    dataframe = filtered_dataframe.copy()\n",
    "    # function to map the numeric mode to its string representation\n",
    "    def map_mode_to_string(mode_number):\n",
    "        try:\n",
    "            return PredictedModeTypes(mode_number).name.title()\n",
    "        except ValueError:\n",
    "            return \"Unknown\"  # unexpected numbers\n",
    "\n",
    "    # apply the function to create a new column with mode type names\n",
    "    dataframe['predicted_mode_name'] = dataframe['data_sensed_mode'].apply(map_mode_to_string)\n",
    "    dataframe['distance_km'] = dataframe['data_distance'] * 0.001\n",
    "\n",
    "    # helper function to calculate the average speed from data_speeds\n",
    "    def calculate_average_speed(speeds):\n",
    "        if isinstance(speeds, str):\n",
    "            # parse the string to a list if in string format\n",
    "            speeds = ast.literal_eval(speeds)\n",
    "        if isinstance(speeds, list) and speeds:\n",
    "            return sum(float(speed) for speed in speeds) / len(speeds)\n",
    "        return 0  # return 0 if speeds is empty or not a list\n",
    "\n",
    "    # apply the helper function to calculate the average speed for each row\n",
    "    dataframe['average_speed'] = dataframe['data_speeds'].apply(calculate_average_speed)\n",
    "\n",
    "    # calculate the average speed for each mode\n",
    "    average_speed_per_mode = dataframe.groupby('predicted_mode_name')['average_speed'].mean().reset_index()\n",
    "    average_speed_per_mode.columns = ['predicted_mode_name', 'average_speed']\n",
    "\n",
    "    # display the result\n",
    "    print(\"Average speed per mode:\")\n",
    "    print(average_speed_per_mode)\n",
    "\n",
    "    g_pkm = {\n",
    "        'Car': 172.78,  # ICEV\n",
    "        'Train': 57.17,\n",
    "        'Subway': 57.17,  # treat Subway as Train\n",
    "        'Bus': 165.94,\n",
    "        'Air_Or_Hsr': 134.86,  # is it ok to group HSR in too?\n",
    "        'Walking': 0,\n",
    "        'Bicycling': 0,\n",
    "    }\n",
    "\n",
    "    # map the CO2 emissions per mode (convert grams to kg by dividing by 1000)\n",
    "    def calculate_co2_emission(row):\n",
    "        mode = row['predicted_mode_name']\n",
    "        distance_km = row['distance_km']\n",
    "        co2_per_km_kg = g_pkm.get(mode, 0) / 1000  # default to 0 if mode is not in g_pkm\n",
    "        return co2_per_km_kg * distance_km\n",
    "\n",
    "    # apply the function to calculate the CO2 emissions for each row\n",
    "    dataframe['co2_emission_kg_naive_naive'] = dataframe.apply(calculate_co2_emission, axis=1)\n",
    "\n",
    "    # verify that 'co2_emission_kg_naive_naive' column exists and contains data\n",
    "    print(dataframe[['predicted_mode_name', 'distance_km', 'co2_emission_kg_naive_naive']].head())\n",
    "\n",
    "    # calculate cumulative CO2 emissions for each mode\n",
    "    cumulative_co2_emission = dataframe.groupby('predicted_mode_name')['co2_emission_kg_naive_naive'].sum().reset_index()\n",
    "\n",
    "    # rename the column to reflect cumulative emissions\n",
    "    cumulative_co2_emission.columns = ['predicted_mode_name', 'cumulative_co2_emission_kg_naive_naive']\n",
    "\n",
    "    # ensure all modes, including \"Walking\" and \"Bicycling\", are represented\n",
    "    for mode in ['Walking', 'Bicycling']:\n",
    "        if mode not in cumulative_co2_emission['predicted_mode_name'].values:\n",
    "            cumulative_co2_emission = pd.concat([\n",
    "                cumulative_co2_emission,\n",
    "                pd.DataFrame({'predicted_mode_name': [mode], 'cumulative_co2_emission_kg_naive_naive': [0]})\n",
    "            ], ignore_index=True)\n",
    "\n",
    "    # exclude specific modes\n",
    "    cumulative_co2_emission = cumulative_co2_emission[~cumulative_co2_emission['predicted_mode_name'].isin(['Tram', 'Light_Rail', 'Unknown'])]\n",
    "\n",
    "    #\n",
    "    # sensed mode to data user input confusion matrix\n",
    "    #\n",
    "        #  temporary merged DataFrame for the confusion matrix\n",
    "\n",
    "    temp_joined_df = pd.merge(\n",
    "        dataframe,\n",
    "        full_dataframe[['data_cleaned_trip', 'data_user_input_mode_confirm']],\n",
    "        left_on=trip_id_column,\n",
    "        right_on='data_cleaned_trip',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    comparison_table = pd.crosstab(\n",
    "        temp_joined_df['data_user_input_mode_confirm'], \n",
    "        temp_joined_df['predicted_mode_name'], \n",
    "        rownames=['User Input Mode'], \n",
    "        colnames=['Predicted Mode'],\n",
    "        normalize='index'  # Normalize by rows to show percentages\n",
    "    ) * 100\n",
    "\n",
    "    # output the raw comparison matrix and normalized version\n",
    "    raw_comparison_table = pd.crosstab(\n",
    "        temp_joined_df['data_user_input_mode_confirm'], \n",
    "        temp_joined_df['predicted_mode_name'], \n",
    "        rownames=['User Input Mode'], \n",
    "        colnames=['Predicted Mode']\n",
    "    )\n",
    "\n",
    "    print(\"Raw Comparison Table:\")\n",
    "    print(raw_comparison_table)\n",
    "\n",
    "    print(\"\\nNormalized Comparison Table (%):\")\n",
    "    print(comparison_table)\n",
    "    \n",
    "    #\n",
    "    #\n",
    "    \n",
    "    \n",
    "    # filter out modes with zero cumulative emissions\n",
    "    cumulative_co2_emission_filtered = cumulative_co2_emission[\n",
    "        cumulative_co2_emission['cumulative_co2_emission_kg_naive_naive'] > 0\n",
    "    ]\n",
    "    # calculate cumulative distance for each mode\n",
    "    cumulative_distance = dataframe.groupby('predicted_mode_name')['distance_km'].sum().reset_index()\n",
    "\n",
    "    # rename the column to reflect cumulative distance\n",
    "    cumulative_distance.columns = ['predicted_mode_name', 'cumulative_distance_km']\n",
    "\n",
    "    # filter out modes with absolutely zero distance and exclude Tram and Unknown\n",
    "    cumulative_distance_filtered = cumulative_distance[\n",
    "        (cumulative_distance['cumulative_distance_km'] > 0) &\n",
    "        (~cumulative_distance['predicted_mode_name'].isin(['Tram', 'Unknown']))\n",
    "    ]\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.bar(\n",
    "        cumulative_distance_filtered['predicted_mode_name'],\n",
    "        cumulative_distance_filtered['cumulative_distance_km']\n",
    "    )\n",
    "\n",
    "    plt.xlabel('Mode of Transport', fontsize=22)\n",
    "    plt.ylabel('Cumulative Distance (km)', fontsize=22)\n",
    "\n",
    "    plt.xticks(fontsize=20, rotation=45)\n",
    "    plt.yticks(fontsize=20)\n",
    "\n",
    "\n",
    "#     plt.yscale('log')\n",
    "\n",
    "    plt.ylim(0, 140000)\n",
    "\n",
    "    # remove scientific notation on the y-axis\n",
    "    ax = plt.gca()\n",
    "    ax.yaxis.set_major_formatter(mticker.ScalarFormatter())\n",
    "    ax.yaxis.get_major_formatter().set_scientific(False)\n",
    "    ax.yaxis.get_major_formatter().set_useOffset(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/naivenaive/{dataset_name.lower().replace(\" \", \"_\")}_cumulative_distance_log.pdf')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    return dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33942e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('inferred'):\n",
    "    if not os.path.isfile('inferred_sections.zip'):\n",
    "        raise ValueError(\"i need the zip with sections, ask TSDC\")\n",
    "    else:\n",
    "        # Unzip the file to the 'bull' directory\n",
    "        with zipfile.ZipFile('inferred_sections.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall('inferred')\n",
    "        print(\"Unzipped to 'inferred' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da884d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909ee65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path configuration\n",
    "data_dir = \"all_CanBikeCO\"\n",
    "# dictionary to store DataFrames with keys as dataset names\n",
    "inferred_sections = {}\n",
    "\n",
    "\n",
    "files_to_combine = [\n",
    "    \"inf_sec_pc.csv\",\n",
    "    \"inf_sec_vail.csv\",\n",
    "    \"inf_sec_4c.csv\",\n",
    "    \"inf_sec_cc.csv\",\n",
    "    \"inf_sec_sc.csv\",\n",
    "    \"inf_sec_fc.csv\",\n",
    "]\n",
    "\n",
    "inferred_canbike = pd.DataFrame()\n",
    "\n",
    "\n",
    "for file_name in files_to_combine:\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    dataset_key = file_name.split('_')[-1].replace('.csv', '')  # Extract dataset key\n",
    "    print('\\nProcessing file:', file_path)\n",
    "    \n",
    "    # read the CSV file\n",
    "    df = pd.read_csv(file_path, engine=\"python\", on_bad_lines='skip')\n",
    "    print(f'{len(df)} rows read from {file_name}')\n",
    "    \n",
    "    \n",
    "    # store df in the dictionary\n",
    "    inferred_sections[dataset_key] = df\n",
    "    \n",
    "    # reset index to ensure uniqueness\n",
    "    df.reset_index()\n",
    "\n",
    "    inferred_canbike = pd.concat([inferred_canbike, df], ignore_index=True)\n",
    "\n",
    "print(f'\\nTotal number of rows after merging: {len(inferred_canbike)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cf255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_reader_naive_naive(inferred_canbike, \"CanBikeCO\", canbikeco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6055513",
   "metadata": {},
   "outputs": [],
   "source": [
    "bull_section = pd.read_csv('inferred/inferred_sections/analysis_inferred_section_DURHAM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b9850",
   "metadata": {},
   "outputs": [],
   "source": [
    "bull_section = section_reader_naive_naive(bull_section, \"Bull eBike in Durham, NC\", bull_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e205d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_section = pd.read_csv('inferred/inferred_sections/analysis_inferred_section_MASS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5470410",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_section = section_reader_naive_naive(mass_section, \"MassCEC\", mass_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddcaad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass_loaded and mass_section\n",
    "mass_loaded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19aa85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_method_comparator(section_df: pd.DataFrame, full_df: pd.DataFrame, dataname: str, cumulative_co2_dict=None):\n",
    "    print(' section before:', len(section_df))\n",
    "\n",
    "    # determine the correct column name to use for trip IDs\n",
    "    print(section_df.columns)\n",
    "    print(':)')\n",
    "    trip_id_column = 'data_trip_id' if 'data_trip_id' in section_df.columns \\\n",
    "        else 'tripno' if 'tripno' in section_df.columns \\\n",
    "        else 'data_cleaned_trip'\n",
    "    filtered_sections_cleaned = section_df[section_df[trip_id_column].isin(full_df['data_cleaned_trip'])]\n",
    "\n",
    "    # merge with the full_df to get the necessary mode and CO2 data\n",
    "    filtered_sections_with_modes = filtered_sections_cleaned.merge(\n",
    "        full_df[['data_cleaned_trip', 'Mode_confirm_kg_CO2', 'Mode_confirm']],\n",
    "        left_on=trip_id_column,\n",
    "        right_on='data_cleaned_trip',\n",
    "        how='left'\n",
    "    )\n",
    "    print('number of sections matched:', len(filtered_sections_cleaned))\n",
    "    \n",
    "    print('distance sections', f\"{filtered_sections_with_modes['data_distance'].sum():,}\")\n",
    "    print('distance full', f\"{full_df['distance'].sum():,}\")\n",
    "\n",
    "    # check if cumulative CO2 dictionary is provided\n",
    "    if cumulative_co2_dict:\n",
    "        # use provided emission values\n",
    "        naive_naive_emissions = cumulative_co2_dict.get('naivenaive', 0)\n",
    "        naive_emissions = cumulative_co2_dict.get('naive', 0)\n",
    "        total_cheer_emissions = cumulative_co2_dict.get('cheer', 0)\n",
    "    else:\n",
    "        # calculate emissions for each method\n",
    "        naive_naive_emissions = filtered_sections_with_modes['co2_emission_kg_naive_naive'].sum()\n",
    "        naive_emissions = full_df['Mode_confirm_kg_CO2'].sum()\n",
    "        total_cheer_emissions = full_df['cheer_kg_co2'].sum()\n",
    "\n",
    "    print(f\"\\nApp 2014: {naive_naive_emissions} kg\")\n",
    "    print(f\"Dashboard 2020: {naive_emissions} kg\")\n",
    "    print(f\"CHEER: {total_cheer_emissions} kg\")\n",
    "    \n",
    "    # Step 1: get unique trip IDs in full_df based on data_cleaned_trip\n",
    "    all_trip_ids = set(full_df[\"data_cleaned_trip\"].unique())\n",
    "\n",
    "    # Step 2: get unique trip IDs in current_section that match with full_df based on tripno\n",
    "    matched_trip_ids = set(filtered_sections_with_modes[filtered_sections_with_modes[trip_id_column].isin(all_trip_ids)][trip_id_column].unique())\n",
    "\n",
    "    # Step 3: find trips in full_df without sections\n",
    "    trips_without_sections = all_trip_ids - matched_trip_ids\n",
    "\n",
    "    # count the number of trips without sections\n",
    "    num_trips_without_sections = len(trips_without_sections)\n",
    "\n",
    "    # output the statistics\n",
    "    print(f\"Total trips in full_df: {len(all_trip_ids)}\")\n",
    "    print(f\"Trips in full_df without any sections: {num_trips_without_sections}\")\n",
    "\n",
    "    #data for plotting\n",
    "    methods = [\"App 2014\", \"Dashboard 2020\", \"CHEER\"]\n",
    "    emissions = [naive_naive_emissions, naive_emissions, total_cheer_emissions]\n",
    "    colors = ['#FFA07A', '#6495ED', '#3CB371']  # custom colors for each method\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.bar(methods, emissions, color=colors)\n",
    "    plt.xlabel(\"Emission Calculation Method\")\n",
    "    plt.ylabel(\"Total COâ‚‚ Emissions (kg)\")\n",
    "#     plt.title(f\"Comparison of COâ‚‚ Emissions by Calculation Method\\n{dataname} Dataset\")\n",
    "    \n",
    "    # format y-axis tick labels with commas\n",
    "    ax = plt.gca()\n",
    "    ax.yaxis.set_major_formatter(mticker.StrMethodFormatter('{x:,.0f}'))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f\"{dataname.replace('(', '').replace(')', '').replace(' ', '_').replace(',', '').lower()}_three_emissions_comparison.pdf\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'naivenaive': naive_naive_emissions,\n",
    "        'naive': naive_emissions,\n",
    "        'cheer': total_cheer_emissions,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e28b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_method_comparator(mass_section, mass_loaded, \"MassCEC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06732e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_method_comparator(bull_section, bull_loaded, \"Bull (Durham, NC) eBike\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41443836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(f\"{full_data['data_distance'].sum():,}\")\n",
    "# three_method_comparator(inferred_canbike, canbikeco, \"CanBikeCO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d0f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(inferred_sections.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926d8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old file mapping\n",
    "lookupdictionary = {\n",
    "    \"sc\": \"sc_21\",\n",
    "    \"boulder\": \"cc_21\",\n",
    "    \"fortcollins\": \"fc_21\",\n",
    "    \"pueblo\": \"pc_21\",\n",
    "    \"durango\": \"4c_21\",\n",
    "    \"vail\": \"vail_22\",\n",
    "}\n",
    "\n",
    "# # Read and concatenate all datasets in a single line\n",
    "# inferred_co_data = pd.concat(\n",
    "#     (\n",
    "#         pd.read_csv(f\"all_CanBikeCO/inf_sec_{program_code}.csv\", engine=\"python\", on_bad_lines='skip')\n",
    "#         .assign(program=program_code.upper())\n",
    "#         for program_code in lookupdictionary.values()\n",
    "#     ),\n",
    "#     ignore_index=True\n",
    "# )\n",
    "\n",
    "# # Output the result for verification\n",
    "# print(f\"Total rows: {len(inferred_co_data)}\")\n",
    "# print(f\"Unique users: {inferred_co_data['perno'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706abae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read and concatenate all datasets in a single line\n",
    "# full_trip_co = pd.concat(\n",
    "#     (\n",
    "#         pd.read_csv(f\"all_CanBikeCO/conf_trip_{program_code}.csv\", engine=\"python\", on_bad_lines='skip')\n",
    "#         .assign(program=program_code.upper())\n",
    "#         for program_code in lookupdictionary.values()\n",
    "#     ),\n",
    "#     ignore_index=True\n",
    "# )\n",
    "\n",
    "# # Output the result for verification\n",
    "# print(f\"Total trips: {len(full_trip_co)}\")\n",
    "# print(f\"Unique users: {full_trip_co['perno'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983f6233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Before processing:\")\n",
    "# print(f\"Number of trips: {len(full_trip_co)}\")\n",
    "# print(f\"Total distance: {full_trip_co['data_distance'].sum():,} m\")\n",
    "\n",
    "# # print(\"Columns in full_trip_co:\")\n",
    "# # print(full_trip_co.columns)\n",
    "\n",
    "# num_missing_mode_confirm = full_trip_co['data_user_input_mode_confirm'].isna().sum()\n",
    "# print(f\"Number of trips with missing 'data_user_input_mode_confirm': {num_missing_mode_confirm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c6b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_trip_co\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac78141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# canbikeco = await load_or_fetch_data(\"canbikeco\", full_trip_co)\n",
    "\n",
    "# print(\"After processing:\")\n",
    "# print(f\"Number of trips: {len(canbikeco)}\")\n",
    "# print(f\"Total distance: {canbikeco['distance'].sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# canbike_new_full = await load_or_fetch_data(\"co-full-new\", full_trip_co) # this function is the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c723b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# three_method_comparator(inferred_canbike, canbike_new_full, \"CanBikeCO\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a737641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Update the keys to be uppercase and adjust 'VAIL_22' to 'VAIL'\n",
    "# confirmed = {key.upper().replace('_22', ''): value for key, value in confirmed.items()}\n",
    "\n",
    "# # Now `datasets` has keys in the desired format\n",
    "# print(confirmed.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd6f05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cumulative_co2 = {\n",
    "    'naivenaive': 0,\n",
    "    'naive': 0,\n",
    "    'cheer': 0,\n",
    "}\n",
    "\n",
    "\n",
    "for biggername in lookupdictionary:\n",
    "#     current_section = inferred_sections[biggername]\n",
    "#     full_csv = lookupdictionary[biggername]\n",
    "    \n",
    "        \n",
    "    current_section = pd.read_csv(f\"CanBikeCO_2/ceo_{lookupdictionary[biggername]}/analysis_inferred_section.csv\", engine=\"python\", on_bad_lines='skip')\n",
    "    \n",
    "    full_csv = pd.read_csv(f\"CanBikeCO_2/ceo_{lookupdictionary[biggername]}/analysis_confirmed_trip.csv\")\n",
    "    \n",
    "    if 'data_sensed_mode' not in current_section.columns:\n",
    "        print('!'*100)\n",
    "        print(biggername, 'does not have sensed mode')\n",
    "        raise ValueError\n",
    "    \n",
    "    full_current_loaded = await load_or_fetch_data(f\"co-{biggername}\",\n",
    "                                                 full_csv)\n",
    "\n",
    "    print('!', biggername)\n",
    "    \n",
    "    section_naive = section_reader_naive_naive(current_section, biggername, full_csv)\n",
    "    \n",
    "    currentsum = section_naive['co2_emission_kg_naive_naive'].sum()\n",
    "\n",
    "    \n",
    "#     display(section_naive)\n",
    "    print('?')\n",
    "\n",
    "    returneddict = three_method_comparator(section_naive, full_current_loaded, biggername)\n",
    "    cumulative_co2['naivenaive'] += returneddict['naivenaive']\n",
    "    cumulative_co2['naive'] += returneddict['naive']\n",
    "    cumulative_co2['cheer'] += returneddict['cheer']\n",
    "#     print('sum for ', biggername, currentsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16fc036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookupdictionary = {\n",
    "#     \"sc\": \"sc\",\n",
    "#     \"boulder\": \"cc\",\n",
    "#     \"fortcollins\": \"fc\",\n",
    "#     \"pueblo\": \"pc\",\n",
    "#     \"durango\": \"fc\",\n",
    "#     \"vail\": \"vail\",\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b200ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cumulative_co2)\n",
    "three_method_comparator(inferred_canbike, canbikeco, \"CanBikeCO\", cumulative_co2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f986b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2eeda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e45006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
