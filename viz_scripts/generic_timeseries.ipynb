{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Static Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the input parameters for the notebook. They will be automatically changed when the scripts to generate monthly statistics are run. You can modify them manually to generate multiple plots locally as well.\n",
    "\n",
    "Pass in `None` to remove the filters and plot all data. This is not recommended for production settings, but might be useful for reports based on data snapshots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2020\n",
    "month = 11\n",
    "program = \"default\"\n",
    "study_type = \"study\"\n",
    "mode_of_interest = None\n",
    "include_test_users = False\n",
    "labels = {}\n",
    "use_imperial = False\n",
    "sensed_algo_prefix = \"cleaned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from plots import *\n",
    "import scaffolding\n",
    "\n",
    "import emcommon.util as emcu\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metric vs imperial vars\n",
    "label_units, dist_unit, label_units_lower, distance_col, weight_unit = scaffolding.get_units(use_imperial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Data From Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "expanded_ct, file_suffix, quality_text, debug_df = await scaffolding.load_viz_notebook_data(year,\n",
    "                                                                            month,\n",
    "                                                                            program,\n",
    "                                                                            study_type,\n",
    "                                                                            labels,\n",
    "                                                                            include_test_users=include_test_users,\n",
    "                                                                            add_footprint=True)\n",
    "expanded_ct = scaffolding.unpack_energy_emissions(expanded_ct) if \"mode_confirm_footprint\" in expanded_ct.columns else expanded_ct\n",
    "\n",
    "expanded_ct_sensed, file_suffix_sensed, quality_text_sensed, debug_df_sensed = await scaffolding.load_viz_notebook_sensor_inference_data(year,\n",
    "                                                                            month,\n",
    "                                                                            program,\n",
    "                                                                            labels,\n",
    "                                                                            include_test_users,\n",
    "                                                                            sensed_algo_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get timestamp from known year/month/day aggregated to days\n",
    "sel_cols_no_label_dep = ['user_id','start_local_dt_year','start_local_dt_month','start_local_dt_day', distance_col]\n",
    "\n",
    "if use_imperial:\n",
    "#     sel_cols_no_label_dep = ['user_id','start_local_dt_year','start_local_dt_month','start_local_dt_day','distance_miles']\n",
    "    sel_cols_with_label_dep = sel_cols_no_label_dep + ['Mode_confirm','Mode_confirm_EI(kWH)','Mode_confirm_lb_CO2']\n",
    "else:\n",
    "#     sel_cols_no_label_dep = ['user_id','start_local_dt_year','start_local_dt_month','start_local_dt_day','distance']\n",
    "    sel_cols_with_label_dep = sel_cols_no_label_dep + ['Mode_confirm','Mode_confirm_EI(kWH)','Mode_confirm_kg_CO2']\n",
    "\n",
    "if len(expanded_ct) == 0:\n",
    "    data = expanded_ct.copy()\n",
    "elif \"Mode_confirm\" not in expanded_ct.columns:\n",
    "    data = expanded_ct[sel_cols_no_label_dep].copy()\n",
    "else:\n",
    "    #add mode confirm related columns if labeled\n",
    "    data = expanded_ct[sel_cols_with_label_dep].copy()\n",
    "\n",
    "if len(expanded_ct) > 0:\n",
    "    data.rename(columns={'start_local_dt_year':'year','start_local_dt_month':'month','start_local_dt_day':'day'}, inplace=True)\n",
    "    data['date_time'] = pd.to_datetime(data[['year','month','day']])\n",
    "    data = data.drop(columns=['year','month','day'])\n",
    "    # Categorical type will include all days/modes in groupby even if there is no data for a particular tabulation\n",
    "    data.user_id = pd.Categorical(data.user_id)\n",
    "    data.date_time = pd.Categorical(data.date_time)\n",
    "    \n",
    "if len(expanded_ct_sensed) > 0:\n",
    "    expanded_ct_sensed.rename(columns={'start_local_dt_year':'year','start_local_dt_month':'month','start_local_dt_day':'day'}, inplace=True)\n",
    "    expanded_ct_sensed['date_time'] = pd.to_datetime(expanded_ct_sensed[['year','month','day']])\n",
    "    expanded_ct_sensed = expanded_ct_sensed.drop(columns=['year','month','day'])\n",
    "    # Categorical type will include all days/modes in groupby even if there is no data for a particular tabulation\n",
    "    expanded_ct_sensed.user_id = pd.Categorical(expanded_ct_sensed.user_id)\n",
    "    expanded_ct_sensed.date_time = pd.Categorical(expanded_ct_sensed.date_time)\n",
    "\n",
    "dic_mode_mapping = scaffolding.mapping_labels(labels, \"MODE\")\n",
    "\n",
    "if \"Mode_confirm\" in expanded_ct.columns:\n",
    "    data.Mode_confirm = pd.Categorical(data.Mode_confirm, ordered=True, categories=np.unique(list(dic_mode_mapping.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_daily_metrics(data, weight_unit, distance_unit):\n",
    "    # Sum daily distance traveled for each mode\n",
    "    mode_distance = data.groupby(['user_id','date_time','Mode_confirm'], as_index=False)[[distance_unit]].sum()\n",
    "    mode_distance.rename(columns={'sum':distance_unit}, inplace=True)\n",
    "    mode_distance[distance_unit] = mode_distance[distance_unit].fillna(0)\n",
    "    \n",
    "    # Sum daily emissions for each user\n",
    "    emissions = data.groupby(['user_id','date_time'], as_index=False)[[f'Mode_confirm_{weight_unit}_CO2', distance_unit]].sum()\n",
    "    emissions[f'Mode_confirm_{weight_unit}_CO2'] = emissions[f'Mode_confirm_{weight_unit}_CO2'].fillna(0)\n",
    "    emissions[distance_unit] = emissions[f'Mode_confirm_{weight_unit}_CO2'].fillna(0)\n",
    "    \n",
    "    # Sum daily energy for each user\n",
    "    energy = data.groupby(['user_id','date_time'], as_index=False)[['Mode_confirm_EI(kWH)', distance_unit]].sum()\n",
    "    energy['Mode_confirm_EI(kWH)'] = energy['Mode_confirm_EI(kWH)'].fillna(0)\n",
    "    energy[distance_unit] = energy['Mode_confirm_EI(kWH)'].fillna(0)\n",
    "    \n",
    "    # Add 7-day rolling avg smoothing to better see trends\n",
    "    mode_counts['trip_count_smooth'] = mode_counts.groupby(['user_id','Mode_confirm'])['trip_count'].apply(lambda x: x.rolling(7,1).mean())\n",
    "    mode_distance[f'{distance_unit}_smooth'] = mode_distance.groupby(['user_id','Mode_confirm'])[distance_unit].apply(lambda x: x.rolling(7,1).mean())\n",
    "    emissions[f'{distance_unit}_smooth'] = emissions.groupby(['user_id'])[distance_unit].apply(lambda x: x.rolling(7,1).mean())\n",
    "    energy[f'{distance_unit}_smooth'] = energy.groupby(['user_id'])[distance_unit].apply(lambda x: x.rolling(7,1).mean())\n",
    "\n",
    "    return mode_counts, mode_distance, emissions, energy\n",
    "\n",
    "if len(expanded_ct) > 0:\n",
    "    # Get the count of unique users that were active on each given date\n",
    "    active_users = pd.DataFrame(data.groupby(['date_time'], as_index=False)['user_id'].nunique())\n",
    "    active_users.rename(columns={'user_id':'active_users'}, inplace=True)\n",
    "\n",
    "    if \"Mode_confirm\" in expanded_ct.columns:\n",
    "        # Count the number of trips for each confirmed mode\n",
    "        mode_counts = data.groupby(['user_id','date_time','Mode_confirm'], as_index=False).size()\n",
    "        mode_counts.rename(columns={'size':'trip_count'}, inplace=True)\n",
    "        mode_counts, mode_distance, emissions, energy = compute_daily_metrics( data, weight_unit = weight_unit, distance_unit = distance_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Timeseries Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emissions per week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_title_no_quality = 'Net Daily Emissions (All Users, excluding air)'\n",
    "file_name = \"ts_emissions_user%s\"%file_suffix\n",
    "\n",
    "def plot_emission_per_week(emissions, unit, active_users):\n",
    "    # Emissions per week across all users (net impact)\n",
    "    plot_data = emissions.groupby(['date_time'], as_index=False)[f'Mode_confirm_{unit}_CO2'].agg(['sum'])\n",
    "    total_sum = plot_data['sum'].sum()\n",
    "    plot_data = plot_data.merge(active_users, on='date_time')\n",
    "    plot_data['sum'] = plot_data['sum'] / plot_data['active_users']\n",
    "\n",
    "    plot_title= plot_title_no_quality+\"\\n\"+quality_text\n",
    "    ylab = f'Emissions ({unit} CO2/day/user)'\n",
    "    timeseries_plot(plot_data['date_time'], plot_data['sum'], plot_title, ylab, file_name)\n",
    "    alt_text = store_alt_text_timeseries(plot_data, file_name, plot_title)\n",
    "\n",
    "try:\n",
    "    plot_emission_per_week(emissions, weight_unit, active_users)\n",
    "except:\n",
    "    generate_missing_plot(plot_title_no_quality,debug_df,file_name)\n",
    "    alt_text = store_alt_text_missing(debug_df, file_name, plot_title_no_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy per week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_title_no_quality = 'Net Daily Energy (All Users, excluding air)'\n",
    "file_name = \"ts_energy_user%s\"%file_suffix\n",
    "\n",
    "try:\n",
    "    # Energy per week across all users (net impact)\n",
    "    plot_data = energy.groupby(['date_time'], as_index=False)['Mode_confirm_EI(kWH)'].agg(['sum'])\n",
    "    plot_data = plot_data.merge(active_users, on='date_time')\n",
    "    plot_data['sum'] = plot_data['sum'] / plot_data['active_users']\n",
    "\n",
    "    plot_title= plot_title_no_quality+\"\\n\"+quality_text\n",
    "    ylab = 'Energy (kWH/day/user)'\n",
    "    timeseries_plot(plot_data['date_time'], plot_data['sum'], plot_title, ylab, file_name)\n",
    "    alt_text = store_alt_text_timeseries(plot_data, file_name, plot_title)\n",
    "except:\n",
    "    generate_missing_plot(plot_title_no_quality,debug_df,file_name)\n",
    "    alt_text = store_alt_text_missing(debug_df, file_name, plot_title_no_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emissions per mile/kilometer per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_title_no_quality = 'Average Daily Emission Rate (All Users, excluding air)'\n",
    "file_name = \"ts_emissions_vmt%s\"%file_suffix\n",
    "\n",
    "def plot_emissions_per_distance_day(emissions, weight_unit, distance_unit, distance_unit_smooth,):\n",
    "    # Emissions per kilometer per day across all users (travel efficiency)\n",
    "    # Note that the energy plot will be identical to this one since scale factor is divided out\n",
    "    emissions[f'CO2_per_{distance_unit}'] = emissions[f'Mode_confirm_{weight_unit}_CO2'] / emissions[f'{distance_unit_smooth}']\n",
    "    emissions[f'CO2_per_{distance_unit}'] = emissions[f'CO2_per_{distance_unit}'].fillna(0)\n",
    "    plot_data = emissions.groupby(['date_time'])[f'CO2_per_{distance_unit}'].agg(['mean']).reset_index()\n",
    "    \n",
    "    plot_title= plot_title_no_quality+\"\\n\"+quality_text\n",
    "    ylab = f'Emissions ({weight_unit} CO2/{distance_unit}/day)'\n",
    "    timeseries_plot(plot_data['date_time'], plot_data['mean'], plot_title, ylab, file_name)\n",
    "    alt_text = store_alt_text_timeseries(plot_data, file_name, plot_title)\n",
    "\n",
    "try:\n",
    "    plot_emissions_per_distance_day(emissions, weight_unit, dist_unit, f'{distance_col}_smooth')\n",
    "\n",
    "except:\n",
    "    generate_missing_plot(plot_title_no_quality,debug_df,file_name)\n",
    "    alt_text = store_alt_text_missing(debug_df, file_name, plot_title_no_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of active users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_title_no_quality = 'Number of Active Users'\n",
    "file_name = \"ts_users%s\"%file_suffix\n",
    "\n",
    "try:\n",
    "    # Plot of active users\n",
    "    plot_data = active_users\n",
    "\n",
    "    plot_title= plot_title_no_quality+\"\\n\"+quality_text\n",
    "    ylab = 'Unique IDs'\n",
    "    timeseries_plot(plot_data['date_time'], plot_data['active_users'], plot_title, ylab, file_name)\n",
    "    alt_text = store_alt_text_timeseries(plot_data, file_name, plot_title)\n",
    "except:\n",
    "    generate_missing_plot(plot_title_no_quality,debug_df,file_name)\n",
    "    alt_text = store_alt_text_missing(debug_df, file_name, plot_title_no_quality) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily Mode share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_title_no_quality = 'Daily Aggregate Mode Share (excluding \"Other\" and \"Not a trip)\"'\n",
    "file_name = \"ts_all_modes%s\"%file_suffix\n",
    "\n",
    "try:\n",
    "    # Plot of mode share proportions across all users\n",
    "    # Consolidate modes\n",
    "    plot_data = mode_counts.replace('Bikeshare', 'Shared Micromobility')\n",
    "    plot_data = plot_data.replace('Scooter share', 'Shared Micromobility')\n",
    "    plot_data = plot_data.replace('Regular Bike', 'Personal Micromobility')\n",
    "    plot_data = plot_data.replace('Skate board', 'Personal Micromobility')\n",
    "    plot_data = plot_data.replace('Train', 'Transit')\n",
    "    plot_data = plot_data.replace('Free Shuttle', 'Transit')\n",
    "    plot_data = plot_data.replace('Bus', 'Transit')\n",
    "    plot_data = plot_data.replace('Walk', 'Walk')\n",
    "    plot_data = plot_data.replace('Taxi/Uber/Lyft', 'Ridehail')\n",
    "    plot_data = plot_data.replace('Pilot ebike', 'E-Bike')\n",
    "\n",
    "    plot_data = plot_data.groupby(['date_time','Mode_confirm'], as_index=False)['trip_count_smooth'].sum()\n",
    "    total_trips = plot_data.groupby(['date_time'], as_index=False).sum()\n",
    "    plot_data = plot_data.merge(total_trips, on='date_time')\n",
    "    plot_data['trip_proportion'] = plot_data['trip_count_smooth_x'] / plot_data['trip_count_smooth_y']\n",
    "    # Re-establish categorical variable to not include Other and Non-trips\n",
    "    plot_data = plot_data[~plot_data['Mode_confirm'].isin(['Not a Trip','Other'])]\n",
    "\n",
    "    plot_data.Mode_confirm = pd.Categorical(plot_data.Mode_confirm, ordered=True, categories=np.unique(list(dic_mode_mapping.values())))    \n",
    "\n",
    "    plot_title= plot_title_no_quality+\"\\n\"+quality_text\n",
    "    ylab = 'Proportion of All Trips'\n",
    "    legend_title = 'Confirmed Mode'\n",
    "    timeseries_multi_plot(plot_data, 'date_time','trip_proportion','Mode_confirm', plot_title, ylab, legend_title, file_name)\n",
    "    alt_text = store_alt_text_generic('multivariate timeseries', file_name, plot_title)\n",
    "except:\n",
    "    generate_missing_plot(plot_title_no_quality,debug_df,file_name)\n",
    "    alt_text = store_alt_text_missing(debug_df, file_name, plot_title_no_quality) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensed vs Labeled over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_title_no_quality = 'Total Trips vs Labeled Trips'\n",
    "file_name = \"ts_totalvlabeled%s\"%file_suffix\n",
    "\n",
    "try:\n",
    "    labeled_trips = data.copy()\n",
    "    labeled_trips = labeled_trips.groupby(['user_id','date_time'], as_index=False).size()\n",
    "    labeled_trips.rename(columns={'size':'trip_count'}, inplace=True)\n",
    "    labeled_trips['trip_count_smooth'] = labeled_trips.groupby(['user_id'])['trip_count'].apply(lambda x: x.rolling(7,1).mean())\n",
    "    labeled_trips.groupby(['date_time'], as_index=False).sum()\n",
    "    labeled_trips = labeled_trips.groupby(['date_time'], as_index=False).sum()\n",
    "    labeled_trips['Trip_type'] = \"Labeled\"\n",
    "\n",
    "    total_trips = expanded_ct_sensed.copy()\n",
    "    total_trips = total_trips.groupby(['user_id','date_time'], as_index=False).size()\n",
    "    total_trips.rename(columns={'size':'trip_count'}, inplace=True)\n",
    "    total_trips['trip_count_smooth'] = total_trips.groupby(['user_id'])['trip_count'].apply(lambda x: x.rolling(7,1).mean())\n",
    "    total_trips.groupby(['date_time'], as_index=False).sum()\n",
    "    total_trips = total_trips.groupby(['date_time'], as_index=False).sum()\n",
    "    total_trips['Trip_type'] = \"Total\"\n",
    "\n",
    "    plot_data = pd.concat([labeled_trips, total_trips])\n",
    "    \n",
    "    print(plot_data.head())\n",
    "    \n",
    "    plot_title= plot_title_no_quality+\"\\n\"+quality_text\n",
    "    ylab = 'Trip Count'\n",
    "    legend_title = 'Trip Type'\n",
    "    timeseries_multi_plot(plot_data, 'date_time','trip_count_smooth','Trip_type', plot_title, ylab, legend_title, file_name)\n",
    "    alt_text = store_alt_text_generic('multivariate timeseries', file_name, plot_title)\n",
    "except:\n",
    "    generate_missing_plot(plot_title_no_quality,debug_df,file_name)\n",
    "    alt_text = store_alt_text_missing(debug_df, file_name, plot_title_no_quality) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
