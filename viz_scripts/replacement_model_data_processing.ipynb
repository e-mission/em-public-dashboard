{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = None\n",
    "month = None\n",
    "program = \"prepilot\"\n",
    "study_type = \"program\"\n",
    "mode_of_interest = \"pilot_ebike\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = '/plots/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "\n",
    "from plots import *\n",
    "import scaffolding\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings and imports specific to this notebook\n",
    "\n",
    "include_replaced_modes_as_valid = True # Flip this when we want to get results versus generate the replaced_mode correction graphs\n",
    "model_with_sensed = False\n",
    "input_dataset = \"ONLY_LABELED\" # \"ONLY_LABELED\", \"ONLY_SENSED\" or \"BEST_AVAILABLE\" for sensitivity analysis\n",
    "LABEL_ASSIST_THRESHOLD = 0.3\n",
    "\n",
    "# For reloading modules from Jupyter\n",
    "# import importlib\n",
    "# importlib.reload(replacement_models)\n",
    "\n",
    "import datetime\n",
    "import pickle\n",
    "import sklearn.metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import emission.core.get_database as edb\n",
    "import emission.core.wrapper.entry as ecwe\n",
    "import emission.storage.decorations.analysis_timeseries_queries as esda\n",
    "import emission.storage.decorations.trip_queries as esdt\n",
    "import emission.storage.decorations.timeline as esdl\n",
    "import emission.storage.timeseries.abstract_timeseries as esta\n",
    "import emission.storage.timeseries.timequery as estt\n",
    "from uuid import UUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not run this notebook at all unless it is for a program; nbclient will run up through this cell\n",
    "if study_type != \"program\":\n",
    "    raise Exception(\"The plots in this notebook are only relevant to programs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading mapping dictionaries from mapping_dictionaries notebook\n",
    "%store -r dic_re\n",
    "%store -r dic_pur\n",
    "\n",
    "# convert a dictionary to a defaultdict\n",
    "dic_re = defaultdict(lambda: 'Other',dic_re)\n",
    "dic_pur = defaultdict(lambda: 'Other',dic_pur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get UUIDs by Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split UUIDs by program\n",
    "program_uuid_map = {}\n",
    "for ue in edb.get_uuid_db().find():\n",
    "    program = ue['user_email'].split(\"_\")[0]\n",
    "    if program in program_uuid_map.keys():\n",
    "        program_uuid_map[program].append(str(ue['uuid']))\n",
    "    else:\n",
    "        print(f\"Found new program {program}, creating new list\")\n",
    "        program_uuid_map[program] = []\n",
    "        program_uuid_map[program].append(str(ue['uuid']))\n",
    "\n",
    "uuid_program_list = []\n",
    "for ue in edb.get_uuid_db().find():\n",
    "    program = ue['user_email'].split(\"_\")[0]\n",
    "    uuid_program_list.append({\"program\": program, \"opcode\": ue[\"user_email\"], \"user_id_str\": str(ue['uuid'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid_program_df = pd.DataFrame.from_dict(uuid_program_list)\n",
    "uuid_program_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Data From Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expanded_ct, file_suffix, quality_text = scaffolding.load_viz_notebook_data(year,\n",
    "                                                                            month,\n",
    "                                                                            program,\n",
    "                                                                            study_type,\n",
    "                                                                            dic_re,\n",
    "                                                                            dic_pur=dic_pur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join to the program df to get each user's program\n",
    "expanded_ct['user_id_str'] = expanded_ct['user_id'].astype(str)\n",
    "expanded_ct = expanded_ct.merge(uuid_program_df, on='user_id_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add non-label category\n",
    "expanded_ct['replaced_mode'] = expanded_ct['replaced_mode'].fillna('Unlabeled')\n",
    "expanded_ct.loc[expanded_ct['replaced_mode'] == 'Unlabeled', 'Replaced_mode'] = \"Unlabeled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the expanded database data to socioeconomic data\n",
    "socio_data = pd.read_csv('./Can Do Colorado eBike Program - en.csv')\n",
    "socio_data.rename(columns={'Unique User ID (auto-filled, do not edit)':'user_id',\n",
    "                          'Please identify which category represents your total household income, before taxes, for last year.':'HHINC',\n",
    "                          'How many motor vehicles are owned, leased, or available for regular use by the people who currently live in your household?':'VEH',\n",
    "                           'In which year were you born?':'AGE',\n",
    "                          'Including yourself, how many people live in your home?':'HHSIZE',\n",
    "                          'How many children under age 18 live in your home?':'CHILDREN',\n",
    "                          'What is your gender?':'GENDER',\n",
    "                          'If you were unable to use your household vehicle(s), which of the following options would be available to you to get you from place to place?':'available_modes',\n",
    "                          'Are you a student?':'STUDENT',\n",
    "                          \"Including yourself, how many people have a driver's license in your household?\":'DRIVERS'}, inplace=True)\n",
    "socio_data = socio_data[~socio_data.user_id.isnull()]\n",
    "\n",
    "# Deal with people who have multiple responses by using most recent\n",
    "socio_data = socio_data.sort_values(by=['user_id', 'Timestamp'])\n",
    "socio_data.drop_duplicates(subset=['user_id'], keep='last', inplace=True)\n",
    "socio_data['user_id_socio'] = socio_data.user_id\n",
    "socio_data = socio_data.drop(labels='user_id', axis=1)\n",
    "\n",
    "# Lose some trips due to people with no survey responses\n",
    "expanded_ct['user_id_socio'] = expanded_ct.user_id.astype(str)\n",
    "expanded_ct.user_id_socio = [i.replace('-','') for i in expanded_ct.user_id_socio] # remove all dashes from strings\n",
    "expanded_ct = expanded_ct.merge(socio_data, on='user_id_socio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Filter database to variables of modeling interest\n",
    "data = expanded_ct[['Mode_confirm','Replaced_mode','replaced_mode','Trip_purpose','duration','distance_miles','start_local_dt_weekday','available_modes','AGE','HHINC','VEH','HHSIZE','CHILDREN','GENDER','STUDENT','DRIVERS','user_id','_id','start_local_dt_year','start_local_dt_month','start_local_dt_day','cleaned_trip','start_fmt_time','start_loc','end_loc']].copy()\n",
    "\n",
    "\n",
    "## Pre-filter round of variable creation\n",
    "# Make copy of user_id to be categorized since both versions are needed\n",
    "data['user_id_int'] = data['user_id']\n",
    "\n",
    "# Get timestamp from known year/month/day aggregated to days\n",
    "data.rename(columns={'start_local_dt_year':'year','start_local_dt_month':'month','start_local_dt_day':'day'}, inplace=True)\n",
    "data['date_time'] = pd.to_datetime(data[['year','month','day']])\n",
    "data = data.drop(columns=['year','day'])\n",
    "\n",
    "# Get time of day\n",
    "data['hour'] = [int(x[1][:2]) for x in expanded_ct.start_fmt_time.str.split('T')]\n",
    "\n",
    "# Fix age\n",
    "data['AGE'] = 2022 - data['AGE']\n",
    "\n",
    "# Number of workers\n",
    "data['WORKERS'] = (data['HHSIZE'] - data['CHILDREN']).astype(int)\n",
    "\n",
    "# Vehicles per driver\n",
    "data['VEH'] = data['VEH'].replace('4+', '4')\n",
    "\n",
    "# Recoded Cyclical Time of Day\n",
    "hours_in_day = 24\n",
    "months_in_year = 12\n",
    "data['sin_time'] = np.sin(2*np.pi*data.hour/hours_in_day)\n",
    "data['cos_time'] = np.cos(2*np.pi*data.hour/hours_in_day)\n",
    "data['sin_month'] = np.sin(2*np.pi*data.month/months_in_year)\n",
    "data['cos_month'] = np.cos(2*np.pi*data.month/months_in_year)\n",
    "\n",
    "# Duration in minutes\n",
    "data['duration'] = data['duration'] / 60\n",
    "\n",
    "# Add coordinates to the data\n",
    "z = pd.json_normalize(data.start_loc)['coordinates']\n",
    "olon = [str(x[0]) for x in z]\n",
    "olat = [str(x[1]) for x in z]\n",
    "data['olat'] = olat\n",
    "data['olon'] = olon\n",
    "z = pd.json_normalize(data.end_loc)['coordinates']\n",
    "dlon = [str(x[0]) for x in z]\n",
    "dlat = [str(x[1]) for x in z]\n",
    "data['dlat'] = dlat\n",
    "data['dlon'] = dlon\n",
    "\n",
    "# Recode variables\n",
    "data.Mode_confirm = data.Mode_confirm.replace(\n",
    "    ['Gas Car, drove alone',\n",
    "    'Gas Car, with others',\n",
    "    'Bikeshare',\n",
    "    'Scooter share',\n",
    "    'Regular Bike',\n",
    "    'Skate board',\n",
    "    'Train',\n",
    "    'Free Shuttle',\n",
    "    'Bus',\n",
    "    'Walk',\n",
    "    'Taxi/Uber/Lyft',\n",
    "    'E-bike'],\n",
    "    ['car',\n",
    "    's_car',\n",
    "    's_micro',\n",
    "    's_micro',\n",
    "    'p_micro',\n",
    "    'p_micro',\n",
    "    'transit',\n",
    "    'transit',\n",
    "    'transit',\n",
    "    'walk',\n",
    "    'ridehail',\n",
    "    'ebike']\n",
    ")\n",
    "data.Replaced_mode = data.Replaced_mode.replace(\n",
    "    ['Gas Car, drove alone',\n",
    "    'Gas Car, with others',\n",
    "    'Bikeshare',\n",
    "    'Scooter share',\n",
    "    'Regular Bike',\n",
    "    'Skate board',\n",
    "    'Train',\n",
    "    'Free Shuttle',\n",
    "    'Bus',\n",
    "    'Walk',\n",
    "    'Taxi/Uber/Lyft',\n",
    "    'E-bike',\n",
    "    'No Travel'],\n",
    "    ['car',\n",
    "    's_car',\n",
    "    's_micro',\n",
    "    's_micro',\n",
    "    'p_micro',\n",
    "    'p_micro',\n",
    "    'transit',\n",
    "    'transit',\n",
    "    'transit',\n",
    "    'walk',\n",
    "    'ridehail',\n",
    "    'ebike',\n",
    "    'no_travel']\n",
    ")\n",
    "data.Trip_purpose = data.Trip_purpose.replace(\n",
    "    ['Work',\n",
    "    'School',\n",
    "    'Recreation/Exercise',\n",
    "    'Transit transfer',\n",
    "    'Meal',\n",
    "    'Entertainment/Social',\n",
    "    'Shopping',\n",
    "    'Personal/Medical',\n",
    "    'Religious',\n",
    "    'Pick-up/Drop off'],\n",
    "    ['commute',\n",
    "    'commute',\n",
    "    'recreation',\n",
    "    'transit_transfer',\n",
    "    'discretionary',\n",
    "    'discretionary',\n",
    "    'discretionary',\n",
    "    'discretionary',\n",
    "    'discretionary',\n",
    "    'pudo']\n",
    ")\n",
    "data['is_weekend'] = 0\n",
    "data.loc[data['start_local_dt_weekday'].isin(['0','6']), 'is_weekend'] = 1\n",
    "data['is_male'] = 0\n",
    "data.loc[data['GENDER'].isin(['Man']), 'is_male'] = 1\n",
    "\n",
    "## Filter data\n",
    "# Filter out responses to data that are not workable\n",
    "data = data[~data['Mode_confirm'].isin(['Not a Trip','Other'])]\n",
    "data = data[~data['Replaced_mode'].isin(['Not a Trip','Other','Unlabeled'])]\n",
    "data = data[~data['available_modes'].isin(['None', 'Prefer not to say'])]\n",
    "data = data[~data['Trip_purpose'].isin(['not_a_trip','Other'])]\n",
    "data = data[~data['HHINC'].isin(['Prefer not to say','$100,000 -$149,999','$150,000','$150,000-$199,999','$200,000 or more'])] # Side note why is 150k (n=7) its own bin?\n",
    "data = data[~data['VEH'].isin(['Prefer not to say / Prefiero no decir.'])]\n",
    "data = data[data['distance_miles']<50]\n",
    "data = data[data['AGE']<100]\n",
    "data = data[data['HHSIZE']<10]\n",
    "data = data[data['HHSIZE']>data['CHILDREN']]\n",
    "\n",
    "\n",
    "## Post-filter round of variable creation\n",
    "# OHE any categorical, non-ordinal variables\n",
    "ohe_vars = ['Trip_purpose','HHINC','STUDENT']\n",
    "ohe_prefixes = ['purp','hhinc','student']\n",
    "data = pd.get_dummies(data, columns=ohe_vars, prefix=ohe_prefixes)\n",
    "\n",
    "# Calculate travel times for each trip, across every mode\n",
    "def add_all_mode_tt(data, mode_col, duration_col, dist_col):\n",
    "    wait_times_init = {'car':0.00,\n",
    "                      's_car':0.00,\n",
    "                      'ridehail':5.00,\n",
    "                      's_micro':5.00,\n",
    "                      'p_micro':0.00,\n",
    "                      'transit':7.00,\n",
    "                      'walk':5.00,\n",
    "                      'ebike':0.00}\n",
    "    mode_travel_times = {}\n",
    "    for mode in pd.unique(data[mode_col]):\n",
    "\n",
    "        # Linear model for duration based on distance for trips belonging to each mode\n",
    "        mode_data = data[data[mode_col]==mode]\n",
    "        regr = linear_model.LinearRegression()\n",
    "        regr.fit(np.log(mode_data[dist_col].values.reshape(-1,1)), np.log(mode_data[duration_col].values.reshape(-1,1)))\n",
    "        \n",
    "        # Make prediction for ALL trips, reverse the log transform to get mins\n",
    "        mode_duration_pred = regr.predict(np.log(data[dist_col].values.reshape(-1,1)))\n",
    "        mode_travel_times['tt_'+mode] = np.exp(mode_duration_pred) + wait_times_init[mode]\n",
    "\n",
    "    # Apply for each mode existing in the dataframe\n",
    "    for mode in mode_travel_times:\n",
    "        data[mode] = mode_travel_times[mode]\n",
    "\n",
    "    return regr, data\n",
    "\n",
    "# Calculate all mode travel times and add to dataframe\n",
    "regr, data = add_all_mode_tt(data,'Mode_confirm','duration','distance_miles')\n",
    "\n",
    "# Calculate vehicle costs\n",
    "cost_factors_init = {'car':0.00,\n",
    "                    's_car':0.00,\n",
    "                    'ridehail':5.00,\n",
    "                    's_micro':1.00,\n",
    "                    'p_micro':0.00,\n",
    "                    'transit':3.50,\n",
    "                    'ebike':0.00,\n",
    "                    'walk':0.00}\n",
    "cost_factors = {'car':0.62,\n",
    "                's_car':0.31,\n",
    "                'ridehail':0.80,\n",
    "                's_micro':0.90,\n",
    "                'p_micro':0.00,\n",
    "                'transit':0.00,\n",
    "                'ebike':0.11,\n",
    "                'walk':0.00}\n",
    "\n",
    "def add_all_mode_cost(data, cost_factors, dist_col):\n",
    "    for factor in cost_factors:\n",
    "        data['cost_'+factor] = cost_factors_init[factor] + (cost_factors[factor] * data[dist_col])\n",
    "    return data\n",
    "\n",
    "# Calculate all mode travel costs and add to dataframe\n",
    "add_all_mode_cost(data, cost_factors, 'distance_miles')\n",
    "\n",
    "# Labels for modes in the availability survey\n",
    "availability_codes = {'Public transportation (bus, subway, light rail, etc.)':'transit',\n",
    "                      'Get a ride from a friend or family member':'s_car',\n",
    "                      'Rental car (including Zipcar/ Car2Go)':'car',\n",
    "                      'Taxi (regular taxi, Uber, Lyft, etc)':'ridehail',\n",
    "                      'Bicycle':'p_micro',\n",
    "                      'Shared bicycle or scooter':'s_micro',\n",
    "                      'Walk/roll':'walk',\n",
    "                      'Skateboard':'p_micro',\n",
    "                      'ebike':'ebike',\n",
    "                      'None':'none'}\n",
    "\n",
    "def add_mode_availability(data, availability_codes, availability_col, choice_col, replaced_col, is_sp):\n",
    "    mode_list = np.unique(list(availability_codes.values())[:-1])\n",
    "    choice_list = data[choice_col].values\n",
    "    replaced_list = data[replaced_col].values\n",
    "    for mode in mode_list:\n",
    "        mode_avail = []\n",
    "        for i, available in enumerate(data[availability_col].values):\n",
    "            available_modes = [availability_codes[x] for x in available.split(';')]\n",
    "            # For SP: Replacement/stated available should be 1, chosen should be 0\n",
    "            if is_sp:\n",
    "                if mode==choice_list[i]:\n",
    "                    mode_check = False\n",
    "                else:\n",
    "                    mode_check = mode==replaced_list[i] or mode in available_modes\n",
    "            # For RP: Chosen/replacement/stated available should be 1\n",
    "            else:\n",
    "                mode_check = mode==choice_list[i] or mode==replaced_list[i] or mode in available_modes\n",
    "            # Keep binary list of which trips the mode was available for\n",
    "            if mode_check:\n",
    "                mode_avail.append(1)\n",
    "            else:\n",
    "                mode_avail.append(0)\n",
    "        # For each mode add a column with binary availability\n",
    "        data['av_'+mode] = mode_avail\n",
    "    return data\n",
    "\n",
    "# Add mode availability according to survey responses\n",
    "data = add_mode_availability(data, availability_codes, 'available_modes', 'Mode_confirm', 'Replaced_mode', is_sp=False)\n",
    "\n",
    "# # Add mode availability as all available\n",
    "mode_list = ['car','s_car','ridehail','transit','p_micro','s_micro','walk','ebike','no_travel']\n",
    "# for mode in mode_list:\n",
    "#     data[f\"av_{mode}\"] = 1\n",
    "\n",
    "# Handle all variables that are ordinal; otherwise they may not end up in correct order\n",
    "# Make sure that all mode variables align after being converted to numeric variables\n",
    "data.Mode_confirm = pd.Categorical(data.Mode_confirm, ordered=True, categories=mode_list)\n",
    "data.Replaced_mode = pd.Categorical(data.Replaced_mode, ordered=True, categories=mode_list)\n",
    "data['Mode_confirm_num'] = data.Mode_confirm.cat.codes\n",
    "data['Replaced_mode_num'] = data.Replaced_mode.cat.codes\n",
    "data = data[data['Mode_confirm_num']!=data['Replaced_mode_num']]\n",
    "\n",
    "## Save cleaned data to be used in modeling\n",
    "data.to_csv(\"processed_replacement_modeling_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data stats before cleaning\n",
    "print(f\"Trips: {len(expanded_ct)}\")\n",
    "print(f\"Users: {len(np.unique(expanded_ct.user_id))}\")\n",
    "print(f\"Trips per user: {len(expanded_ct) / len(pd.unique(expanded_ct.user_id))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data stats after cleaning + columns available\n",
    "print(f\"Trips: {len(data)}\")\n",
    "print(f\"Users: {len(np.unique(data.user_id))}\")\n",
    "print(f\"Trips per user: {len(data) / len(pd.unique(data.user_id))}\\n\")\n",
    "print(f\"Columns: \\n{data.columns.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for NAs\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check # obs for each class\n",
    "print(f\"Mode_confirm:\\n{pd.value_counts(data.Mode_confirm)}\\n\")\n",
    "print(f\"Replaced_mode:\\n{pd.value_counts(data.Replaced_mode)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
