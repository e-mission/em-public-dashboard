{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import importlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from uuid import UUID\n",
    "from collections import defaultdict\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_path = Path(os.getcwd()).parent.parent / 'my_emission_server' / 'e-mission-server'\n",
    "sys.path.append(str(emission_path))\n",
    "\n",
    "# Also add the home (viz_scripts) to the path\n",
    "sys.path.append('../viz_scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scaffolding\n",
    "import emission.core.get_database as edb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'scaffolding' from '/Users/rkulhall/em-public-dashboard/rm_src/../viz_scripts/scaffolding.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(scaffolding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.reset_index(drop=True, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../viz_scripts/auxiliary_files/dic_re.pkl', 'rb') as f:\n",
    "    dic_re = pickle.loads(f.read())\n",
    "\n",
    "with open('../viz_scripts/auxiliary_files/dic_pur.pkl', 'rb') as f:\n",
    "    dic_pur = pickle.loads(f.read())\n",
    "\n",
    "# convert a dictionary to a defaultdict\n",
    "dic_re = defaultdict(lambda: 'Other', dic_re)\n",
    "dic_pur = defaultdict(lambda: 'Other', dic_pur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new program stage, creating new list\n",
      "Found new program 4c, creating new list\n",
      "Found new program cc, creating new list\n",
      "Found new program fc, creating new list\n",
      "Found new program pc, creating new list\n",
      "Found new program sc, creating new list\n",
      "Found new program vail, creating new list\n",
      "Found new program prepilot, creating new list\n"
     ]
    }
   ],
   "source": [
    "# Split UUIDs by program\n",
    "program_uuid_map = {}\n",
    "for ue in edb.get_uuid_db().find():\n",
    "    uuid = str(ue['uuid'])\n",
    "    # uuid = str(ue['uuid'])\n",
    "    program = ue['user_email'].split(\"_\")[0]\n",
    "    if program in program_uuid_map.keys():\n",
    "        program_uuid_map[program].append(uuid)\n",
    "    else:\n",
    "        print(f\"Found new program {program}, creating new list\")\n",
    "        program_uuid_map[program] = []\n",
    "        program_uuid_map[program].append(uuid)\n",
    "\n",
    "uuid_program_list = []\n",
    "for ue in edb.get_uuid_db().find():\n",
    "    # uuid = str(ue['uuid'].as_uuid(3))\n",
    "    uuid = str(ue['uuid'])\n",
    "    program = ue['user_email'].split(\"_\")[0]\n",
    "    uuid_program_list.append({\"program\": program, \"opcode\": ue[\"user_email\"], \"user_id\": uuid})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid_program_df = pd.DataFrame(uuid_program_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded all confirmed trips of length 241123\n",
      "After filtering, found 241123 participant trips \n",
      "After filtering, found 92446 labeled trips\n",
      "Found Index(['mode_confirm', 'purpose_confirm', 'replaced_mode'], dtype='object') columns of length 3\n",
      "After expanding, columns went from 41 -> 44\n",
      "_prepilot\n",
      "Based on 92395 confirmed trips from 235 users\n",
      "of 241123 total  trips from 261 users (38.32%)\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "\n",
    "# for program in uuid_program_df.program.unique():\n",
    "expanded_ct, file_suffix, quality_text, debug_df = scaffolding.load_viz_notebook_data(None,\n",
    "                                                                            None,\n",
    "                                                                            'prepilot',\n",
    "                                                                            'program',\n",
    "                                                                            dic_re,\n",
    "                                                                            dic_pur=dic_pur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join to the program df to get each user's program\n",
    "expanded_ct['original_user_id'] = expanded_ct['user_id'].copy()\n",
    "expanded_ct['user_id'] = expanded_ct['user_id'].apply(lambda x: str(x))\n",
    "expanded_ct = expanded_ct.merge(uuid_program_df, on='user_id')\n",
    "expanded_ct['user_id'] = expanded_ct['user_id'].apply(lambda x: str(x).replace(\"-\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source', 'end_ts', 'end_fmt_time', 'end_loc', 'raw_trip', 'start_ts',\n",
       "       'start_fmt_time', 'start_loc', 'duration', 'distance', 'start_place',\n",
       "       'end_place', 'cleaned_trip', 'inferred_labels', 'inferred_trip',\n",
       "       'expectation', 'confidence_threshold', 'expected_trip', 'user_input',\n",
       "       'section_modes', 'section_distances', 'start_local_dt_year',\n",
       "       'start_local_dt_month', 'start_local_dt_day', 'start_local_dt_hour',\n",
       "       'start_local_dt_minute', 'start_local_dt_second',\n",
       "       'start_local_dt_weekday', 'start_local_dt_timezone',\n",
       "       'end_local_dt_year', 'end_local_dt_month', 'end_local_dt_day',\n",
       "       'end_local_dt_hour', 'end_local_dt_minute', 'end_local_dt_second',\n",
       "       'end_local_dt_weekday', 'end_local_dt_timezone', '_id', 'user_id',\n",
       "       'metadata_write_ts', 'additions', 'mode_confirm', 'purpose_confirm',\n",
       "       'replaced_mode', 'distance_miles', 'Mode_confirm', 'Replaced_mode',\n",
       "       'Trip_purpose', 'original_user_id', 'program', 'opcode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_ct.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the target column.\n",
    "expanded_ct.drop(columns=['replaced_mode'], axis='rows', inplace=True)\n",
    "expanded_ct['Replaced_mode'] = expanded_ct['Replaced_mode'].fillna('Unlabeled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only wish to focus on Denver data for now.\n",
    "\n",
    "denver_data = r(expanded_ct.loc[\n",
    "    (expanded_ct.start_local_dt_timezone == \"America/Denver\") & (expanded_ct.end_local_dt_timezone == \"America/Denver\"), \n",
    "    :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "denver_data['start_fmt_time'] = pd.to_datetime(\n",
    "    denver_data['start_fmt_time'], utc=True\n",
    ").dt.tz_convert('America/Denver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-22 17:13:55.883513-06:00 2022-12-30 23:33:27.147785-07:00\n"
     ]
    }
   ],
   "source": [
    "print(denver_data.start_fmt_time.min(), denver_data.start_fmt_time.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the datetime to Denver time.\n",
    "# denver_data['start_fmt_time'] = pd.to_datetime(denver_data['start_fmt_time'], utc=True).dt.tz_convert('America/Denver')\n",
    "\n",
    "# Re-compute all the start variables.\n",
    "denver_data['start_local_dt_year'] = denver_data['start_fmt_time'].dt.year\n",
    "denver_data['start_local_dt_month'] = denver_data['start_fmt_time'].dt.month\n",
    "denver_data['start_local_dt_day'] = denver_data['start_fmt_time'].dt.day\n",
    "denver_data['start_local_dt_hour'] = denver_data['start_fmt_time'].dt.hour\n",
    "denver_data['start_local_dt_weekday'] = denver_data['start_fmt_time'].dt.weekday\n",
    "\n",
    "## Do the same with the end time.\n",
    "denver_data['end_fmt_time'] = pd.to_datetime(denver_data['end_fmt_time'], utc=True).dt.tz_convert('America/Denver')\n",
    "\n",
    "# Re-compute all the end variables.\n",
    "denver_data['end_local_dt_year'] = denver_data['end_fmt_time'].dt.year\n",
    "denver_data['end_local_dt_month'] = denver_data['end_fmt_time'].dt.month\n",
    "denver_data['end_local_dt_day'] = denver_data['end_fmt_time'].dt.day\n",
    "denver_data['end_local_dt_hour'] = denver_data['end_fmt_time'].dt.hour\n",
    "denver_data['end_local_dt_weekday'] = denver_data['end_fmt_time'].dt.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the Demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Denver dedmographic info\n",
    "survey_data = pd.read_csv('../viz_scripts/Can Do Colorado eBike Program - en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column renaming here!\n",
    "\n",
    "survey_data.rename(\n",
    "    {\n",
    "        \"Unique User ID (auto-filled, do not edit)\": \"user_id\",\n",
    "        \"In which year were you born?\": \"birth_year\",\n",
    "        \"What is your gender?\": \"gender\",\n",
    "        \"Do you have a valid driver's license?\": \"has_drivers_license\",\n",
    "        \"Are you a student?\": \"is_student\",\n",
    "        \"What is the highest grade or degree that you have completed?\": \"highest_education\",\n",
    "        \"Do you work for either pay or profit?\": \"is_paid\",\n",
    "        \"Do you have more than one job?\": \"has_multiple_jobs\",\n",
    "        \"Do you work full-time or part-time at your primary job?\": \"primary_job_type\",\n",
    "        \"Which best describes your primary job?\": \"primary_job_description\",\n",
    "        \"How did you usually get to your primary job last week? \": \"primary_job_commute_mode\",\n",
    "        \"Thinking about your daily commute to work last week, how many minutes did it usually take to get from home to the primary job/work place?\": \"primary_job_commute_time\",\n",
    "        \"At your primary job, do you have the ability to set or change your own start time?\": \"is_primary_job_flexible\",\n",
    "        \"Do you have the option of working from home or an alternate location instead of going into your primary work place?\": \"primary_job_can_wfh\",\n",
    "        \"How many days per week do you usually work from home or an alternate location?\": \"wfh_days\",\n",
    "        \"Do you own or rent your place of residence?\": \"residence_ownership_type\",\n",
    "        \"What is your home type?\": \"residence_type\",\n",
    "        \"Please identify which category represents your total household income, before taxes, for last year.\": \"income_category\",\n",
    "        \"Including yourself, how many people live in your home?\": \"n_residence_members\",\n",
    "        \"How many children under age 18 live in your home?\": \"n_residents_u18\",\n",
    "        \"Including yourself, how many people have a driver's license in your household?\": \"n_residents_with_license\",\n",
    "        \"How many motor vehicles are owned, leased, or available for regular use by the people who currently live in your household?\": \"n_motor_vehicles\",\n",
    "        \"If you were unable to use your household vehicle(s), which of the following options would be available to you to get you from place to place?\": \"available_modes\",\n",
    "        \"Do you have a medical condition that makes it difficult to travel outside of the home?\": \"has_medical_condition\",\n",
    "        \"How long have you had this condition?\": \"medical_condition_duration\"\n",
    "    },\n",
    "    axis='columns',\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, if we have duplicate users, we'd like to retain the last chronological entry.\n",
    "survey_data = survey_data.loc[~((survey_data.user_id.isna())|(survey_data.user_id == \"\")), :]\n",
    "\n",
    "# timezonoe-aware parsing:\n",
    "survey_data['Timestamp'] = survey_data['Timestamp'].str.replace('PDT|PST', '', regex=True)\n",
    "survey_data['Timestamp'] = pd.to_datetime(survey_data['Timestamp']).dt.tz_localize('America/Denver')\n",
    "\n",
    "# Sort by user_id and time, then drop everything but the last entry.\n",
    "survey_data.sort_values(by=['user_id', 'Timestamp'], ascending=True, inplace=True, axis='rows')\n",
    "survey_data.drop_duplicates(['user_id'], keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the trip data with the survey data.\n",
    "\n",
    "merged_data = denver_data.merge(\n",
    "    survey_data, left_on='user_id', right_on='user_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start choosing features for modeling.\n",
    "\n",
    "base_time_features = ['fmt_time', 'local_dt_year', 'local_dt_month', 'local_dt_day', 'local_dt_hour', 'local_dt_weekday']\n",
    "time_features = ['start_' + x for x in base_time_features] + ['end_' + x for x in base_time_features]\n",
    "\n",
    "demographic_features = ['available_modes',\n",
    "    'birth_year', 'income_category', 'n_motor_vehicles', 'n_residence_members', 'n_residents_u18', 'gender', \n",
    "    'is_student', 'n_residents_with_license']\n",
    "\n",
    "sensed_features = ['duration', 'distance_miles', 'cleaned_trip', 'start_loc', 'end_loc', 'section_modes', 'section_distances']\n",
    "\n",
    "modeling_data = merged_data[['user_id', '_id', 'original_user_id', 'cleaned_trip', 'Replaced_mode', 'Mode_confirm'] + time_features + demographic_features + sensed_features].copy()\n",
    "\n",
    "# Rename columns in-place.\n",
    "modeling_data.rename(columns={\n",
    "    'start_local_dt_year': 'start:year', 'start_local_dt_month': 'start:month', 'start_local_dt_day': 'start:day', 'start_local_dt_hour': 'start:hour',\n",
    "    'end_local_dt_year': 'end:year', 'end_local_dt_month': 'end:month', 'end_local_dt_day': 'end:day', 'end_local_dt_hour': 'end:hour'\n",
    "    }, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calendar import monthrange\n",
    "\n",
    "# Find day of month: use monthrange with (mm, yyyy) args and find how many days that month had (leap years are supported).\n",
    "def get_num_days_in_month(yyyy, mm):\n",
    "    return monthrange(yyyy, mm)[1]\n",
    "\n",
    "def is_overnight_trip(start_date, end_date):\n",
    "    return int((end_date - start_date).days > 0)\n",
    "\n",
    "# get the number of days for the start and end times.\n",
    "modeling_data['start:n_days_in_month'] = modeling_data.apply(lambda x: get_num_days_in_month(x['start:year'], x['start:month']), axis=1)\n",
    "modeling_data['end:n_days_in_month'] = modeling_data.apply(lambda x: get_num_days_in_month(x['end:year'], x['end:month']), axis=1)\n",
    "\n",
    "# age = current year - year of birth\n",
    "modeling_data['age'] = 2023 - modeling_data['birth_year']\n",
    "\n",
    "# overnight trips may be more likely taken by car.\n",
    "modeling_data['is_overnight_trip'] = modeling_data.apply(lambda x: is_overnight_trip(x.start_fmt_time, x.end_fmt_time), axis=1)\n",
    "\n",
    "# Number of working individuals in the household = number of individuals in the house - number of children.\n",
    "modeling_data['n_working_residents'] = (modeling_data['n_residence_members'] - modeling_data['n_residents_u18']).astype(int)\n",
    "\n",
    "# Create a binary indicator.\n",
    "modeling_data['is_male'] = modeling_data.gender.apply(lambda x: 1 if x==\"Male\" else 0)\n",
    "\n",
    "# Bin the number of vehicles owned.\n",
    "# Drop the observations with (Prefer not to say)\n",
    "modeling_data = modeling_data.loc[~modeling_data['n_motor_vehicles'].isin(['Prefer not to say / Prefiero no decir.']), :]\n",
    "modeling_data.loc[modeling_data['n_motor_vehicles'].isin(['4+']), 'n_motor_vehicles'] = 4\n",
    "modeling_data['n_motor_vehicles'] = modeling_data['n_motor_vehicles'].astype(int)\n",
    "\n",
    "# Convert the total duration of the trip into minutes.\n",
    "modeling_data[['duration']] = modeling_data[['duration']]/60\n",
    "\n",
    "# Extract start and end latitudes and longitudes.\n",
    "modeling_data['start_lat'] = modeling_data['start_loc'].apply(lambda x: x['coordinates'][1])\n",
    "modeling_data['start_lng'] = modeling_data['start_loc'].apply(lambda x: x['coordinates'][0])\n",
    "\n",
    "modeling_data['end_lat'] = modeling_data['end_loc'].apply(lambda x: x['coordinates'][1])\n",
    "modeling_data['end_lng'] = modeling_data['end_loc'].apply(lambda x: x['coordinates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calendar import monthrange\n",
    "\n",
    "# Find day of month: use monthrange with (mm, yyyy) args and find how many days that month had (leap years are supported).\n",
    "def get_num_days_in_month(yyyy, mm):\n",
    "    return monthrange(yyyy, mm)[1]\n",
    "\n",
    "def is_overnight_trip(start_date, end_date):\n",
    "    return int((end_date - start_date).days > 0)\n",
    "\n",
    "# get the number of days for the start and end times.\n",
    "modeling_data['start:n_days_in_month'] = modeling_data.apply(lambda x: get_num_days_in_month(x['start:year'], x['start:month']), axis=1)\n",
    "modeling_data['end:n_days_in_month'] = modeling_data.apply(lambda x: get_num_days_in_month(x['end:year'], x['end:month']), axis=1)\n",
    "\n",
    "# age = current year - year of birth\n",
    "modeling_data['age'] = 2023 - modeling_data['birth_year']\n",
    "\n",
    "# overnight trips may be more likely taken by car.\n",
    "modeling_data['is_overnight_trip'] = modeling_data.apply(lambda x: is_overnight_trip(x.start_fmt_time, x.end_fmt_time), axis=1)\n",
    "\n",
    "# Number of working individuals in the household = number of individuals in the house - number of children.\n",
    "modeling_data['n_working_residents'] = (modeling_data['n_residence_members'] - modeling_data['n_residents_u18']).astype(int)\n",
    "\n",
    "# Create a binary indicator.\n",
    "modeling_data['is_male'] = modeling_data.gender.apply(lambda x: 1 if x==\"Male\" else 0)\n",
    "\n",
    "# Bin the number of vehicles owned.\n",
    "# Drop the observations with (Prefer not to say)\n",
    "modeling_data = modeling_data.loc[~modeling_data['n_motor_vehicles'].isin(['Prefer not to say / Prefiero no decir.']), :]\n",
    "modeling_data.loc[modeling_data['n_motor_vehicles'].isin(['4+']), 'n_motor_vehicles'] = 4\n",
    "modeling_data['n_motor_vehicles'] = modeling_data['n_motor_vehicles'].astype(int)\n",
    "\n",
    "# Convert the total duration of the trip into minutes.\n",
    "modeling_data[['duration']] = modeling_data[['duration']]/60\n",
    "\n",
    "# Extract start and end latitudes and longitudes.\n",
    "modeling_data['start_lat'] = modeling_data['start_loc'].apply(lambda x: x['coordinates'][1])\n",
    "modeling_data['start_lng'] = modeling_data['start_loc'].apply(lambda x: x['coordinates'][0])\n",
    "\n",
    "modeling_data['end_lat'] = modeling_data['end_loc'].apply(lambda x: x['coordinates'][1])\n",
    "modeling_data['end_lng'] = modeling_data['end_loc'].apply(lambda x: x['coordinates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-related feature engineeering:\n",
    "'''\n",
    "HOD: hour of day\n",
    "DOM: day of month\n",
    "MOY: month of year\n",
    "'''\n",
    "\n",
    "def get_HOD(hour, how='sin'):\n",
    "    if how == 'sin':\n",
    "        return np.sin(2 * np.pi * (hour/24))\n",
    "    return np.cos(2 * np.pi * (hour/24))\n",
    "\n",
    "def get_DOM(day, n_days, how='sin'):\n",
    "    if how == 'sin':\n",
    "        return np.sin(2 * np.pi * (day/n_days))\n",
    "    return np.cos(2 * np.pi * (day/n_days))\n",
    "\n",
    "def get_MOY(month, how='sin'):\n",
    "    if how == 'sin':\n",
    "        return np.sin(2 * np.pi * (month/12))\n",
    "    return np.cos(2 * np.pi * (month/12))\n",
    "\n",
    "# Start - sin\n",
    "modeling_data['start:sin_HOD'] = modeling_data.apply(lambda x: get_HOD(x['start:hour']), axis=1)\n",
    "modeling_data['start:sin_DOM'] = modeling_data.apply(lambda x: get_DOM(x['start:day'], x['start:n_days_in_month']), axis=1)\n",
    "modeling_data['start:sin_MOY'] = modeling_data.apply(lambda x: get_MOY(x['start:year']), axis=1)\n",
    "\n",
    "# Start - cos\n",
    "modeling_data['start:cos_HOD'] = modeling_data.apply(lambda x: get_HOD(x['start:hour'], how='cos'), axis=1)\n",
    "modeling_data['start:cos_DOM'] = modeling_data.apply(lambda x: get_DOM(x['start:day'], x['start:n_days_in_month'], how='cos'), axis=1)\n",
    "modeling_data['start:cos_MOY'] = modeling_data.apply(lambda x: get_MOY(x['start:year'], how='cos'), axis=1)\n",
    "\n",
    "# End - sin\n",
    "modeling_data['end:sin_HOD'] = modeling_data.apply(lambda x: get_HOD(x['end:hour']), axis=1)\n",
    "modeling_data['end:sin_DOM'] = modeling_data.apply(lambda x: get_DOM(x['end:day'], x['end:n_days_in_month']), axis=1)\n",
    "modeling_data['end:sin_MOY'] = modeling_data.apply(lambda x: get_MOY(x['end:year']), axis=1)\n",
    "\n",
    "# End - cos\n",
    "modeling_data['end:cos_HOD'] = modeling_data.apply(lambda x: get_HOD(x['end:hour'], how='cos'), axis=1)\n",
    "modeling_data['end:cos_DOM'] = modeling_data.apply(lambda x: get_DOM(x['end:day'], x['end:n_days_in_month'], how='cos'), axis=1)\n",
    "modeling_data['end:cos_MOY'] = modeling_data.apply(lambda x: get_MOY(x['end:year'], how='cos'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for every trip, we have the corresponding section mode that covered the longest distance for the trip.\n",
    "\n",
    "Using this as well as the `available_modes` column:\n",
    "\n",
    "```language=python\n",
    "\n",
    "    # unique available modes:\n",
    "    {'Bicycle',\n",
    "    'Do not have vehicle ',\n",
    "    'Get a ride from a friend or family member',\n",
    "    'None',\n",
    "    'Public transportation (bus, subway, light rail, etc.)',\n",
    "    'Rental car (including Zipcar/ Car2Go)',\n",
    "    'Shared bicycle or scooter',\n",
    "    'Skateboard',\n",
    "    'Taxi (regular taxi, Uber, Lyft, etc)',\n",
    "    'Walk/roll'}\n",
    "\n",
    "    # unique section modes:\n",
    "    {'bicycling', 'bus', 'car', 'no_sensed', 'train', 'walking'}\n",
    "\n",
    "    \n",
    "```\n",
    "\n",
    "What mapping can we establish here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_air_or_hsr(df):\n",
    "\n",
    "    df['mark'] = 0\n",
    "\n",
    "    for ix, row in df.iterrows():\n",
    "        sections = row['section_modes']\n",
    "        if 'air_or_hsr' in sections:\n",
    "            df.loc[ix, 'mark'] = 1\n",
    "    \n",
    "    df = r(df.loc[df.mark == 0, :])\n",
    "    df.drop(columns=['mark'], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data = remove_air_or_hsr(modeling_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(scaffolding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data = modeling_data.loc[:,~modeling_data.columns.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | [a, b, c] | start_time | end_time |\n",
    "# -> | [a, b, c] | [s1, s2, s3] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(modeling_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I manually split the modeling data into chunks of 10000 points at one time.\n",
    "# This significantly expedited the processing time. Each chunk takes ~26 minutes to finish.\n",
    "# split = modeling_data.loc[70000:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(split[['original_user_id', 'cleaned_trip']].head())\n",
    "# print(split.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from time import perf_counter\n",
    "\n",
    "# now = perf_counter()\n",
    "# result = scaffolding.get_section_durations(split)\n",
    "# end = perf_counter() - now\n",
    "\n",
    "# print(f\"Took {end/60} minutes to complete\")\n",
    "# results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = pd.concat(results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(modeling_data.shape[0], final_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling_data.to_csv('../data/modeling_data.csv', index=False)\n",
    "# final_df.to_csv('../data/modeling_w_duration.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from time import perf_counter\n",
    "# importlib.reload(scaffolding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/modeling_w_duration.csv')\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape, modeling_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = modeling_data.iloc[50000:, :]\n",
    "\n",
    "print(dummy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now = perf_counter()\n",
    "df_modded = scaffolding.get_section_coordinates(dummy)\n",
    "# end = perf_counter() - now\n",
    "\n",
    "# print(f\"Fetched sections in {end/60} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(locations):\n",
    "    return locations is not None and len(locations) > 0\n",
    "\n",
    "\n",
    "bools = df_modded.apply(lambda x: verify(x.section_locations_argmax), axis=1)\n",
    "print(bools.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(df_modded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = pd.concat(results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([df, final_results['section_locations_argmax']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[['section_modes', 'section_distances', 'section_durations', 'section_locations_argmax']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('../data/final_modeling_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.section_locations_argmax[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab0c6e94c9422d07d42069ec9e3bb23090f5e156fc0e23cc25ca45a62375bf53"
  },
  "kernelspec": {
   "display_name": "emission",
   "language": "python",
   "name": "emission"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
